<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>llmflex.Tools.tool_utils API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>llmflex.Tools.tool_utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import inspect
from typing import Literal, List, Dict, Any, Optional, Callable, Union, Type
from ..Models.Cores.base_core import BaseLLM
from ..Prompts.prompt_template import PromptTemplate

PYTHON_TO_JSON_TYPES = {
    &#34;str&#34;: &#34;string&#34;,
    &#34;int&#34;: &#34;integer&#34;,
    &#34;float&#34;: &#34;number&#34;,
    &#34;bool&#34;: &#34;boolean&#34;,
    &#34;list&#34;: &#34;array&#34;
}

def normalise_tool_name(name: str) -&gt; str:
    &#34;&#34;&#34;Make the tool name in lower case and split it with &#34;_&#34;.

    Args:
        name (str): Original name of the tool.

    Returns:
        str: Normalised tool name.
    &#34;&#34;&#34;
    import re
    tokens = re.sub( r&#34;([A-Z])&#34;, r&#34; \1&#34;, name).split()
    tokens = list(map(lambda x: x.lower().strip(&#39; \n\r\t_&#39;), tokens))
    return &#39;_&#39;.join(tokens).strip()

def get_description(docstring: str) -&gt; str:
    &#34;&#34;&#34;Get the function or tool description from the docstring.

    Args:
        docstring (str): The docstring of the function or tool.

    Returns:
        str: The description of the function or tool.
    &#34;&#34;&#34;
    blocks = [&#39;args:&#39;, &#39;raises:&#39;, &#39;returns:&#39;]
    lines = map(lambda x: x.strip(), docstring.split(&#39;\n&#39;))
    lines = filter(lambda x: x != &#39;&#39;, lines)
    descriptions = []
    for line in lines:
        if line.lower() in blocks:
            break
        else:
            descriptions.append(line)
    return &#39;\n&#39;.join(descriptions).strip()

class BaseTool:
    &#34;&#34;&#34;Base class for tools.
    &#34;&#34;&#34;
    def __init__(self, name: Optional[str] = None, description: Optional[str] = None) -&gt; None:
        &#34;&#34;&#34;Initialising the tool.

        Args:
            name (Optional[str], optional): Name of the tool. If not given, it will be the tool class name. Defaults to None.
            description (Optional[str], optional): Description of the tool. If not given, it will read from the docstring of the tool class. Defaults to None.
        &#34;&#34;&#34;
        from ..utils import validate_type
        self._name = normalise_tool_name(validate_type(name.strip(), str)) if name is not None else normalise_tool_name(self.__class__.__name__)
        self._description = validate_type(description.strip(), str) if description is not None else get_description(self.__doc__) if self.__doc__ else &#39;&#39;

    @property
    def name(self) -&gt; str:
        &#34;&#34;&#34;Name of the tool.

        Returns:
            str: Name of the tool.
        &#34;&#34;&#34;
        return self._name
    
    @property
    def description(self) -&gt; str:
        &#34;&#34;&#34;Description of the tool.

        Returns:
            str: Description of the tool.
        &#34;&#34;&#34;
        return self._description
    
    def __call__(self, **kwargs) -&gt; Any:
        &#34;&#34;&#34;The main function of the tool.

        Returns:
            Any: Output of the tool.
        &#34;&#34;&#34;
        pass

def get_args_descriptions(docstring: str) -&gt; Dict[str, str]:
    &#34;&#34;&#34;Get the description of the arguments of a function or tool given the docstring.

    Args:
        docstring (str): Docstring of the callable.

    Returns:
        Dict[str, str]: Dictionary of the arguments and their descriptions.
    &#34;&#34;&#34;
    blocks = [&#39;raises:&#39;, &#39;returns:&#39;]
    lines = map(lambda x: x.strip(), docstring.split(&#39;\n&#39;))
    lines = filter(lambda x: x != &#39;&#39;, lines)
    started = False
    args = dict()
    for line in lines:
        if line.lower() == &#39;args:&#39;:
            started = True
        elif line.lower() in blocks:
            started = False
        elif started:
            elements = line.split(&#39;:&#39;)
            if len(elements) &gt; 1:
                args[elements[0].split(&#39;(&#39;)[0].strip()] = &#39;:&#39;.join(elements[1:]).strip()
    return args
                
def get_required_args(fn: Callable) -&gt; List[str]:
    &#34;&#34;&#34;Get the mandatory arguments of the given function.

    Args:
        fn (Callable): Function of interest.

    Returns:
        List[str]: List of mandatory arguments.
    &#34;&#34;&#34;
    specs = inspect.getfullargspec(fn)
    args = specs.args
    if specs.defaults:
        args = args[:-len(specs.defaults)]
    args = list(filter(lambda x: x not in [&#39;cls&#39;, &#39;self&#39;], args))
    return args

def get_args_dtypes(fn: Callable) -&gt; Dict[str, Dict[str, Any]]:
    &#34;&#34;&#34;Get the data types of the arguments of a function or tool given the callable.

    Args:
        fn (Callable): The function or the tool.

    Returns:
        Dict[str, Dict[str, Any]]: Dictionary of the arguments and their data types and descriptions.
    &#34;&#34;&#34;
    annotations = inspect.getfullargspec(fn).annotations
    args_desc = get_args_descriptions(fn.__doc__) if fn.__doc__ is not None else dict()
    required = get_required_args(fn)
    signature = inspect.signature(fn)
    defaults = {
        k: v.default
        for k, v in signature.parameters.items()
        if v.default is not inspect.Parameter.empty
    }
    args = dict()
    for arg, arg_type in annotations.items():
        if arg in [&#39;return&#39;, &#39;cls&#39;, &#39;self&#39;]:
            continue

        if getattr(arg_type, &#39;__name__&#39;) in PYTHON_TO_JSON_TYPES.keys():
            args[arg] = dict(type=PYTHON_TO_JSON_TYPES[arg_type.__name__])
            if arg in args_desc:
                args[arg][&#39;description&#39;] = args_desc[arg]
            if arg not in required:
                args[arg][&#39;default&#39;] = defaults[arg]
        elif getattr(arg_type, &#39;__name__&#39;) == &#39;Literal&#39;:
            dtype = getattr(type(arg_type.__args__[0]), &#39;__name__&#39;)
            dtype = PYTHON_TO_JSON_TYPES.get(dtype, None)
            args[arg] = dict()
            if dtype is not None:
                args[arg][&#39;type&#39;] = dtype
                if arg in args_desc:
                    args[arg][&#39;description&#39;] = args_desc[arg]
                args[arg][&#39;enum&#39;] = list(arg_type.__args__)
                if arg not in required:
                    args[arg][&#39;default&#39;] = defaults[arg]
            else:
                args[arg][&#39;type&#39;] = getattr(arg_type, &#39;__name__&#39;, str(arg_type))
                if arg in args_desc:
                    args[arg][&#39;description&#39;] = args_desc[arg]
                args[arg][&#39;enum&#39;] = list(map(lambda x: str(x), arg_type.__args__))
                if arg not in required:
                    args[arg][&#39;default&#39;] = defaults[arg]
        elif getattr(arg_type, &#39;__name__&#39;) == &#39;Optional&#39;:
            dtype = getattr(arg_type.__args__[0], &#39;__name__&#39;)
            dtype = PYTHON_TO_JSON_TYPES.get(dtype, None)
            args[arg] = dict()
            if dtype is not None:
                args[arg][&#39;type&#39;] = dtype
            else:
                args[arg][&#39;type&#39;] = getattr(arg_type, &#39;__name__&#39;, str(arg_type))
            if arg in args_desc:
                args[arg][&#39;description&#39;] = args_desc[arg]
            if arg not in required:
                args[arg][&#39;default&#39;] = defaults[arg]
        else:
            args[arg] = dict()
            args[arg][&#39;type&#39;] = getattr(arg_type, &#39;__name__&#39;, str(arg_type))
            if arg in args_desc:
                args[arg][&#39;description&#39;] = args_desc[arg]
            if arg not in required:
                args[arg][&#39;default&#39;] = defaults[arg]
    return args

def get_tool_metadata(fn: Union[Callable, Type[BaseTool]]) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Get the tool metadata as a dictionary.

    Args:
        fn (Union[Callable, Type[BaseTool]]): Tool or python function.

    Returns:
        Dict[str, Any]: Metadata of the tool or function.
    &#34;&#34;&#34;
    is_tool = isinstance(fn, BaseTool)
    desc_doc = fn.description if isinstance(fn, BaseTool) else getattr(fn, &#39;__doc__&#39;)
    if is_tool:
        name = fn.name
        description = desc_doc
        required = get_required_args(fn.__call__)
        args = get_args_dtypes(fn.__call__)
    else:
        name = normalise_tool_name(fn.__name__)
        description = get_description(desc_doc) if desc_doc else &#39;&#39;
        required = get_required_args(fn)
        args = get_args_dtypes(fn)
    return dict(name=name, description=description, parameters=dict(type=&#39;object&#39;, properties=args, required=required))
    
def select(llm: Type[BaseLLM], prompt: str, options: List[str], 
           stop: Optional[List[str]] = None, default: Optional[str] = None, retry: int = 3, raise_error: bool = False, **kwargs) -&gt; Optional[str]:
    &#34;&#34;&#34;Ask the LLM to make a selection of the list of options provided.

    Args:
        llm (Type[BaseLLM]): LLM to generate the selection.
        prompt (str): Prompt for the llm.
        options (List[str]): List of options for the LLM to pick.
        stop (Optional[List[str]], None): List of stop words for the LLM to help the llm stop earlier. Defaults to None.
        default (Optional[str], optional): Default value if the LLM fails to generate the option. If none is given and the LLM fail, an error will be raised. Defaults to None.
        retry (int, optional): Number of times the llm can retry. Defaults to 3.
        raise_error (bool, optional): Whether to raise an error if the selection failed. Defaults to False.

    Returns:
        Optional[str]: The selection of the LLM given the options.
    &#34;&#34;&#34;
    if len(options) == 0:
        raise ValueError(&#39;&#34;options&#34; must contain at least one string.&#39;)
    if llm.core.core_type ==&#39;llama_cpp_core&#39;:
        from guidance.models.llama_cpp import LlamaCpp
        from guidance import select as gselect
        gllm = LlamaCpp(model=llm.core.model, echo=False)
        res = gllm + prompt + gselect(options=options)
        res = str(res).removeprefix(prompt)
        del gllm
        return res
    else:
        from math import ceil
        from copy import deepcopy
        option_num_tokens = [llm.get_num_tokens(opt) for opt in options]
        max_new_tokens = ceil(max(option_num_tokens) * 1.2)
        stop = [] if stop is None else stop
        for i in range(retry):
            clone_kw = deepcopy(kwargs)
            clone_kw.pop(&#39;max_new_tokens&#39;, None)
            res = llm.invoke(prompt, stop=stop, max_new_tokens=max_new_tokens, **clone_kw)
            if res in options:
                return res
            else:
                valids = list(filter(lambda x: res.startswith(x), options))
                if len(valids) &gt;= 1:
                    return max(valids, key=len)
        if default is not None:
            return default
        elif raise_error:
            raise RuntimeError(f&#39;LLM cannot generate one of the options after {retry} retries.&#39;)
        else:
            return None
        
def gen_string(llm: Type[BaseLLM], prompt: str, double_quote: bool = True, max_gen: int = 5, **kwargs) -&gt; str:
    &#34;&#34;&#34;Generate a valid string that can be wrapped between quotes safely. 

    Args:
        llm (Type[BaseLLM]): LLM for the string generation.
        prompt (str): Prompt for generating the string, should not include the open quote.
        double_quote (bool, optional): Whether to use double quote or not. The quote character will be added to the end of the original prompt. Defaults to True.
        max_gen (int, optional): In the unlikely event of the LLM keep generating without being able to generate a valid string, this set the maximum of generation the LLM can go. Defaults to 5.

    Returns:
        str: A valid string that can be wrapped between quotes safely. If a valid string cannot be generated, an empty string will be returned.
    &#34;&#34;&#34;
    quote = &#39;&#34;&#39; if double_quote else &#34;&#39;&#34;
    original = prompt + quote
    text = quote
    not_string: bool = True
    count = 0
    while ((not_string) &amp; (count &lt; max_gen)):
        try:
            assert isinstance(eval(text), str)
            not_string = False
        except:
            new = llm.invoke(original, stop=[quote], **kwargs)
            text += new + quote
            original += new + quote
            count += 1
    if not not_string:
        return eval(text)
    else:
        return &#39;&#39;

def direct_response() -&gt; str:
    &#34;&#34;&#34;Direct response without using any tools or functions.

    Returns:
        str: Response.
    &#34;&#34;&#34;
    # This is a placeholder function for function call when no tools or functions are required. 
    pass

### Tool selection
class ToolSelector:
    &#34;&#34;&#34;Class for selecting tool.
    &#34;&#34;&#34;
    def __init__(self, tools: List[Union[Callable, Type[BaseTool]]]) -&gt; None:
        self._tools = tools if direct_response in tools else tools + [direct_response]
        self._metadatas = [get_tool_metadata(tool) for tool in self.tools]
        self._tool_names: List[str] = [m[&#39;name&#39;] for m in self._metadatas]
        self._enabled = dict(zip(self._tool_names, [True] * len(self._tool_names)))
    
    @property
    def tool_names(self) -&gt; List[str]:
        &#34;&#34;&#34;List of tool names.

        Returns:
            List[str]: List of tool names.
        &#34;&#34;&#34;
        return self._tool_names
    
    @property
    def enabled_tools(self) -&gt; List[str]:
        &#34;&#34;&#34;List of tool names that are enabled.

        Returns:
            List[str]: List of tool names that are enabled.
        &#34;&#34;&#34;
        enabled_tools = filter(lambda x: x[1], self._enabled.items())
        return list(map(lambda x: x[0], enabled_tools))
    
    @property
    def num_tools(self) -&gt; int:
        &#34;&#34;&#34;Number of enabled tools.

        Returns:
            int: Number of enabled tools.
        &#34;&#34;&#34;
        return len(self.enabled_tools)
    
    @property
    def tools(self) -&gt; List[Union[Callable, Type[BaseTool]]]:
        &#34;&#34;&#34;List of available tools.

        Returns:
            List[Union[Callable, Type[BaseTool]]]: List of available tools.
        &#34;&#34;&#34;
        return self._tools

    @property
    def metadatas(self) -&gt; List[Dict[str, Any]]:
        &#34;&#34;&#34;List of metadatas of tools.

        Returns:
            List[Dict[str, Any]]: List of metadatas of tools.
        &#34;&#34;&#34;
        return list(filter(lambda x: x[&#39;name&#39;] in self.enabled_tools, self._metadatas))
    
    @property
    def tool_map(self) -&gt; Dict[str, Union[Callable, Type[BaseTool]]]:
        &#34;&#34;&#34;Map of tool names and the tools.

        Returns:
            Dict[str, Union[Callable, Type[BaseTool]]]: Map of tool names and the tools.
        &#34;&#34;&#34;
        if not hasattr(self, &#39;_tool_map&#39;):
            names = [m[&#39;name&#39;] for m in self.metadatas]
            self._tool_map = dict(zip(names, self.tools))
        return {k: self._tool_map[k] for k in self.enabled_tools}
    
    @property
    def function_metadata(self) -&gt; Dict[str, str]:
        &#34;&#34;&#34;A message with the role &#34;function_metadata&#34; and content being the metadata of the tools.

        Returns:
            Dict[str, str]: A message with the role &#34;function_metadata&#34; and content being the metadata of the tools.
        &#34;&#34;&#34;
        import json
        return dict(role=&#39;function_metadata&#39;, content=json.dumps(self.metadatas, indent=4))
        
    @property
    def is_empty(self) -&gt; bool:
        &#34;&#34;&#34;Whether tools except direct_response are enabled.

        Returns:
            bool: Whether tools except direct_response are enabled.
        &#34;&#34;&#34;
        return ((len(self.enabled_tools) == 1) &amp; (&#39;direct_response&#39; in self.enabled_tools))

    def get_tool_metadata(self, tool_name: str) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Get the tool metadata given the tool name.

        Args:
            tool_name (str): Tool name.

        Returns:
            Dict[str, Any]: Metadata of the tool.
        &#34;&#34;&#34;
        return list(filter(lambda x: x[&#39;name&#39;] == tool_name, self.metadatas))[0]
    
    def structured_input_generation(self, raw_prompt: str, llm: Type[BaseLLM], **kwargs) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Core part of tool input generation.

        Args:
            raw_prompt (str): The starting prompt.
            llm (Type[BaseLLM]): LLM for generation.

        Returns:
            Dict[str, Any]: Dictionary containing the name of the function and the input arguments.
        &#34;&#34;&#34;
        import json
        original_prompt = raw_prompt
        prompt: str = original_prompt + &#39;{\n\t&#34;name&#34;: &#34;&#39;
        tool_name = select(llm=llm, prompt=prompt, options=self.enabled_tools, default=&#39;direct_response&#39;, **kwargs)
        tool = self.get_tool_metadata(tool_name=tool_name)

        # gather tool info
        args_info = tool[&#39;parameters&#39;][&#39;properties&#39;]
        args = list(args_info.keys())
        required_args = tool[&#39;parameters&#39;][&#39;required&#39;]
        optional_args = list(filter(lambda x: x not in required_args, args))

        prompt += tool_name + &#39;&#34;&#39;
        if len(args) == 0:
            prompt += &#39;\n}&#39;
        else:
            prompt += &#39;,\n\t&#34;inputs&#34;: {&#39;
            if len(required_args) != 0:
                for arg in required_args:
                    prompt += f&#39;\n\t\t&#34;{arg}&#34;: &#39;
                    enum = args_info[arg].get(&#39;enum&#39;)
                    if args_info[arg].get(&#39;type&#39;) == &#39;string&#39;:
                        if enum is None:
                            val = gen_string(llm=llm, prompt=prompt, **kwargs)
                            prompt += &#39;&#34;&#39; + val + &#39;&#34;,&#39;
                        else:
                            val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                            if val is not None:
                                prompt +=  f&#39;&#34;{val}&#34;&#39; + &#39;,&#39;
                            else:
                                return dict(name=&#39;direct_response&#39;)
                    elif enum is None:
                        prompt += llm.invoke(prompt, stop=[&#39;\n\t&#39;], **kwargs)
                    else:
                        val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                        if val is not None:
                            prompt += val + &#39;,&#39;
                        else:
                            return dict(name=&#39;direct_response&#39;)
                prompt = prompt.rstrip(&#39;,&#39;) # strip off the comma, see if the llm wants to continue on optional arguments
                if len(optional_args) &gt; 0:
                    from copy import deepcopy
                    clone_kw = deepcopy(kwargs)
                    clone_kw.pop(&#39;max_new_tokens&#39;, None)
                    new_tokens = llm.invoke(prompt, max_new_tokens=3, **clone_kw)
                    used_args = []
                    while ((new_tokens.startswith(&#39;,&#39;)) &amp; (len(used_args) &lt; len(optional_args))):
                        prompt += &#39;,\n\t\t&#34;&#39;
                        arg = select(llm=llm, prompt=prompt, options=list(filter(lambda x: x not in used_args, optional_args)), stop=[&#39;&#34;&#39;], **kwargs)
                        if arg is None:
                            prompt = prompt.removesuffix(&#39;,\n\t\t&#34;&#39;)
                            new_tokens = &#39;&#39;
                        else:
                            prompt += arg + &#39;&#34;: &#39;
                            enum = args_info[arg].get(&#39;enum&#39;)
                            default = args_info[arg].get(&#39;default&#39;)
                            default = &#39;null&#39; if default is None else default
                            if args_info[arg].get(&#39;type&#39;) == &#39;string&#39;:
                                if enum is None:
                                    val = gen_string(llm=llm, prompt=prompt, **kwargs)
                                    val = default if val == &#39;&#39; else f&#39;&#34;{val}&#34;&#39;
                                    prompt += val
                                else:
                                    val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                                    val = default if val is None else f&#39;&#34;{val}&#34;&#39;
                                    prompt += val
                            elif enum is None:
                                prompt += llm.invoke(prompt, stop=[&#39;\n\t&#39;], **kwargs)
                                prompt = prompt.strip(&#39;, \n\r\t&#39;)
                            else:
                                val = select(llm, prompt=prompt, options=enum, **kwargs)
                                val = default if val is None else val
                                prompt += val
                            clone_kw = deepcopy(kwargs)
                            clone_kw.pop(&#39;max_new_tokens&#39;, None)
                            new_tokens = llm.invoke(prompt, max_new_tokens=3, **clone_kw)
            prompt += &#39;\n\t}\n}&#39;
        try:
            return json.loads(prompt.removeprefix(original_prompt))
        except:
            return dict(name=&#39;direct_response&#39;)
    
    def tool_call_input(self, llm: Type[BaseLLM], messages: List[Dict[str, str]], prompt_template: Optional[PromptTemplate] = None, **kwargs) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Generate a dictionary of the tool to use and the input arguments.

        Args:
            llm (Type[BaseLLM]): LLM for the function call generation.
            messages (List[Dict[str, str]]): List of messages of the conversation history, msut contain the function metadatas.
            prompt_template (Optional[PromptTemplate], optional): Prompt template to use. If none is give, the default prompt template for the llm will be used. Defaults to None.

        Returns:
            Dict[str, Any]: Dictionary containing the name of the function and the input arguments.
        &#34;&#34;&#34;
        # set temperature to zero if temperature not given in kwargs
        if &#39;temperature&#39; not in kwargs.keys():
            kwargs[&#39;temperature&#39;] = 0
        # Start tool selection logic
        if ((len(self.enabled_tools) == 1) &amp; (self.enabled_tools[0] == &#39;direct_response&#39;)):
            return dict(name=&#39;direct_response&#39;)
        prompt_template = llm.core.prompt_template if prompt_template is None else prompt_template
        # check if the function metadata content is in the messages.
        if not any(self.function_metadata[&#39;content&#39;]  in content for content in list(map(lambda x: x[&#39;content&#39;], messages))):
            return dict(name=&#39;direct_response&#39;)
        original_prompt = prompt_template.create_custom_prompt_with_open_role(messages=messages, end_role=&#39;function_call&#39;)
        return self.structured_input_generation(raw_prompt=original_prompt, llm=llm, **kwargs)

    def tool_call_output(self, tool_input: Dict[str, Any], return_error: bool = False) -&gt; Optional[Dict[str, Any]]:
        &#34;&#34;&#34;Return the output of the function call along with the input ditionary.

        Args:
            tool_input (Dict[str, Any]): Inputs of the tool, including the name of the tool and the input arguments.
            return_error (bool, optional): Whether to return the error should the tool failed to execute. If False and the tool failed, None will be returned instead of the error message.

        Returns:
            Optional[Dict[str, Any]]: Dictionary containing the name of the function, the inputs, and the outputs. If None is returned, that means no tool is required and the llm should respond directly.
        &#34;&#34;&#34;
        import json
        from copy import deepcopy
        tool_inputs = deepcopy(tool_input)
        tool_name = tool_inputs[&#39;name&#39;]
        if tool_name == &#39;direct_response&#39;:
            return None
        inputs = tool_inputs.get(&#39;inputs&#39;, dict())
        tool = self.tool_map[tool_name]
        try:
            output = tool(**inputs)
        except Exception as e:
            if return_error:
                tool_inputs[&#39;error&#39;] = str(e)
                return tool_inputs
            else:
                return None
        # formatting output
        jsonable = True
        try:
            json.dumps(output)
        except:
            jsonable = False
        tool_inputs[&#39;output&#39;] = output if jsonable else str(output)
        return tool_inputs

    def turn_on_tools(self, tools: List[str]) -&gt; None:
        &#34;&#34;&#34;Enable the given list of tools.

        Args:
            tools (List[str]): List of tool names.
        &#34;&#34;&#34;
        for tool in tools:
            if tool in self.tool_names:
                self._enabled[tool] = True

    def turn_off_tools(self, tools: List[str]) -&gt; None:
        &#34;&#34;&#34;Disable the given list of tools.

        Args:
            tools (List[str]): List of tool names.
        &#34;&#34;&#34;
        for tool in tools:
            if ((tool in self.tool_names) &amp; (tool != &#39;direct_response&#39;)):
                self._enabled[tool] = False


                    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="llmflex.Tools.tool_utils.direct_response"><code class="name flex">
<span>def <span class="ident">direct_response</span></span>(<span>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Direct response without using any tools or functions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Response.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def direct_response() -&gt; str:
    &#34;&#34;&#34;Direct response without using any tools or functions.

    Returns:
        str: Response.
    &#34;&#34;&#34;
    # This is a placeholder function for function call when no tools or functions are required. 
    pass</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.gen_string"><code class="name flex">
<span>def <span class="ident">gen_string</span></span>(<span>llm: Type[<a title="llmflex.Models.Cores.base_core.BaseLLM" href="../Models/Cores/base_core.html#llmflex.Models.Cores.base_core.BaseLLM">BaseLLM</a>], prompt: str, double_quote: bool = True, max_gen: int = 5, **kwargs) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a valid string that can be wrapped between quotes safely. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>llm</code></strong> :&ensp;<code>Type[BaseLLM]</code></dt>
<dd>LLM for the string generation.</dd>
<dt><strong><code>prompt</code></strong> :&ensp;<code>str</code></dt>
<dd>Prompt for generating the string, should not include the open quote.</dd>
<dt><strong><code>double_quote</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to use double quote or not. The quote character will be added to the end of the original prompt. Defaults to True.</dd>
<dt><strong><code>max_gen</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>In the unlikely event of the LLM keep generating without being able to generate a valid string, this set the maximum of generation the LLM can go. Defaults to 5.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>A valid string that can be wrapped between quotes safely. If a valid string cannot be generated, an empty string will be returned.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_string(llm: Type[BaseLLM], prompt: str, double_quote: bool = True, max_gen: int = 5, **kwargs) -&gt; str:
    &#34;&#34;&#34;Generate a valid string that can be wrapped between quotes safely. 

    Args:
        llm (Type[BaseLLM]): LLM for the string generation.
        prompt (str): Prompt for generating the string, should not include the open quote.
        double_quote (bool, optional): Whether to use double quote or not. The quote character will be added to the end of the original prompt. Defaults to True.
        max_gen (int, optional): In the unlikely event of the LLM keep generating without being able to generate a valid string, this set the maximum of generation the LLM can go. Defaults to 5.

    Returns:
        str: A valid string that can be wrapped between quotes safely. If a valid string cannot be generated, an empty string will be returned.
    &#34;&#34;&#34;
    quote = &#39;&#34;&#39; if double_quote else &#34;&#39;&#34;
    original = prompt + quote
    text = quote
    not_string: bool = True
    count = 0
    while ((not_string) &amp; (count &lt; max_gen)):
        try:
            assert isinstance(eval(text), str)
            not_string = False
        except:
            new = llm.invoke(original, stop=[quote], **kwargs)
            text += new + quote
            original += new + quote
            count += 1
    if not not_string:
        return eval(text)
    else:
        return &#39;&#39;</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.get_args_descriptions"><code class="name flex">
<span>def <span class="ident">get_args_descriptions</span></span>(<span>docstring: str) ‑> Dict[str, str]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the description of the arguments of a function or tool given the docstring.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>docstring</code></strong> :&ensp;<code>str</code></dt>
<dd>Docstring of the callable.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, str]</code></dt>
<dd>Dictionary of the arguments and their descriptions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_args_descriptions(docstring: str) -&gt; Dict[str, str]:
    &#34;&#34;&#34;Get the description of the arguments of a function or tool given the docstring.

    Args:
        docstring (str): Docstring of the callable.

    Returns:
        Dict[str, str]: Dictionary of the arguments and their descriptions.
    &#34;&#34;&#34;
    blocks = [&#39;raises:&#39;, &#39;returns:&#39;]
    lines = map(lambda x: x.strip(), docstring.split(&#39;\n&#39;))
    lines = filter(lambda x: x != &#39;&#39;, lines)
    started = False
    args = dict()
    for line in lines:
        if line.lower() == &#39;args:&#39;:
            started = True
        elif line.lower() in blocks:
            started = False
        elif started:
            elements = line.split(&#39;:&#39;)
            if len(elements) &gt; 1:
                args[elements[0].split(&#39;(&#39;)[0].strip()] = &#39;:&#39;.join(elements[1:]).strip()
    return args</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.get_args_dtypes"><code class="name flex">
<span>def <span class="ident">get_args_dtypes</span></span>(<span>fn: Callable) ‑> Dict[str, Dict[str, Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the data types of the arguments of a function or tool given the callable.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fn</code></strong> :&ensp;<code>Callable</code></dt>
<dd>The function or the tool.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Dict[str, Any]]</code></dt>
<dd>Dictionary of the arguments and their data types and descriptions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_args_dtypes(fn: Callable) -&gt; Dict[str, Dict[str, Any]]:
    &#34;&#34;&#34;Get the data types of the arguments of a function or tool given the callable.

    Args:
        fn (Callable): The function or the tool.

    Returns:
        Dict[str, Dict[str, Any]]: Dictionary of the arguments and their data types and descriptions.
    &#34;&#34;&#34;
    annotations = inspect.getfullargspec(fn).annotations
    args_desc = get_args_descriptions(fn.__doc__) if fn.__doc__ is not None else dict()
    required = get_required_args(fn)
    signature = inspect.signature(fn)
    defaults = {
        k: v.default
        for k, v in signature.parameters.items()
        if v.default is not inspect.Parameter.empty
    }
    args = dict()
    for arg, arg_type in annotations.items():
        if arg in [&#39;return&#39;, &#39;cls&#39;, &#39;self&#39;]:
            continue

        if getattr(arg_type, &#39;__name__&#39;) in PYTHON_TO_JSON_TYPES.keys():
            args[arg] = dict(type=PYTHON_TO_JSON_TYPES[arg_type.__name__])
            if arg in args_desc:
                args[arg][&#39;description&#39;] = args_desc[arg]
            if arg not in required:
                args[arg][&#39;default&#39;] = defaults[arg]
        elif getattr(arg_type, &#39;__name__&#39;) == &#39;Literal&#39;:
            dtype = getattr(type(arg_type.__args__[0]), &#39;__name__&#39;)
            dtype = PYTHON_TO_JSON_TYPES.get(dtype, None)
            args[arg] = dict()
            if dtype is not None:
                args[arg][&#39;type&#39;] = dtype
                if arg in args_desc:
                    args[arg][&#39;description&#39;] = args_desc[arg]
                args[arg][&#39;enum&#39;] = list(arg_type.__args__)
                if arg not in required:
                    args[arg][&#39;default&#39;] = defaults[arg]
            else:
                args[arg][&#39;type&#39;] = getattr(arg_type, &#39;__name__&#39;, str(arg_type))
                if arg in args_desc:
                    args[arg][&#39;description&#39;] = args_desc[arg]
                args[arg][&#39;enum&#39;] = list(map(lambda x: str(x), arg_type.__args__))
                if arg not in required:
                    args[arg][&#39;default&#39;] = defaults[arg]
        elif getattr(arg_type, &#39;__name__&#39;) == &#39;Optional&#39;:
            dtype = getattr(arg_type.__args__[0], &#39;__name__&#39;)
            dtype = PYTHON_TO_JSON_TYPES.get(dtype, None)
            args[arg] = dict()
            if dtype is not None:
                args[arg][&#39;type&#39;] = dtype
            else:
                args[arg][&#39;type&#39;] = getattr(arg_type, &#39;__name__&#39;, str(arg_type))
            if arg in args_desc:
                args[arg][&#39;description&#39;] = args_desc[arg]
            if arg not in required:
                args[arg][&#39;default&#39;] = defaults[arg]
        else:
            args[arg] = dict()
            args[arg][&#39;type&#39;] = getattr(arg_type, &#39;__name__&#39;, str(arg_type))
            if arg in args_desc:
                args[arg][&#39;description&#39;] = args_desc[arg]
            if arg not in required:
                args[arg][&#39;default&#39;] = defaults[arg]
    return args</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.get_description"><code class="name flex">
<span>def <span class="ident">get_description</span></span>(<span>docstring: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function or tool description from the docstring.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>docstring</code></strong> :&ensp;<code>str</code></dt>
<dd>The docstring of the function or tool.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The description of the function or tool.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_description(docstring: str) -&gt; str:
    &#34;&#34;&#34;Get the function or tool description from the docstring.

    Args:
        docstring (str): The docstring of the function or tool.

    Returns:
        str: The description of the function or tool.
    &#34;&#34;&#34;
    blocks = [&#39;args:&#39;, &#39;raises:&#39;, &#39;returns:&#39;]
    lines = map(lambda x: x.strip(), docstring.split(&#39;\n&#39;))
    lines = filter(lambda x: x != &#39;&#39;, lines)
    descriptions = []
    for line in lines:
        if line.lower() in blocks:
            break
        else:
            descriptions.append(line)
    return &#39;\n&#39;.join(descriptions).strip()</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.get_required_args"><code class="name flex">
<span>def <span class="ident">get_required_args</span></span>(<span>fn: Callable) ‑> List[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the mandatory arguments of the given function.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fn</code></strong> :&ensp;<code>Callable</code></dt>
<dd>Function of interest.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[str]</code></dt>
<dd>List of mandatory arguments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_required_args(fn: Callable) -&gt; List[str]:
    &#34;&#34;&#34;Get the mandatory arguments of the given function.

    Args:
        fn (Callable): Function of interest.

    Returns:
        List[str]: List of mandatory arguments.
    &#34;&#34;&#34;
    specs = inspect.getfullargspec(fn)
    args = specs.args
    if specs.defaults:
        args = args[:-len(specs.defaults)]
    args = list(filter(lambda x: x not in [&#39;cls&#39;, &#39;self&#39;], args))
    return args</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.get_tool_metadata"><code class="name flex">
<span>def <span class="ident">get_tool_metadata</span></span>(<span>fn: Union[Callable, Type[<a title="llmflex.Tools.tool_utils.BaseTool" href="#llmflex.Tools.tool_utils.BaseTool">BaseTool</a>]]) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the tool metadata as a dictionary.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fn</code></strong> :&ensp;<code>Union[Callable, Type[<a title="llmflex.Tools.tool_utils.BaseTool" href="#llmflex.Tools.tool_utils.BaseTool">BaseTool</a>]]</code></dt>
<dd>Tool or python function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Any]</code></dt>
<dd>Metadata of the tool or function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_tool_metadata(fn: Union[Callable, Type[BaseTool]]) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Get the tool metadata as a dictionary.

    Args:
        fn (Union[Callable, Type[BaseTool]]): Tool or python function.

    Returns:
        Dict[str, Any]: Metadata of the tool or function.
    &#34;&#34;&#34;
    is_tool = isinstance(fn, BaseTool)
    desc_doc = fn.description if isinstance(fn, BaseTool) else getattr(fn, &#39;__doc__&#39;)
    if is_tool:
        name = fn.name
        description = desc_doc
        required = get_required_args(fn.__call__)
        args = get_args_dtypes(fn.__call__)
    else:
        name = normalise_tool_name(fn.__name__)
        description = get_description(desc_doc) if desc_doc else &#39;&#39;
        required = get_required_args(fn)
        args = get_args_dtypes(fn)
    return dict(name=name, description=description, parameters=dict(type=&#39;object&#39;, properties=args, required=required))</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.normalise_tool_name"><code class="name flex">
<span>def <span class="ident">normalise_tool_name</span></span>(<span>name: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Make the tool name in lower case and split it with "_".</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Original name of the tool.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Normalised tool name.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalise_tool_name(name: str) -&gt; str:
    &#34;&#34;&#34;Make the tool name in lower case and split it with &#34;_&#34;.

    Args:
        name (str): Original name of the tool.

    Returns:
        str: Normalised tool name.
    &#34;&#34;&#34;
    import re
    tokens = re.sub( r&#34;([A-Z])&#34;, r&#34; \1&#34;, name).split()
    tokens = list(map(lambda x: x.lower().strip(&#39; \n\r\t_&#39;), tokens))
    return &#39;_&#39;.join(tokens).strip()</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.select"><code class="name flex">
<span>def <span class="ident">select</span></span>(<span>llm: Type[<a title="llmflex.Models.Cores.base_core.BaseLLM" href="../Models/Cores/base_core.html#llmflex.Models.Cores.base_core.BaseLLM">BaseLLM</a>], prompt: str, options: List[str], stop: Optional[List[str]] = None, default: Optional[str] = None, retry: int = 3, raise_error: bool = False, **kwargs) ‑> Optional[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Ask the LLM to make a selection of the list of options provided.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>llm</code></strong> :&ensp;<code>Type[BaseLLM]</code></dt>
<dd>LLM to generate the selection.</dd>
<dt><strong><code>prompt</code></strong> :&ensp;<code>str</code></dt>
<dd>Prompt for the llm.</dd>
<dt><strong><code>options</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>List of options for the LLM to pick.</dd>
<dt><strong><code>stop</code></strong> :&ensp;<code>Optional[List[str]], None</code></dt>
<dd>List of stop words for the LLM to help the llm stop earlier. Defaults to None.</dd>
<dt><strong><code>default</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Default value if the LLM fails to generate the option. If none is given and the LLM fail, an error will be raised. Defaults to None.</dd>
<dt><strong><code>retry</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of times the llm can retry. Defaults to 3.</dd>
<dt><strong><code>raise_error</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to raise an error if the selection failed. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Optional[str]</code></dt>
<dd>The selection of the LLM given the options.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select(llm: Type[BaseLLM], prompt: str, options: List[str], 
           stop: Optional[List[str]] = None, default: Optional[str] = None, retry: int = 3, raise_error: bool = False, **kwargs) -&gt; Optional[str]:
    &#34;&#34;&#34;Ask the LLM to make a selection of the list of options provided.

    Args:
        llm (Type[BaseLLM]): LLM to generate the selection.
        prompt (str): Prompt for the llm.
        options (List[str]): List of options for the LLM to pick.
        stop (Optional[List[str]], None): List of stop words for the LLM to help the llm stop earlier. Defaults to None.
        default (Optional[str], optional): Default value if the LLM fails to generate the option. If none is given and the LLM fail, an error will be raised. Defaults to None.
        retry (int, optional): Number of times the llm can retry. Defaults to 3.
        raise_error (bool, optional): Whether to raise an error if the selection failed. Defaults to False.

    Returns:
        Optional[str]: The selection of the LLM given the options.
    &#34;&#34;&#34;
    if len(options) == 0:
        raise ValueError(&#39;&#34;options&#34; must contain at least one string.&#39;)
    if llm.core.core_type ==&#39;llama_cpp_core&#39;:
        from guidance.models.llama_cpp import LlamaCpp
        from guidance import select as gselect
        gllm = LlamaCpp(model=llm.core.model, echo=False)
        res = gllm + prompt + gselect(options=options)
        res = str(res).removeprefix(prompt)
        del gllm
        return res
    else:
        from math import ceil
        from copy import deepcopy
        option_num_tokens = [llm.get_num_tokens(opt) for opt in options]
        max_new_tokens = ceil(max(option_num_tokens) * 1.2)
        stop = [] if stop is None else stop
        for i in range(retry):
            clone_kw = deepcopy(kwargs)
            clone_kw.pop(&#39;max_new_tokens&#39;, None)
            res = llm.invoke(prompt, stop=stop, max_new_tokens=max_new_tokens, **clone_kw)
            if res in options:
                return res
            else:
                valids = list(filter(lambda x: res.startswith(x), options))
                if len(valids) &gt;= 1:
                    return max(valids, key=len)
        if default is not None:
            return default
        elif raise_error:
            raise RuntimeError(f&#39;LLM cannot generate one of the options after {retry} retries.&#39;)
        else:
            return None</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="llmflex.Tools.tool_utils.BaseTool"><code class="flex name class">
<span>class <span class="ident">BaseTool</span></span>
<span>(</span><span>name: Optional[str] = None, description: Optional[str] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for tools.</p>
<p>Initialising the tool.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Name of the tool. If not given, it will be the tool class name. Defaults to None.</dd>
<dt><strong><code>description</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Description of the tool. If not given, it will read from the docstring of the tool class. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseTool:
    &#34;&#34;&#34;Base class for tools.
    &#34;&#34;&#34;
    def __init__(self, name: Optional[str] = None, description: Optional[str] = None) -&gt; None:
        &#34;&#34;&#34;Initialising the tool.

        Args:
            name (Optional[str], optional): Name of the tool. If not given, it will be the tool class name. Defaults to None.
            description (Optional[str], optional): Description of the tool. If not given, it will read from the docstring of the tool class. Defaults to None.
        &#34;&#34;&#34;
        from ..utils import validate_type
        self._name = normalise_tool_name(validate_type(name.strip(), str)) if name is not None else normalise_tool_name(self.__class__.__name__)
        self._description = validate_type(description.strip(), str) if description is not None else get_description(self.__doc__) if self.__doc__ else &#39;&#39;

    @property
    def name(self) -&gt; str:
        &#34;&#34;&#34;Name of the tool.

        Returns:
            str: Name of the tool.
        &#34;&#34;&#34;
        return self._name
    
    @property
    def description(self) -&gt; str:
        &#34;&#34;&#34;Description of the tool.

        Returns:
            str: Description of the tool.
        &#34;&#34;&#34;
        return self._description
    
    def __call__(self, **kwargs) -&gt; Any:
        &#34;&#34;&#34;The main function of the tool.

        Returns:
            Any: Output of the tool.
        &#34;&#34;&#34;
        pass</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="llmflex.Tools.browser_tool.BrowserTool" href="browser_tool.html#llmflex.Tools.browser_tool.BrowserTool">BrowserTool</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="llmflex.Tools.tool_utils.BaseTool.description"><code class="name">var <span class="ident">description</span> : str</code></dt>
<dd>
<div class="desc"><p>Description of the tool.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Description of the tool.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def description(self) -&gt; str:
    &#34;&#34;&#34;Description of the tool.

    Returns:
        str: Description of the tool.
    &#34;&#34;&#34;
    return self._description</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.BaseTool.name"><code class="name">var <span class="ident">name</span> : str</code></dt>
<dd>
<div class="desc"><p>Name of the tool.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Name of the tool.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def name(self) -&gt; str:
    &#34;&#34;&#34;Name of the tool.

    Returns:
        str: Name of the tool.
    &#34;&#34;&#34;
    return self._name</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector"><code class="flex name class">
<span>class <span class="ident">ToolSelector</span></span>
<span>(</span><span>tools: List[Union[Callable, Type[<a title="llmflex.Tools.tool_utils.BaseTool" href="#llmflex.Tools.tool_utils.BaseTool">BaseTool</a>]]])</span>
</code></dt>
<dd>
<div class="desc"><p>Class for selecting tool.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ToolSelector:
    &#34;&#34;&#34;Class for selecting tool.
    &#34;&#34;&#34;
    def __init__(self, tools: List[Union[Callable, Type[BaseTool]]]) -&gt; None:
        self._tools = tools if direct_response in tools else tools + [direct_response]
        self._metadatas = [get_tool_metadata(tool) for tool in self.tools]
        self._tool_names: List[str] = [m[&#39;name&#39;] for m in self._metadatas]
        self._enabled = dict(zip(self._tool_names, [True] * len(self._tool_names)))
    
    @property
    def tool_names(self) -&gt; List[str]:
        &#34;&#34;&#34;List of tool names.

        Returns:
            List[str]: List of tool names.
        &#34;&#34;&#34;
        return self._tool_names
    
    @property
    def enabled_tools(self) -&gt; List[str]:
        &#34;&#34;&#34;List of tool names that are enabled.

        Returns:
            List[str]: List of tool names that are enabled.
        &#34;&#34;&#34;
        enabled_tools = filter(lambda x: x[1], self._enabled.items())
        return list(map(lambda x: x[0], enabled_tools))
    
    @property
    def num_tools(self) -&gt; int:
        &#34;&#34;&#34;Number of enabled tools.

        Returns:
            int: Number of enabled tools.
        &#34;&#34;&#34;
        return len(self.enabled_tools)
    
    @property
    def tools(self) -&gt; List[Union[Callable, Type[BaseTool]]]:
        &#34;&#34;&#34;List of available tools.

        Returns:
            List[Union[Callable, Type[BaseTool]]]: List of available tools.
        &#34;&#34;&#34;
        return self._tools

    @property
    def metadatas(self) -&gt; List[Dict[str, Any]]:
        &#34;&#34;&#34;List of metadatas of tools.

        Returns:
            List[Dict[str, Any]]: List of metadatas of tools.
        &#34;&#34;&#34;
        return list(filter(lambda x: x[&#39;name&#39;] in self.enabled_tools, self._metadatas))
    
    @property
    def tool_map(self) -&gt; Dict[str, Union[Callable, Type[BaseTool]]]:
        &#34;&#34;&#34;Map of tool names and the tools.

        Returns:
            Dict[str, Union[Callable, Type[BaseTool]]]: Map of tool names and the tools.
        &#34;&#34;&#34;
        if not hasattr(self, &#39;_tool_map&#39;):
            names = [m[&#39;name&#39;] for m in self.metadatas]
            self._tool_map = dict(zip(names, self.tools))
        return {k: self._tool_map[k] for k in self.enabled_tools}
    
    @property
    def function_metadata(self) -&gt; Dict[str, str]:
        &#34;&#34;&#34;A message with the role &#34;function_metadata&#34; and content being the metadata of the tools.

        Returns:
            Dict[str, str]: A message with the role &#34;function_metadata&#34; and content being the metadata of the tools.
        &#34;&#34;&#34;
        import json
        return dict(role=&#39;function_metadata&#39;, content=json.dumps(self.metadatas, indent=4))
        
    @property
    def is_empty(self) -&gt; bool:
        &#34;&#34;&#34;Whether tools except direct_response are enabled.

        Returns:
            bool: Whether tools except direct_response are enabled.
        &#34;&#34;&#34;
        return ((len(self.enabled_tools) == 1) &amp; (&#39;direct_response&#39; in self.enabled_tools))

    def get_tool_metadata(self, tool_name: str) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Get the tool metadata given the tool name.

        Args:
            tool_name (str): Tool name.

        Returns:
            Dict[str, Any]: Metadata of the tool.
        &#34;&#34;&#34;
        return list(filter(lambda x: x[&#39;name&#39;] == tool_name, self.metadatas))[0]
    
    def structured_input_generation(self, raw_prompt: str, llm: Type[BaseLLM], **kwargs) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Core part of tool input generation.

        Args:
            raw_prompt (str): The starting prompt.
            llm (Type[BaseLLM]): LLM for generation.

        Returns:
            Dict[str, Any]: Dictionary containing the name of the function and the input arguments.
        &#34;&#34;&#34;
        import json
        original_prompt = raw_prompt
        prompt: str = original_prompt + &#39;{\n\t&#34;name&#34;: &#34;&#39;
        tool_name = select(llm=llm, prompt=prompt, options=self.enabled_tools, default=&#39;direct_response&#39;, **kwargs)
        tool = self.get_tool_metadata(tool_name=tool_name)

        # gather tool info
        args_info = tool[&#39;parameters&#39;][&#39;properties&#39;]
        args = list(args_info.keys())
        required_args = tool[&#39;parameters&#39;][&#39;required&#39;]
        optional_args = list(filter(lambda x: x not in required_args, args))

        prompt += tool_name + &#39;&#34;&#39;
        if len(args) == 0:
            prompt += &#39;\n}&#39;
        else:
            prompt += &#39;,\n\t&#34;inputs&#34;: {&#39;
            if len(required_args) != 0:
                for arg in required_args:
                    prompt += f&#39;\n\t\t&#34;{arg}&#34;: &#39;
                    enum = args_info[arg].get(&#39;enum&#39;)
                    if args_info[arg].get(&#39;type&#39;) == &#39;string&#39;:
                        if enum is None:
                            val = gen_string(llm=llm, prompt=prompt, **kwargs)
                            prompt += &#39;&#34;&#39; + val + &#39;&#34;,&#39;
                        else:
                            val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                            if val is not None:
                                prompt +=  f&#39;&#34;{val}&#34;&#39; + &#39;,&#39;
                            else:
                                return dict(name=&#39;direct_response&#39;)
                    elif enum is None:
                        prompt += llm.invoke(prompt, stop=[&#39;\n\t&#39;], **kwargs)
                    else:
                        val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                        if val is not None:
                            prompt += val + &#39;,&#39;
                        else:
                            return dict(name=&#39;direct_response&#39;)
                prompt = prompt.rstrip(&#39;,&#39;) # strip off the comma, see if the llm wants to continue on optional arguments
                if len(optional_args) &gt; 0:
                    from copy import deepcopy
                    clone_kw = deepcopy(kwargs)
                    clone_kw.pop(&#39;max_new_tokens&#39;, None)
                    new_tokens = llm.invoke(prompt, max_new_tokens=3, **clone_kw)
                    used_args = []
                    while ((new_tokens.startswith(&#39;,&#39;)) &amp; (len(used_args) &lt; len(optional_args))):
                        prompt += &#39;,\n\t\t&#34;&#39;
                        arg = select(llm=llm, prompt=prompt, options=list(filter(lambda x: x not in used_args, optional_args)), stop=[&#39;&#34;&#39;], **kwargs)
                        if arg is None:
                            prompt = prompt.removesuffix(&#39;,\n\t\t&#34;&#39;)
                            new_tokens = &#39;&#39;
                        else:
                            prompt += arg + &#39;&#34;: &#39;
                            enum = args_info[arg].get(&#39;enum&#39;)
                            default = args_info[arg].get(&#39;default&#39;)
                            default = &#39;null&#39; if default is None else default
                            if args_info[arg].get(&#39;type&#39;) == &#39;string&#39;:
                                if enum is None:
                                    val = gen_string(llm=llm, prompt=prompt, **kwargs)
                                    val = default if val == &#39;&#39; else f&#39;&#34;{val}&#34;&#39;
                                    prompt += val
                                else:
                                    val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                                    val = default if val is None else f&#39;&#34;{val}&#34;&#39;
                                    prompt += val
                            elif enum is None:
                                prompt += llm.invoke(prompt, stop=[&#39;\n\t&#39;], **kwargs)
                                prompt = prompt.strip(&#39;, \n\r\t&#39;)
                            else:
                                val = select(llm, prompt=prompt, options=enum, **kwargs)
                                val = default if val is None else val
                                prompt += val
                            clone_kw = deepcopy(kwargs)
                            clone_kw.pop(&#39;max_new_tokens&#39;, None)
                            new_tokens = llm.invoke(prompt, max_new_tokens=3, **clone_kw)
            prompt += &#39;\n\t}\n}&#39;
        try:
            return json.loads(prompt.removeprefix(original_prompt))
        except:
            return dict(name=&#39;direct_response&#39;)
    
    def tool_call_input(self, llm: Type[BaseLLM], messages: List[Dict[str, str]], prompt_template: Optional[PromptTemplate] = None, **kwargs) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Generate a dictionary of the tool to use and the input arguments.

        Args:
            llm (Type[BaseLLM]): LLM for the function call generation.
            messages (List[Dict[str, str]]): List of messages of the conversation history, msut contain the function metadatas.
            prompt_template (Optional[PromptTemplate], optional): Prompt template to use. If none is give, the default prompt template for the llm will be used. Defaults to None.

        Returns:
            Dict[str, Any]: Dictionary containing the name of the function and the input arguments.
        &#34;&#34;&#34;
        # set temperature to zero if temperature not given in kwargs
        if &#39;temperature&#39; not in kwargs.keys():
            kwargs[&#39;temperature&#39;] = 0
        # Start tool selection logic
        if ((len(self.enabled_tools) == 1) &amp; (self.enabled_tools[0] == &#39;direct_response&#39;)):
            return dict(name=&#39;direct_response&#39;)
        prompt_template = llm.core.prompt_template if prompt_template is None else prompt_template
        # check if the function metadata content is in the messages.
        if not any(self.function_metadata[&#39;content&#39;]  in content for content in list(map(lambda x: x[&#39;content&#39;], messages))):
            return dict(name=&#39;direct_response&#39;)
        original_prompt = prompt_template.create_custom_prompt_with_open_role(messages=messages, end_role=&#39;function_call&#39;)
        return self.structured_input_generation(raw_prompt=original_prompt, llm=llm, **kwargs)

    def tool_call_output(self, tool_input: Dict[str, Any], return_error: bool = False) -&gt; Optional[Dict[str, Any]]:
        &#34;&#34;&#34;Return the output of the function call along with the input ditionary.

        Args:
            tool_input (Dict[str, Any]): Inputs of the tool, including the name of the tool and the input arguments.
            return_error (bool, optional): Whether to return the error should the tool failed to execute. If False and the tool failed, None will be returned instead of the error message.

        Returns:
            Optional[Dict[str, Any]]: Dictionary containing the name of the function, the inputs, and the outputs. If None is returned, that means no tool is required and the llm should respond directly.
        &#34;&#34;&#34;
        import json
        from copy import deepcopy
        tool_inputs = deepcopy(tool_input)
        tool_name = tool_inputs[&#39;name&#39;]
        if tool_name == &#39;direct_response&#39;:
            return None
        inputs = tool_inputs.get(&#39;inputs&#39;, dict())
        tool = self.tool_map[tool_name]
        try:
            output = tool(**inputs)
        except Exception as e:
            if return_error:
                tool_inputs[&#39;error&#39;] = str(e)
                return tool_inputs
            else:
                return None
        # formatting output
        jsonable = True
        try:
            json.dumps(output)
        except:
            jsonable = False
        tool_inputs[&#39;output&#39;] = output if jsonable else str(output)
        return tool_inputs

    def turn_on_tools(self, tools: List[str]) -&gt; None:
        &#34;&#34;&#34;Enable the given list of tools.

        Args:
            tools (List[str]): List of tool names.
        &#34;&#34;&#34;
        for tool in tools:
            if tool in self.tool_names:
                self._enabled[tool] = True

    def turn_off_tools(self, tools: List[str]) -&gt; None:
        &#34;&#34;&#34;Disable the given list of tools.

        Args:
            tools (List[str]): List of tool names.
        &#34;&#34;&#34;
        for tool in tools:
            if ((tool in self.tool_names) &amp; (tool != &#39;direct_response&#39;)):
                self._enabled[tool] = False</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="llmflex.Tools.tool_utils.ToolSelector.enabled_tools"><code class="name">var <span class="ident">enabled_tools</span> : List[str]</code></dt>
<dd>
<div class="desc"><p>List of tool names that are enabled.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[str]</code></dt>
<dd>List of tool names that are enabled.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def enabled_tools(self) -&gt; List[str]:
    &#34;&#34;&#34;List of tool names that are enabled.

    Returns:
        List[str]: List of tool names that are enabled.
    &#34;&#34;&#34;
    enabled_tools = filter(lambda x: x[1], self._enabled.items())
    return list(map(lambda x: x[0], enabled_tools))</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.function_metadata"><code class="name">var <span class="ident">function_metadata</span> : Dict[str, str]</code></dt>
<dd>
<div class="desc"><p>A message with the role "function_metadata" and content being the metadata of the tools.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, str]</code></dt>
<dd>A message with the role "function_metadata" and content being the metadata of the tools.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def function_metadata(self) -&gt; Dict[str, str]:
    &#34;&#34;&#34;A message with the role &#34;function_metadata&#34; and content being the metadata of the tools.

    Returns:
        Dict[str, str]: A message with the role &#34;function_metadata&#34; and content being the metadata of the tools.
    &#34;&#34;&#34;
    import json
    return dict(role=&#39;function_metadata&#39;, content=json.dumps(self.metadatas, indent=4))</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.is_empty"><code class="name">var <span class="ident">is_empty</span> : bool</code></dt>
<dd>
<div class="desc"><p>Whether tools except direct_response are enabled.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether tools except direct_response are enabled.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def is_empty(self) -&gt; bool:
    &#34;&#34;&#34;Whether tools except direct_response are enabled.

    Returns:
        bool: Whether tools except direct_response are enabled.
    &#34;&#34;&#34;
    return ((len(self.enabled_tools) == 1) &amp; (&#39;direct_response&#39; in self.enabled_tools))</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.metadatas"><code class="name">var <span class="ident">metadatas</span> : List[Dict[str, Any]]</code></dt>
<dd>
<div class="desc"><p>List of metadatas of tools.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Dict[str, Any]]</code></dt>
<dd>List of metadatas of tools.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def metadatas(self) -&gt; List[Dict[str, Any]]:
    &#34;&#34;&#34;List of metadatas of tools.

    Returns:
        List[Dict[str, Any]]: List of metadatas of tools.
    &#34;&#34;&#34;
    return list(filter(lambda x: x[&#39;name&#39;] in self.enabled_tools, self._metadatas))</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.num_tools"><code class="name">var <span class="ident">num_tools</span> : int</code></dt>
<dd>
<div class="desc"><p>Number of enabled tools.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of enabled tools.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def num_tools(self) -&gt; int:
    &#34;&#34;&#34;Number of enabled tools.

    Returns:
        int: Number of enabled tools.
    &#34;&#34;&#34;
    return len(self.enabled_tools)</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.tool_map"><code class="name">var <span class="ident">tool_map</span> : Dict[str, Union[Callable, Type[<a title="llmflex.Tools.tool_utils.BaseTool" href="#llmflex.Tools.tool_utils.BaseTool">BaseTool</a>]]]</code></dt>
<dd>
<div class="desc"><p>Map of tool names and the tools.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Union[Callable, Type[<a title="llmflex.Tools.tool_utils.BaseTool" href="#llmflex.Tools.tool_utils.BaseTool">BaseTool</a>]]]</code></dt>
<dd>Map of tool names and the tools.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def tool_map(self) -&gt; Dict[str, Union[Callable, Type[BaseTool]]]:
    &#34;&#34;&#34;Map of tool names and the tools.

    Returns:
        Dict[str, Union[Callable, Type[BaseTool]]]: Map of tool names and the tools.
    &#34;&#34;&#34;
    if not hasattr(self, &#39;_tool_map&#39;):
        names = [m[&#39;name&#39;] for m in self.metadatas]
        self._tool_map = dict(zip(names, self.tools))
    return {k: self._tool_map[k] for k in self.enabled_tools}</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.tool_names"><code class="name">var <span class="ident">tool_names</span> : List[str]</code></dt>
<dd>
<div class="desc"><p>List of tool names.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[str]</code></dt>
<dd>List of tool names.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def tool_names(self) -&gt; List[str]:
    &#34;&#34;&#34;List of tool names.

    Returns:
        List[str]: List of tool names.
    &#34;&#34;&#34;
    return self._tool_names</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.tools"><code class="name">var <span class="ident">tools</span> : List[Union[Callable, Type[<a title="llmflex.Tools.tool_utils.BaseTool" href="#llmflex.Tools.tool_utils.BaseTool">BaseTool</a>]]]</code></dt>
<dd>
<div class="desc"><p>List of available tools.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Union[Callable, Type[<a title="llmflex.Tools.tool_utils.BaseTool" href="#llmflex.Tools.tool_utils.BaseTool">BaseTool</a>]]]</code></dt>
<dd>List of available tools.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def tools(self) -&gt; List[Union[Callable, Type[BaseTool]]]:
    &#34;&#34;&#34;List of available tools.

    Returns:
        List[Union[Callable, Type[BaseTool]]]: List of available tools.
    &#34;&#34;&#34;
    return self._tools</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="llmflex.Tools.tool_utils.ToolSelector.get_tool_metadata"><code class="name flex">
<span>def <span class="ident">get_tool_metadata</span></span>(<span>self, tool_name: str) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the tool metadata given the tool name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tool_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Tool name.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Any]</code></dt>
<dd>Metadata of the tool.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_tool_metadata(self, tool_name: str) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Get the tool metadata given the tool name.

    Args:
        tool_name (str): Tool name.

    Returns:
        Dict[str, Any]: Metadata of the tool.
    &#34;&#34;&#34;
    return list(filter(lambda x: x[&#39;name&#39;] == tool_name, self.metadatas))[0]</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.structured_input_generation"><code class="name flex">
<span>def <span class="ident">structured_input_generation</span></span>(<span>self, raw_prompt: str, llm: Type[<a title="llmflex.Models.Cores.base_core.BaseLLM" href="../Models/Cores/base_core.html#llmflex.Models.Cores.base_core.BaseLLM">BaseLLM</a>], **kwargs) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Core part of tool input generation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>raw_prompt</code></strong> :&ensp;<code>str</code></dt>
<dd>The starting prompt.</dd>
<dt><strong><code>llm</code></strong> :&ensp;<code>Type[BaseLLM]</code></dt>
<dd>LLM for generation.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Any]</code></dt>
<dd>Dictionary containing the name of the function and the input arguments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def structured_input_generation(self, raw_prompt: str, llm: Type[BaseLLM], **kwargs) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Core part of tool input generation.

    Args:
        raw_prompt (str): The starting prompt.
        llm (Type[BaseLLM]): LLM for generation.

    Returns:
        Dict[str, Any]: Dictionary containing the name of the function and the input arguments.
    &#34;&#34;&#34;
    import json
    original_prompt = raw_prompt
    prompt: str = original_prompt + &#39;{\n\t&#34;name&#34;: &#34;&#39;
    tool_name = select(llm=llm, prompt=prompt, options=self.enabled_tools, default=&#39;direct_response&#39;, **kwargs)
    tool = self.get_tool_metadata(tool_name=tool_name)

    # gather tool info
    args_info = tool[&#39;parameters&#39;][&#39;properties&#39;]
    args = list(args_info.keys())
    required_args = tool[&#39;parameters&#39;][&#39;required&#39;]
    optional_args = list(filter(lambda x: x not in required_args, args))

    prompt += tool_name + &#39;&#34;&#39;
    if len(args) == 0:
        prompt += &#39;\n}&#39;
    else:
        prompt += &#39;,\n\t&#34;inputs&#34;: {&#39;
        if len(required_args) != 0:
            for arg in required_args:
                prompt += f&#39;\n\t\t&#34;{arg}&#34;: &#39;
                enum = args_info[arg].get(&#39;enum&#39;)
                if args_info[arg].get(&#39;type&#39;) == &#39;string&#39;:
                    if enum is None:
                        val = gen_string(llm=llm, prompt=prompt, **kwargs)
                        prompt += &#39;&#34;&#39; + val + &#39;&#34;,&#39;
                    else:
                        val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                        if val is not None:
                            prompt +=  f&#39;&#34;{val}&#34;&#39; + &#39;,&#39;
                        else:
                            return dict(name=&#39;direct_response&#39;)
                elif enum is None:
                    prompt += llm.invoke(prompt, stop=[&#39;\n\t&#39;], **kwargs)
                else:
                    val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                    if val is not None:
                        prompt += val + &#39;,&#39;
                    else:
                        return dict(name=&#39;direct_response&#39;)
            prompt = prompt.rstrip(&#39;,&#39;) # strip off the comma, see if the llm wants to continue on optional arguments
            if len(optional_args) &gt; 0:
                from copy import deepcopy
                clone_kw = deepcopy(kwargs)
                clone_kw.pop(&#39;max_new_tokens&#39;, None)
                new_tokens = llm.invoke(prompt, max_new_tokens=3, **clone_kw)
                used_args = []
                while ((new_tokens.startswith(&#39;,&#39;)) &amp; (len(used_args) &lt; len(optional_args))):
                    prompt += &#39;,\n\t\t&#34;&#39;
                    arg = select(llm=llm, prompt=prompt, options=list(filter(lambda x: x not in used_args, optional_args)), stop=[&#39;&#34;&#39;], **kwargs)
                    if arg is None:
                        prompt = prompt.removesuffix(&#39;,\n\t\t&#34;&#39;)
                        new_tokens = &#39;&#39;
                    else:
                        prompt += arg + &#39;&#34;: &#39;
                        enum = args_info[arg].get(&#39;enum&#39;)
                        default = args_info[arg].get(&#39;default&#39;)
                        default = &#39;null&#39; if default is None else default
                        if args_info[arg].get(&#39;type&#39;) == &#39;string&#39;:
                            if enum is None:
                                val = gen_string(llm=llm, prompt=prompt, **kwargs)
                                val = default if val == &#39;&#39; else f&#39;&#34;{val}&#34;&#39;
                                prompt += val
                            else:
                                val = select(llm, prompt=prompt + &#39;&#34;&#39;, options=enum, **kwargs)
                                val = default if val is None else f&#39;&#34;{val}&#34;&#39;
                                prompt += val
                        elif enum is None:
                            prompt += llm.invoke(prompt, stop=[&#39;\n\t&#39;], **kwargs)
                            prompt = prompt.strip(&#39;, \n\r\t&#39;)
                        else:
                            val = select(llm, prompt=prompt, options=enum, **kwargs)
                            val = default if val is None else val
                            prompt += val
                        clone_kw = deepcopy(kwargs)
                        clone_kw.pop(&#39;max_new_tokens&#39;, None)
                        new_tokens = llm.invoke(prompt, max_new_tokens=3, **clone_kw)
        prompt += &#39;\n\t}\n}&#39;
    try:
        return json.loads(prompt.removeprefix(original_prompt))
    except:
        return dict(name=&#39;direct_response&#39;)</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.tool_call_input"><code class="name flex">
<span>def <span class="ident">tool_call_input</span></span>(<span>self, llm: Type[<a title="llmflex.Models.Cores.base_core.BaseLLM" href="../Models/Cores/base_core.html#llmflex.Models.Cores.base_core.BaseLLM">BaseLLM</a>], messages: List[Dict[str, str]], prompt_template: Optional[<a title="llmflex.Prompts.prompt_template.PromptTemplate" href="../Prompts/prompt_template.html#llmflex.Prompts.prompt_template.PromptTemplate">PromptTemplate</a>] = None, **kwargs) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a dictionary of the tool to use and the input arguments.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>llm</code></strong> :&ensp;<code>Type[BaseLLM]</code></dt>
<dd>LLM for the function call generation.</dd>
<dt><strong><code>messages</code></strong> :&ensp;<code>List[Dict[str, str]]</code></dt>
<dd>List of messages of the conversation history, msut contain the function metadatas.</dd>
<dt><strong><code>prompt_template</code></strong> :&ensp;<code>Optional[PromptTemplate]</code>, optional</dt>
<dd>Prompt template to use. If none is give, the default prompt template for the llm will be used. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Any]</code></dt>
<dd>Dictionary containing the name of the function and the input arguments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tool_call_input(self, llm: Type[BaseLLM], messages: List[Dict[str, str]], prompt_template: Optional[PromptTemplate] = None, **kwargs) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Generate a dictionary of the tool to use and the input arguments.

    Args:
        llm (Type[BaseLLM]): LLM for the function call generation.
        messages (List[Dict[str, str]]): List of messages of the conversation history, msut contain the function metadatas.
        prompt_template (Optional[PromptTemplate], optional): Prompt template to use. If none is give, the default prompt template for the llm will be used. Defaults to None.

    Returns:
        Dict[str, Any]: Dictionary containing the name of the function and the input arguments.
    &#34;&#34;&#34;
    # set temperature to zero if temperature not given in kwargs
    if &#39;temperature&#39; not in kwargs.keys():
        kwargs[&#39;temperature&#39;] = 0
    # Start tool selection logic
    if ((len(self.enabled_tools) == 1) &amp; (self.enabled_tools[0] == &#39;direct_response&#39;)):
        return dict(name=&#39;direct_response&#39;)
    prompt_template = llm.core.prompt_template if prompt_template is None else prompt_template
    # check if the function metadata content is in the messages.
    if not any(self.function_metadata[&#39;content&#39;]  in content for content in list(map(lambda x: x[&#39;content&#39;], messages))):
        return dict(name=&#39;direct_response&#39;)
    original_prompt = prompt_template.create_custom_prompt_with_open_role(messages=messages, end_role=&#39;function_call&#39;)
    return self.structured_input_generation(raw_prompt=original_prompt, llm=llm, **kwargs)</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.tool_call_output"><code class="name flex">
<span>def <span class="ident">tool_call_output</span></span>(<span>self, tool_input: Dict[str, Any], return_error: bool = False) ‑> Optional[Dict[str, Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Return the output of the function call along with the input ditionary.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tool_input</code></strong> :&ensp;<code>Dict[str, Any]</code></dt>
<dd>Inputs of the tool, including the name of the tool and the input arguments.</dd>
<dt><strong><code>return_error</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to return the error should the tool failed to execute. If False and the tool failed, None will be returned instead of the error message.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Optional[Dict[str, Any]]</code></dt>
<dd>Dictionary containing the name of the function, the inputs, and the outputs. If None is returned, that means no tool is required and the llm should respond directly.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tool_call_output(self, tool_input: Dict[str, Any], return_error: bool = False) -&gt; Optional[Dict[str, Any]]:
    &#34;&#34;&#34;Return the output of the function call along with the input ditionary.

    Args:
        tool_input (Dict[str, Any]): Inputs of the tool, including the name of the tool and the input arguments.
        return_error (bool, optional): Whether to return the error should the tool failed to execute. If False and the tool failed, None will be returned instead of the error message.

    Returns:
        Optional[Dict[str, Any]]: Dictionary containing the name of the function, the inputs, and the outputs. If None is returned, that means no tool is required and the llm should respond directly.
    &#34;&#34;&#34;
    import json
    from copy import deepcopy
    tool_inputs = deepcopy(tool_input)
    tool_name = tool_inputs[&#39;name&#39;]
    if tool_name == &#39;direct_response&#39;:
        return None
    inputs = tool_inputs.get(&#39;inputs&#39;, dict())
    tool = self.tool_map[tool_name]
    try:
        output = tool(**inputs)
    except Exception as e:
        if return_error:
            tool_inputs[&#39;error&#39;] = str(e)
            return tool_inputs
        else:
            return None
    # formatting output
    jsonable = True
    try:
        json.dumps(output)
    except:
        jsonable = False
    tool_inputs[&#39;output&#39;] = output if jsonable else str(output)
    return tool_inputs</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.turn_off_tools"><code class="name flex">
<span>def <span class="ident">turn_off_tools</span></span>(<span>self, tools: List[str]) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Disable the given list of tools.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tools</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>List of tool names.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def turn_off_tools(self, tools: List[str]) -&gt; None:
    &#34;&#34;&#34;Disable the given list of tools.

    Args:
        tools (List[str]): List of tool names.
    &#34;&#34;&#34;
    for tool in tools:
        if ((tool in self.tool_names) &amp; (tool != &#39;direct_response&#39;)):
            self._enabled[tool] = False</code></pre>
</details>
</dd>
<dt id="llmflex.Tools.tool_utils.ToolSelector.turn_on_tools"><code class="name flex">
<span>def <span class="ident">turn_on_tools</span></span>(<span>self, tools: List[str]) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Enable the given list of tools.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tools</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>List of tool names.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def turn_on_tools(self, tools: List[str]) -&gt; None:
    &#34;&#34;&#34;Enable the given list of tools.

    Args:
        tools (List[str]): List of tool names.
    &#34;&#34;&#34;
    for tool in tools:
        if tool in self.tool_names:
            self._enabled[tool] = True</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="llmflex.Tools" href="index.html">llmflex.Tools</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="llmflex.Tools.tool_utils.direct_response" href="#llmflex.Tools.tool_utils.direct_response">direct_response</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.gen_string" href="#llmflex.Tools.tool_utils.gen_string">gen_string</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.get_args_descriptions" href="#llmflex.Tools.tool_utils.get_args_descriptions">get_args_descriptions</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.get_args_dtypes" href="#llmflex.Tools.tool_utils.get_args_dtypes">get_args_dtypes</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.get_description" href="#llmflex.Tools.tool_utils.get_description">get_description</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.get_required_args" href="#llmflex.Tools.tool_utils.get_required_args">get_required_args</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.get_tool_metadata" href="#llmflex.Tools.tool_utils.get_tool_metadata">get_tool_metadata</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.normalise_tool_name" href="#llmflex.Tools.tool_utils.normalise_tool_name">normalise_tool_name</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.select" href="#llmflex.Tools.tool_utils.select">select</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="llmflex.Tools.tool_utils.BaseTool" href="#llmflex.Tools.tool_utils.BaseTool">BaseTool</a></code></h4>
<ul class="">
<li><code><a title="llmflex.Tools.tool_utils.BaseTool.description" href="#llmflex.Tools.tool_utils.BaseTool.description">description</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.BaseTool.name" href="#llmflex.Tools.tool_utils.BaseTool.name">name</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="llmflex.Tools.tool_utils.ToolSelector" href="#llmflex.Tools.tool_utils.ToolSelector">ToolSelector</a></code></h4>
<ul class="">
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.enabled_tools" href="#llmflex.Tools.tool_utils.ToolSelector.enabled_tools">enabled_tools</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.function_metadata" href="#llmflex.Tools.tool_utils.ToolSelector.function_metadata">function_metadata</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.get_tool_metadata" href="#llmflex.Tools.tool_utils.ToolSelector.get_tool_metadata">get_tool_metadata</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.is_empty" href="#llmflex.Tools.tool_utils.ToolSelector.is_empty">is_empty</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.metadatas" href="#llmflex.Tools.tool_utils.ToolSelector.metadatas">metadatas</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.num_tools" href="#llmflex.Tools.tool_utils.ToolSelector.num_tools">num_tools</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.structured_input_generation" href="#llmflex.Tools.tool_utils.ToolSelector.structured_input_generation">structured_input_generation</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.tool_call_input" href="#llmflex.Tools.tool_utils.ToolSelector.tool_call_input">tool_call_input</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.tool_call_output" href="#llmflex.Tools.tool_utils.ToolSelector.tool_call_output">tool_call_output</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.tool_map" href="#llmflex.Tools.tool_utils.ToolSelector.tool_map">tool_map</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.tool_names" href="#llmflex.Tools.tool_utils.ToolSelector.tool_names">tool_names</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.tools" href="#llmflex.Tools.tool_utils.ToolSelector.tools">tools</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.turn_off_tools" href="#llmflex.Tools.tool_utils.ToolSelector.turn_off_tools">turn_off_tools</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.ToolSelector.turn_on_tools" href="#llmflex.Tools.tool_utils.ToolSelector.turn_on_tools">turn_on_tools</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>