<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>llmflex.Tools.sd_tool API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>llmflex.Tools.sd_tool</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .tool_utils import BaseTool
from typing import Any, List, Optional, Literal, Dict


class StableDiffusionTool(BaseTool):
    &#34;&#34;&#34;Generating images using a Stable Diffusion model.
    &#34;&#34;&#34;
    def __init__(self, base_url: str) -&gt; None:
        &#34;&#34;&#34;Initialising the tool.

        Args:
            base_url (str): Base url to the Automatic1111 API.
        &#34;&#34;&#34;
        import os
        from ..utils import get_config
        self.base_url = base_url
        self.img_dir = os.path.join(get_config(&#39;package_home&#39;), &#39;sd_tool_resource&#39;, &#39;imgs&#39;)
        os.makedirs(self.img_dir, exist_ok=True)
        super().__init__()

    def text2img(self, prompt: str, negative_prompt: Optional[str] = None, num_imgs: int = 1, 
                 cfg_scale: float = 10.0, img_orientation: Literal[&#39;square&#39;, &#39;portrait&#39;, &#39;horizontal&#39;] = &#39;square&#39;, steps: int = 20) -&gt; List[str]:
        &#34;&#34;&#34;Generating images from text.

        Args:
            prompt (str): Text prompt to the stable diffusion model. It should contain the detailed description of the desired image.
            negative_prompt (Optional[str], optional): Description for objects that are not suppose to be in the image, for example, if trees are not supposed to be in the image, the negative prompt should be &#34;trees&#34;. Defaults to None.
            num_imgs (int, optional): Number of images to be generated. Defaults to 1.
            cfg_scale (float, optional): A scale for how close the image generation should stick with the prompt, the higher the scale, the more likely the description will be accurate. Defaults to 10.0.
            img_orientation (Literal[&amp;#39;square&amp;#39;, &amp;#39;portrait&amp;#39;, &amp;#39;horizontal&amp;#39;], optional): The shape of the image. Defaults to &#39;square&#39;.
            steps (int, optional): Number of steps the stable diffusion model will go through to reach the final image. Defaults to 20.

        Returns:
            List[str]: List of file paths of the generated images.
        &#34;&#34;&#34;
        import requests
        import base64
        import os
        from ..utils import current_time
        width = 512 if img_orientation in [&#39;square&#39;, &#39;protrait&#39;] else 768
        height = 512 if img_orientation in [&#39;square&#39;, &#39;horizontal&#39;] else 768
        payload = dict(
            prompt=prompt,
            negative_prompt=&#39;&#39; if negative_prompt is None else negative_prompt,
            batch_size=num_imgs,
            cfg_scale=cfg_scale,
            steps=steps,
            width=width,
            height=height
        )
        response = requests.post(url=f&#39;{self.base_url}/sdapi/v1/txt2img&#39;, json=payload)
        r = response.json()

        timestamp = current_time()
        img_dirs = []
        for i, img in enumerate(r[&#39;images&#39;]):
            img_dir = os.path.join(self.img_dir, f&#39;{timestamp}_{i}.png&#39;)
            img_dirs.append(img_dir)
            with open(img_dir, &#39;wb&#39;) as f:
                f.write(base64.b64decode(img))
        return img_dirs

    def __call__(self, prompt: str, negative_prompt: Optional[str] = None, num_imgs: int = 1, 
                 img_orientation: Literal[&#39;square&#39;, &#39;portrait&#39;, &#39;horizontal&#39;] = &#39;square&#39;) -&gt; Dict[str, List[str]]:
        &#34;&#34;&#34;Generating images from text.

        Args:
            prompt (str): Text prompt to the stable diffusion model. It should contain the detailed description of the desired image.
            negative_prompt (Optional[str], optional): Description for objects that are not suppose to be in the image, for example, if trees are not supposed to be in the image, the negative prompt should be &#34;trees&#34;. Defaults to None.
            num_imgs (int, optional): Number of images to be generated. Defaults to 1.
            img_orientation (Literal[&amp;#39;square&amp;#39;, &amp;#39;portrait&amp;#39;, &amp;#39;horizontal&amp;#39;], optional): The shape of the image. Defaults to &#39;square&#39;.

        Returns:
            Dict[str, List[str]]: Image directories.
        &#34;&#34;&#34;
        img_dirs = self.text2img(prompt=prompt, negative_prompt=negative_prompt, num_imgs=num_imgs, img_orientation=img_orientation)
        footnote = [f&#39;![Image {i}]({img_dir})&#39; for i, img_dir in enumerate(img_dirs)]
        return dict(images=img_dirs)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="llmflex.Tools.sd_tool.StableDiffusionTool"><code class="flex name class">
<span>class <span class="ident">StableDiffusionTool</span></span>
<span>(</span><span>base_url: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Generating images using a Stable Diffusion model.</p>
<p>Initialising the tool.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>base_url</code></strong> :&ensp;<code>str</code></dt>
<dd>Base url to the Automatic1111 API.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StableDiffusionTool(BaseTool):
    &#34;&#34;&#34;Generating images using a Stable Diffusion model.
    &#34;&#34;&#34;
    def __init__(self, base_url: str) -&gt; None:
        &#34;&#34;&#34;Initialising the tool.

        Args:
            base_url (str): Base url to the Automatic1111 API.
        &#34;&#34;&#34;
        import os
        from ..utils import get_config
        self.base_url = base_url
        self.img_dir = os.path.join(get_config(&#39;package_home&#39;), &#39;sd_tool_resource&#39;, &#39;imgs&#39;)
        os.makedirs(self.img_dir, exist_ok=True)
        super().__init__()

    def text2img(self, prompt: str, negative_prompt: Optional[str] = None, num_imgs: int = 1, 
                 cfg_scale: float = 10.0, img_orientation: Literal[&#39;square&#39;, &#39;portrait&#39;, &#39;horizontal&#39;] = &#39;square&#39;, steps: int = 20) -&gt; List[str]:
        &#34;&#34;&#34;Generating images from text.

        Args:
            prompt (str): Text prompt to the stable diffusion model. It should contain the detailed description of the desired image.
            negative_prompt (Optional[str], optional): Description for objects that are not suppose to be in the image, for example, if trees are not supposed to be in the image, the negative prompt should be &#34;trees&#34;. Defaults to None.
            num_imgs (int, optional): Number of images to be generated. Defaults to 1.
            cfg_scale (float, optional): A scale for how close the image generation should stick with the prompt, the higher the scale, the more likely the description will be accurate. Defaults to 10.0.
            img_orientation (Literal[&amp;#39;square&amp;#39;, &amp;#39;portrait&amp;#39;, &amp;#39;horizontal&amp;#39;], optional): The shape of the image. Defaults to &#39;square&#39;.
            steps (int, optional): Number of steps the stable diffusion model will go through to reach the final image. Defaults to 20.

        Returns:
            List[str]: List of file paths of the generated images.
        &#34;&#34;&#34;
        import requests
        import base64
        import os
        from ..utils import current_time
        width = 512 if img_orientation in [&#39;square&#39;, &#39;protrait&#39;] else 768
        height = 512 if img_orientation in [&#39;square&#39;, &#39;horizontal&#39;] else 768
        payload = dict(
            prompt=prompt,
            negative_prompt=&#39;&#39; if negative_prompt is None else negative_prompt,
            batch_size=num_imgs,
            cfg_scale=cfg_scale,
            steps=steps,
            width=width,
            height=height
        )
        response = requests.post(url=f&#39;{self.base_url}/sdapi/v1/txt2img&#39;, json=payload)
        r = response.json()

        timestamp = current_time()
        img_dirs = []
        for i, img in enumerate(r[&#39;images&#39;]):
            img_dir = os.path.join(self.img_dir, f&#39;{timestamp}_{i}.png&#39;)
            img_dirs.append(img_dir)
            with open(img_dir, &#39;wb&#39;) as f:
                f.write(base64.b64decode(img))
        return img_dirs

    def __call__(self, prompt: str, negative_prompt: Optional[str] = None, num_imgs: int = 1, 
                 img_orientation: Literal[&#39;square&#39;, &#39;portrait&#39;, &#39;horizontal&#39;] = &#39;square&#39;) -&gt; Dict[str, List[str]]:
        &#34;&#34;&#34;Generating images from text.

        Args:
            prompt (str): Text prompt to the stable diffusion model. It should contain the detailed description of the desired image.
            negative_prompt (Optional[str], optional): Description for objects that are not suppose to be in the image, for example, if trees are not supposed to be in the image, the negative prompt should be &#34;trees&#34;. Defaults to None.
            num_imgs (int, optional): Number of images to be generated. Defaults to 1.
            img_orientation (Literal[&amp;#39;square&amp;#39;, &amp;#39;portrait&amp;#39;, &amp;#39;horizontal&amp;#39;], optional): The shape of the image. Defaults to &#39;square&#39;.

        Returns:
            Dict[str, List[str]]: Image directories.
        &#34;&#34;&#34;
        img_dirs = self.text2img(prompt=prompt, negative_prompt=negative_prompt, num_imgs=num_imgs, img_orientation=img_orientation)
        footnote = [f&#39;![Image {i}]({img_dir})&#39; for i, img_dir in enumerate(img_dirs)]
        return dict(images=img_dirs)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="llmflex.Tools.tool_utils.BaseTool" href="tool_utils.html#llmflex.Tools.tool_utils.BaseTool">BaseTool</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="llmflex.Tools.sd_tool.StableDiffusionTool.text2img"><code class="name flex">
<span>def <span class="ident">text2img</span></span>(<span>self, prompt: str, negative_prompt: Optional[str] = None, num_imgs: int = 1, cfg_scale: float = 10.0, img_orientation: Literal['square', 'portrait', 'horizontal'] = 'square', steps: int = 20) ‑> List[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Generating images from text.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>prompt</code></strong> :&ensp;<code>str</code></dt>
<dd>Text prompt to the stable diffusion model. It should contain the detailed description of the desired image.</dd>
<dt><strong><code>negative_prompt</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Description for objects that are not suppose to be in the image, for example, if trees are not supposed to be in the image, the negative prompt should be "trees". Defaults to None.</dd>
<dt><strong><code>num_imgs</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of images to be generated. Defaults to 1.</dd>
<dt><strong><code>cfg_scale</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>A scale for how close the image generation should stick with the prompt, the higher the scale, the more likely the description will be accurate. Defaults to 10.0.</dd>
<dt>img_orientation (Literal[&#39;square&#39;, &#39;portrait&#39;, &#39;horizontal&#39;], optional): The shape of the image. Defaults to 'square'.</dt>
<dt><strong><code>steps</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of steps the stable diffusion model will go through to reach the final image. Defaults to 20.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[str]</code></dt>
<dd>List of file paths of the generated images.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def text2img(self, prompt: str, negative_prompt: Optional[str] = None, num_imgs: int = 1, 
             cfg_scale: float = 10.0, img_orientation: Literal[&#39;square&#39;, &#39;portrait&#39;, &#39;horizontal&#39;] = &#39;square&#39;, steps: int = 20) -&gt; List[str]:
    &#34;&#34;&#34;Generating images from text.

    Args:
        prompt (str): Text prompt to the stable diffusion model. It should contain the detailed description of the desired image.
        negative_prompt (Optional[str], optional): Description for objects that are not suppose to be in the image, for example, if trees are not supposed to be in the image, the negative prompt should be &#34;trees&#34;. Defaults to None.
        num_imgs (int, optional): Number of images to be generated. Defaults to 1.
        cfg_scale (float, optional): A scale for how close the image generation should stick with the prompt, the higher the scale, the more likely the description will be accurate. Defaults to 10.0.
        img_orientation (Literal[&amp;#39;square&amp;#39;, &amp;#39;portrait&amp;#39;, &amp;#39;horizontal&amp;#39;], optional): The shape of the image. Defaults to &#39;square&#39;.
        steps (int, optional): Number of steps the stable diffusion model will go through to reach the final image. Defaults to 20.

    Returns:
        List[str]: List of file paths of the generated images.
    &#34;&#34;&#34;
    import requests
    import base64
    import os
    from ..utils import current_time
    width = 512 if img_orientation in [&#39;square&#39;, &#39;protrait&#39;] else 768
    height = 512 if img_orientation in [&#39;square&#39;, &#39;horizontal&#39;] else 768
    payload = dict(
        prompt=prompt,
        negative_prompt=&#39;&#39; if negative_prompt is None else negative_prompt,
        batch_size=num_imgs,
        cfg_scale=cfg_scale,
        steps=steps,
        width=width,
        height=height
    )
    response = requests.post(url=f&#39;{self.base_url}/sdapi/v1/txt2img&#39;, json=payload)
    r = response.json()

    timestamp = current_time()
    img_dirs = []
    for i, img in enumerate(r[&#39;images&#39;]):
        img_dir = os.path.join(self.img_dir, f&#39;{timestamp}_{i}.png&#39;)
        img_dirs.append(img_dir)
        with open(img_dir, &#39;wb&#39;) as f:
            f.write(base64.b64decode(img))
    return img_dirs</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="llmflex.Tools.tool_utils.BaseTool" href="tool_utils.html#llmflex.Tools.tool_utils.BaseTool">BaseTool</a></b></code>:
<ul class="hlist">
<li><code><a title="llmflex.Tools.tool_utils.BaseTool.description" href="tool_utils.html#llmflex.Tools.tool_utils.BaseTool.description">description</a></code></li>
<li><code><a title="llmflex.Tools.tool_utils.BaseTool.name" href="tool_utils.html#llmflex.Tools.tool_utils.BaseTool.name">name</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="llmflex.Tools" href="index.html">llmflex.Tools</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="llmflex.Tools.sd_tool.StableDiffusionTool" href="#llmflex.Tools.sd_tool.StableDiffusionTool">StableDiffusionTool</a></code></h4>
<ul class="">
<li><code><a title="llmflex.Tools.sd_tool.StableDiffusionTool.text2img" href="#llmflex.Tools.sd_tool.StableDiffusionTool.text2img">text2img</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>