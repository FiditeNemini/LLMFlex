<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>llmflex.Frontend.streamlit_interface API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>llmflex.Frontend.streamlit_interface</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import streamlit as st
from streamlit_extras.bottom_container import bottom
from streamlit_extras.row import row
from ..Frontend.app_resource import AppBackend
from ..Memory.base_memory import list_chat_ids, get_title_from_id
from ..Memory.memory_utils import create_prompt_with_history
from ..Prompts.prompt_template import presets
from ..Tools.tool_utils import gen_string
from ..utils import PACKAGE_DISPLAY_NAME
from typing import Dict, Any, Literal, Optional, Tuple
import yaml

DEFAULT_CONFIG = dict(
    model = dict(
        model_id = &#39;NousResearch/Hermes-2-Theta-Llama-3-8B-GGUF&#39;,
        model_type = &#39;gguf&#39;,
        model_file = &#39;Hermes-2-Pro-Llama-3-Instruct-Merged-DPO-Q4_K_M.gguf&#39;,
        context_length = 8192
    ),
    embeddings = dict(
        class_name = &#39;HuggingfaceEmbeddingsToolkit&#39;,
        model_id = &#39;thenlper/gte-small&#39;
    ),
    ranker = dict(
        class_name = &#39;FlashrankRanker&#39;
    ),
    text_splitter = dict(
        class_name = &#39;SentenceTokenTextSplitter&#39;,
        count_token_fn = &#39;default&#39;
    ),
    tools = [
        dict(
            class_name = &#39;BrowserTool&#39;,
            llm = &#39;default&#39;,
            embeddings = &#39;default&#39;,
            ranker = &#39;default&#39;
        ),
        dict(
            class_name = &#39;math_tool&#39;
        )
    ],
    credentials = None
)

def create_streamlit_script() -&gt; str:
    &#34;&#34;&#34;Create the main script to run the app.

    Returns:
        str: Script directory.
    &#34;&#34;&#34;
    script = [&#39;from llmflex.Frontend.streamlit_interface import AppInterface&#39;]
    script.append(&#39;if __name__ == &#34;__main__&#34;:&#39;)
    script.append(&#39;\tapp = AppInterface()\n\tapp.run()&#39;)
    script = &#39;\n&#39;.join(script)
    import os
    from ..utils import get_config
    script_dir = os.path.join(get_config()[&#39;package_home&#39;], &#39;.streamlit_scripts&#39;, &#39;webapp.py&#39;)
    os.makedirs(os.path.dirname(script_dir), exist_ok=True)
    with open(script_dir, &#39;w&#39;) as f:
        f.write(script)
    return script_dir

@st.cache_resource
def get_backend() -&gt; AppBackend:
    &#34;&#34;&#34;Get the backend object for the webapp.

    Returns:
        AppBackend: Backend object for the webapp.
    &#34;&#34;&#34;
    from ..utils import get_config
    import os
    with open(os.path.join(get_config()[&#39;package_home&#39;], &#39;.streamlit_scripts&#39;, &#39;chatbot_config.yaml&#39;), &#39;r&#39;) as f:
        config = yaml.safe_load(f)
    return AppBackend(config=config)

class AppInterface:

    def __init__(self) -&gt; None:
        from ..utils import get_config
        import os
        st.set_page_config(layout=&#39;wide&#39;)
        self.log_dir = os.path.join(get_config()[&#39;package_home&#39;], &#39;.streamlit_scripts&#39;, &#39;logs&#39;)
        os.makedirs(self.log_dir, exist_ok=True)

    @property
    def credentials(self) -&gt; Optional[Tuple[str, str]]:
        &#34;&#34;&#34;Login credentials if provided.

        Returns:
            Optional[Tuple[str, str]]: Login credentials if provided.
        &#34;&#34;&#34;
        return self.backend.config.get(&#39;credentials&#39;)

    @property
    def is_login(self) -&gt; bool:
        &#34;&#34;&#34;Whether it is logged in or not.

        Returns:
            bool: Whether it is logged in or not.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;is_login&#39;):
            st.session_state.is_login = False if self.credentials is not None else True
        return st.session_state.is_login

    @property
    def backend(self) -&gt; AppBackend:
        &#34;&#34;&#34;Backend resources.

        Returns:
            AppBackend: Backend resources.
        &#34;&#34;&#34;
        return get_backend()
    
    @property
    def generating(self) -&gt; bool:
        &#34;&#34;&#34;Whether text generation in progress.

        Returns:
            bool: Whether text generation in progress.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;generating&#39;):
            st.session_state.generating = False
        return st.session_state.generating
    
    @property
    def chat_delete_button(self) -&gt; bool:
        &#34;&#34;&#34;Whether to show chat deletion buttons.

        Returns:
            bool: Whether to show chat deletion buttons.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;chat_delete_button&#39;):
            st.session_state.chat_delete_button = False
        return st.session_state.chat_delete_button
    
    @property
    def mobile(self) -&gt; bool:
        &#34;&#34;&#34;Whether on mobile device.

        Returns:
            bool: Whether on mobile device.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;mobile&#39;):
            st.session_state.mobile = False
        return st.session_state.mobile
    
    @property
    def enable_begin_text(self) -&gt; bool:
        &#34;&#34;&#34;Whether on mobile device.

        Returns:
            bool: Whether on mobile device.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;enable_begin_text&#39;):
            st.session_state.enable_begin_text = False
        return st.session_state.enable_begin_text
    
    @property
    def begin_text_cache(self) -&gt; str:
        &#34;&#34;&#34;Begin text cache.

        Returns:
            str: Begin text cache.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;begin_text_cache&#39;):
            st.session_state.begin_text_cache = &#39;&#39;
        return st.session_state.begin_text_cache

    @property
    def input_config(self) -&gt; Optional[Dict[str, Any]]:
        &#34;&#34;&#34;Configuration for text generation if available.

        Returns:
            Optional[Dict[str, Any]]: Configuration for text generation if available.
        &#34;&#34;&#34;
        if hasattr(st.session_state, &#39;input_config&#39;):
            return st.session_state.input_config

    # Login page
    def login(self) -&gt; None:
        &#34;&#34;&#34;Creating login page.
        &#34;&#34;&#34;
        login_form = st.form(key=&#39;login&#39;)
        with login_form:
            user = st.text_input(label=&#39;Username:&#39;, placeholder=&#39;Your username...&#39;)
            password = st.text_input(label=&#39;Password&#39;, placeholder=&#39;Your password...&#39;, type=&#39;password&#39;)
            if st.form_submit_button(label=&#39;Login&#39;):
                if ((user == self.credentials[0]) &amp; (password == self.credentials[1])):
                    st.session_state.is_login = True
                    st.rerun()
                else:
                    st.warning(&#39;Incorrect credentials. Please try again.&#39;)

    # Sidebar frontend
    def chats(self) -&gt; None:
        &#34;&#34;&#34;Listing all conversations.
        &#34;&#34;&#34;
        st.button(label=&#39;:heavy_plus_sign: Start a new conversation&#39;, key=f&#39;new_chat&#39;, use_container_width=True, on_click=self.backend.create_memory, disabled=self.generating)

        active_chat_id = self.backend.memory.chat_id
        ids = list_chat_ids()

        def toggle_delete_chats():
            st.session_state.chat_delete_button = not st.session_state.chat_delete_button

        if self.chat_delete_button:
            convs = dict()
            for id in ids:
                btn_type = &#39;primary&#39; if id == active_chat_id else &#39;secondary&#39;
                real_title = get_title_from_id(id)
                title = real_title.replace(&#39;_&#39;, &#39; &#39;).title()
                if len(title) &gt; 20:
                    title = title[:20] + &#39;...&#39;
                convs[id] = row(spec=[0.8, 0.2])
                convs[id].button(label=title, key=id, type=btn_type, use_container_width=True, 
                                 on_click=self.backend.switch_memory, kwargs=dict(chat_id=id), disabled=self.generating, help=real_title)
                convs[id].button(label=&#39;:heavy_minus_sign:&#39;, key=f&#39;del_{id}&#39;, use_container_width=True, 
                                 on_click=self.backend.drop_memory, kwargs=dict(chat_id=id), disabled=self.generating)
        else:
            for id in ids:
                btn_type = &#39;primary&#39; if id == active_chat_id else &#39;secondary&#39;
                real_title = get_title_from_id(id)
                title = real_title.replace(&#39;_&#39;, &#39; &#39;).title()
                if len(title) &gt; 25:
                    title = title[:25] + &#39;...&#39;
                st.button(label=title, key=id, type=btn_type, use_container_width=True, 
                          on_click=self.backend.switch_memory, kwargs=dict(chat_id=id), disabled=self.generating, help=real_title)
        st.toggle(label=&#39;:wastebasket:&#39;, key=f&#39;conv_delete&#39;, disabled=self.generating, 
                value=self.chat_delete_button, on_change=toggle_delete_chats, help=&#39;Select conversations to remove.&#39;)

    def settings(self) -&gt; None:
        &#34;&#34;&#34;Creating the settings.
        &#34;&#34;&#34;
        page_dict = {
            &#39;Prompt Format Settings&#39;: self.prompt_format_settings, 
            &#39;System Message Settings&#39;: self.system_message_setttings, 
            &#39;Memory Settings&#39;: self.memory_settings, 
            &#39;Model Settings&#39;: self.model_settings
            }
        if self.backend.has_tools:
            page_dict[&#39;Tool Settings&#39;] = self.tool_settings
        self.mobile_settings()
        self.begin_text_settings()
        setting_dropdown = st.selectbox(
            label = &#39;Setting dropdown&#39;,
            label_visibility=&#39;collapsed&#39;,
            options= list(page_dict.keys())
        )
        st.markdown(setting_dropdown + &#39;:&#39;)
        page_dict[setting_dropdown]()

    def mobile_settings(self) -&gt; None:
        &#34;&#34;&#34;Create toggle button for mobile mode.
        &#34;&#34;&#34;
        def toggle_mobile() -&gt; None:
            st.session_state.mobile = not st.session_state.mobile
        st.toggle(label=&#39;Mobile&#39;, value=self.mobile, help=&#39;Toggle mobile mode.&#39;, on_change=toggle_mobile, disabled=self.generating) 

    def begin_text_settings(self) -&gt; None:
        &#34;&#34;&#34;Create toggle button for response starting text.
        &#34;&#34;&#34;
        def toggle_begin_text() -&gt; None:
            st.session_state.enable_begin_text = not st.session_state.enable_begin_text
        st.toggle(label=&#39;Response Edit&#39;, value=self.enable_begin_text, help=&#39;Toggle mobile mode.&#39;, on_change=toggle_begin_text, disabled=self.generating) 

    def prompt_format_settings(self) -&gt; None:
        &#34;&#34;&#34;Prompt format settings.
        &#34;&#34;&#34;
        def set_prompt_template() -&gt; None:
            if st.session_state.prompt_format in presets.keys():
                self.backend.set_prompt_template(st.session_state.prompt_format)
            else:
                self.backend._prompt_template = self.backend.factory.prompt_template
        options = list(presets.keys())
        if self.backend.prompt_template.template_name not in options:
            options.append(self.backend.prompt_template.template_name)
        option_index_dict = dict(zip(options, range(len(options))))
        current_index = option_index_dict.get(self.backend.prompt_template.template_name)
        prompt_format = st.selectbox(
            label=&#39;prompt_formats&#39;, 
            label_visibility=&#39;collapsed&#39;,
            key=&#39;prompt_format&#39;,
            options=options, 
            disabled=self.generating, 
            index=current_index,
            on_change=set_prompt_template
        )
        if not self.backend.prompt_template.allow_custom_role:
            st.warning(&#39;Current prompt format does not support function calling.&#39;)
        
    def system_message_setttings(self) -&gt; None:
        &#34;&#34;&#34;Create settings for system message.
        &#34;&#34;&#34;
        self.system_text = st.text_area(label=&#39;System message&#39;, height=250, key=&#39;system_msg&#39;,label_visibility=&#39;collapsed&#39;, value=self.backend.memory.system, disabled=self.generating)
        st.markdown(f&#39;System message token count: {self.backend.llm.get_num_tokens(self.backend.memory.system)}&#39;)
        st.button(label=&#39;:floppy_disk:&#39;, key=&#39;system_save&#39;, disabled=self.generating, use_container_width=True, on_click=self.backend.set_system_message, kwargs=dict(system=self.system_text))

    def memory_settings(self) -&gt; None:
        &#34;&#34;&#34;Create settings for memory.
        &#34;&#34;&#34;
        self.short_limit_slidder = st.slider(&#39;Short term memory token limit&#39;, min_value=0, max_value=10000, step=1, 
                value=self.backend.memory_config[&#39;recent_token_limit&#39;], disabled=self.generating)
        self.long_limit_slidder = st.slider(&#39;Long term memory token limit&#39;, min_value=0, max_value=6000, step=1, 
                value=self.backend.memory_config[&#39;relevant_token_limit&#39;], disabled=self.generating)
        self.rel_score_threshold_slidder = st.slider(&#39;Relevance score threshold for long term memory&#39;, min_value=0.0, max_value=1.0, step=0.01,
                value=self.backend.memory_config[&#39;relevance_score_threshold&#39;], disabled=self.generating)
        self.sim_score_threshold_slidder = st.slider(&#39;Similarity score threshold for long term memory&#39;, min_value=0.0, max_value=1.0, step=0.01,
                value=self.backend.memory_config[&#39;similarity_score_threshold&#39;], disabled=self.generating)
        summary = [
            &#39;Current settings:&#39;,
            f&#34;Short term memory token limit: {self.backend.memory_config[&#39;recent_token_limit&#39;]}&#34;,
            f&#34;Long term memory token limit: {self.backend.memory_config[&#39;relevant_token_limit&#39;]}&#34;,
            f&#34;Relevance score threshold: {self.backend.memory_config[&#39;relevance_score_threshold&#39;]}&#34;,
            f&#34;Similarity score threshold: {self.backend.memory_config[&#39;similarity_score_threshold&#39;]}&#34;

        ]
        st.markdown(&#39;  \n&#39;.join(summary))
        st.button(label=&#39;:floppy_disk:&#39;, key=&#39;memory_token_save&#39;, disabled=self.generating, 
                  use_container_width=True,
                  on_click=self.backend.set_memory_config,
                  kwargs=dict(recent_token_limit=self.short_limit_slidder,
                              relevant_token_limit=self.long_limit_slidder,
                              relevance_score_threshold=self.rel_score_threshold_slidder,
                              similarity_score_threshold=self.sim_score_threshold_slidder))

    def model_settings(self) -&gt; None:
        &#34;&#34;&#34;Create settings for text generation.
        &#34;&#34;&#34;
        self.temperature_slidder = st.slider(&#39;Temparature&#39;, min_value=0.0, max_value=2.0, step=0.01, value=self.backend.generation_config[&#39;temperature&#39;], disabled=self.generating)
        self.max_new_token_slidder = st.slider(&#39;Maximum number of new tokens&#39;, min_value=0, max_value=4096, step=1, value=self.backend.generation_config[&#39;max_new_tokens&#39;], disabled=self.generating)
        self.repetition_slidder = st.slider(&#39;Repetition penalty&#39;, min_value=1.0, max_value=2.0, step=0.01, value=self.backend.generation_config[&#39;repetition_penalty&#39;], disabled=self.generating)
        self.topp_slidder = st.slider(&#39;Top P&#39;, min_value=0.0, max_value=1.0, step=0.01, value=self.backend.generation_config[&#39;top_p&#39;], disabled=self.generating)
        self.topk_slidder = st.slider(&#39;Top K&#39;, min_value=0, max_value=30000, step=1, value=self.backend.generation_config[&#39;top_k&#39;], disabled=self.generating)
        summary = [
            &#39;Current settings:&#39;,
            f&#34;Temperature: {self.backend.generation_config[&#39;temperature&#39;]}&#34;,
            f&#34;Max new tokens: {self.backend.generation_config[&#39;max_new_tokens&#39;]}&#34;,
            f&#34;Repetition penalty: {self.backend.generation_config[&#39;repetition_penalty&#39;]}&#34;,
            f&#34;Top P: {self.backend.generation_config[&#39;top_p&#39;]}&#34;,
            f&#34;Top K: {self.backend.generation_config[&#39;top_k&#39;]}&#34;,
        ]
        st.markdown(&#39;  \n&#39;.join(summary))
        st.button(label=&#39;:floppy_disk:&#39;, 
                  key=&#39;llm_config_save&#39;, 
                  disabled=self.generating, 
                  use_container_width=True,
                  on_click=self.backend.set_generation_config,
                  kwargs=dict(temperature=self.temperature_slidder,
                              max_new_tokens=self.max_new_token_slidder,
                              repetition_penalty=self.repetition_slidder,
                              top_p=self.topp_slidder,
                              top_k=self.topk_slidder))

    def tool_settings(self) -&gt; None:
        &#34;&#34;&#34;Create settings for tools.
        &#34;&#34;&#34;
        for k, v in self.backend.tool_status.items():
            pretty_name = k.replace(&#39;_&#39;, &#39; &#39;).strip().title()
            st.toggle(label=f&#39;{pretty_name}&#39;, value=v, on_change=self.backend.toggle_tool, kwargs=dict(tool_name=k),
                        disabled=self.generating)

    def sidebar(self) -&gt; None:
        &#34;&#34;&#34;Creating the sidebar.
        &#34;&#34;&#34;
        with st.sidebar:
            app_summary = [&#39;Powered by:&#39;, 
                        f&#39;* LLM: {self.backend.factory.model_id}&#39;, 
                        f&#39;* Embedding model: {self.backend.embeddings.name}&#39;, 
                        &#39;&#39;, 
                        &#39;Current conversation:&#39;, 
                        f&#39;* {self.backend.memory.title}&#39;,
                        &#39;&#39;,
                        &#39;Current prompt format:&#39;,
                        f&#39;* {self.backend.prompt_template.template_name}&#39;]
            st.header(PACKAGE_DISPLAY_NAME.upper(), help=&#39;  \n&#39;.join(app_summary), divider=&#34;grey&#34;)
            with st.expander(label=&#39;:left_speech_bubble: Conversations&#39;, expanded=True):
                self.chats()

            with st.expander(label=&#39;:gear: Settings&#39;, expanded=False):
                self.settings()

    # Chatbot frontend
    def create_input_config(self, user_input: str, begin_text: str, generation_mode: Literal[&#39;new&#39;, &#39;retry&#39;, &#39;continue&#39;]) -&gt; None:
        &#34;&#34;&#34;Create everything needed for the next generation.

        Args:
            user_input (str): User request.
            begin_text (str): Starting text of the response.
            generation_mode (Literal[&amp;#39;new&amp;#39;, &amp;#39;retry&amp;#39;, &amp;#39;continue&amp;#39;]): Mode of generation.
        &#34;&#34;&#34;
        new_input = user_input.strip()
        ai_start = begin_text.lstrip()
        if generation_mode != &#39;new&#39;:
            last_record = self.backend.memory.history[-1]
            new_input = last_record[0]
            if generation_mode == &#39;continue&#39;:
                ai_start = last_record[1]
            self.backend.memory.remove_last_interaction()
        prompt_args = dict(
            llm=self.backend.llm,
            memory=self.backend.memory,
            user_input=new_input,
            prompt_template=self.backend.prompt_template,
            system=self.backend.memory.system,
            recent_token_limit=self.backend.memory_config[&#39;recent_token_limit&#39;],
            relevant_token_limit=self.backend.memory_config[&#39;relevant_token_limit&#39;],
            relevance_score_threshold=self.backend.memory_config[&#39;relevance_score_threshold&#39;],
            similarity_score_threshold=self.backend.memory_config[&#39;similarity_score_threshold&#39;]
        )
        if ai_start.strip() != &#39;&#39;:
            prompt = create_prompt_with_history(**prompt_args) + ai_start
            st.session_state.begin_text_cache = ai_start
        elif ((not self.backend.tool_selector.is_empty) &amp; (self.backend.prompt_template.allow_custom_role)):
            prompt_args[&#39;tool_selector&#39;] = self.backend.tool_selector
            prompt = create_prompt_with_history(**prompt_args)
        else:
            prompt = create_prompt_with_history(**prompt_args)
        
        st.session_state.input_config = dict(
            prompt=prompt,
            user_input=new_input,
            begin_text=ai_start,
            mode=generation_mode
        )

    def generation_message(self) -&gt; None:
        &#34;&#34;&#34;Create streaming message.
        &#34;&#34;&#34;
        import json
        if self.input_config is not None:
            import os
            from ..utils import current_time, save_json
            logfilename = os.path.join(self.log_dir, f&#39;{self.backend.memory.chat_id}_{current_time()}.json&#39;)
            save_json(content=self.input_config, file_dir=logfilename)
            with st.chat_message(name=&#39;user&#39;):
                st.markdown(self.input_config[&#39;user_input&#39;])
            with st.chat_message(name=&#39;assistant&#39;):
                with st.spinner(&#39;Thinking....&#39;):
                    prompt = self.input_config[&#39;prompt&#39;]
                    begin_text = self.input_config[&#39;begin_text&#39;]
                    save_args = dict()
                    if not isinstance(prompt, str):
                        tool_input = self.backend.tool_selector.tool_call_input(llm=self.backend.llm, messages=prompt, prompt_template=self.backend.prompt_template, **self.backend.generation_config)
                        if tool_input[&#39;name&#39;] == &#39;direct_response&#39;:
                            prompt = self.backend.prompt_template.create_custom_prompt(messages=prompt) + begin_text
                        else:
                            toolholder = st.empty()
                            tool_name = tool_input[&#39;name&#39;].replace(&#39;_&#39;, &#39; &#39;).title().strip()
                            with toolholder.status(label=f&#34;:hammer_and_pick: Running __{tool_name}__...&#34;, state=&#39;running&#39;):
                                st.text(json.dumps(tool_input, indent=4))
                                tool_output = self.backend.tool_selector.tool_call_output(tool_input=tool_input, return_error=True)
                                save_args[&#39;function_call&#39;] = tool_output
                            with toolholder.status(label=f&#34;:hammer_and_pick: __{tool_name}__&#34;, state=&#39;complete&#39;):
                                st.text(json.dumps(tool_output, indent=4))
                            prompt.append(dict(role=&#39;function_call&#39;, content=str(tool_output)))
                            prompt = self.backend.prompt_template.create_custom_prompt(messages=prompt) + begin_text
                    placeholder = st.empty()
                    streamer = self.backend.llm.stream(prompt, stop=self.backend.prompt_template.stop, **self.backend.generation_config)
                    output = begin_text
                    placeholder.markdown(output.strip(&#39; \r\n\t&#39;))
                    for i in streamer:
                        output += i
                        placeholder.markdown(output.strip(&#39; \r\n\t&#39;))
                    self.backend.memory.save_interaction(user_input=self.input_config[&#39;user_input&#39;], assistant_output=output, **save_args)

                    # Change title if the title is New Chat
                    if self.backend.memory.title == &#39;New Chat&#39;:
                        pref = &#39;\n\nNote: This is the short title of this conversation: {&#34;title&#34;: &#39;
                        title = gen_string(self.backend.llm, prompt=prompt + output + pref, max_new_tokens=30)
                        if title != &#39;New Chat&#39;:
                            self.backend.memory.update_title(title)
                    st.session_state.input_config = None
                    st.session_state.generating = False
                    st.rerun()

    def historical_conversation(self) -&gt; None:
        &#34;&#34;&#34;Creating the historical conversation.
        &#34;&#34;&#34;
        import json
        history = self.backend.memory.history_dict
        for message in history:
            with st.chat_message(name=message[&#39;role&#39;]):
                fn_call = message.get(&#39;function_call&#39;)
                content = message[&#39;content&#39;]
                if fn_call is not None:
                    fn_name = fn_call[&#39;name&#39;].replace(&#39;_&#39;, &#39; &#39;).strip().title()
                    with st.status(label=f&#34;:hammer_and_pick: __{fn_name}__&#34;, state=&#39;complete&#39;):
                        st.code(json.dumps(fn_call, indent=4), language=&#39;plaintext&#39;)
                    if fn_call.get(&#39;output&#39;, dict()).get(&#39;footnote&#39;) is not None:
                        footnote = fn_call.get(&#39;output&#39;, dict()).get(&#39;footnote&#39;)
                        if isinstance(footnote, list):
                            footnote = &#39;  \n&#39;.join(footnote)
                        else:
                            footnote = str(footnote)
                        content += &#39;\n\n---\n&#39; + footnote
                st.markdown(content, help=f&#39;Number of tokens: {self.backend.llm.get_num_tokens(message[&#34;content&#34;])}&#39;)
        self.generation_message()

    def util_buttons(self) -&gt; None:
        &#34;&#34;&#34;Create utility buttons for text generation.
        &#34;&#34;&#34;
        def retry_response(mode):
            if self.backend.memory.interaction_count != 0:
                self.create_input_config(user_input=&#39;sample&#39;, begin_text=self.begin_text, generation_mode=mode)
                st.session_state.generating = True

        btns = row([1, 1, 1])
        btns.button(&#39;:arrows_counterclockwise:&#39;, use_container_width=True, help=&#39;Re-generate response&#39;, disabled=self.generating, 
                      on_click=retry_response, kwargs=dict(mode=&#39;retry&#39;))

        btns.button(&#39;:fast_forward:&#39;, use_container_width=True, help=&#39;Continue generating response&#39;, disabled=self.generating,
                      on_click=retry_response, kwargs=dict(mode=&#39;retry&#39;))

        btns.button(&#39;:wastebasket:&#39;, use_container_width=True, help=&#39;Remove the latest question and response&#39;, disabled=self.generating, 
                       on_click=self.backend.memory.remove_last_interaction)

    def input_box(self) -&gt; None:
        &#34;&#34;&#34;Creating the input box.
        &#34;&#34;&#34;
        with bottom():
            self.user_input = st.chat_input(placeholder=&#39;Your message...&#39;, disabled=self.generating)
            if self.enable_begin_text:
                self.begin_text = st.text_area(label=&#39;response_start&#39;, placeholder=&#39;Starting text of the response here...&#39;, value=self.begin_text_cache, label_visibility=&#39;collapsed&#39;)
            else:
                self.begin_text = &#39;&#39;

            if self.user_input:
                if self.user_input.strip() != &#39;&#39;:
                    self.create_input_config(user_input=self.user_input, begin_text=self.begin_text, generation_mode=&#39;new&#39;)
                    st.session_state.generating = True
                    st.rerun()

            if self.mobile:
                with st.expander(&#39;:gear: Extra options&#39;):
                    self.util_buttons()
            else:
                self.util_buttons()
            
    def chatbot(self) -&gt; None:
        &#34;&#34;&#34;Creating the chatbot interface.
        &#34;&#34;&#34;
        self.historical_conversation()
        self.input_box()

    def run(self) -&gt; None:
        &#34;&#34;&#34;Run the app.
        &#34;&#34;&#34;
        if self.is_login:
            self.sidebar()
            self.chatbot()
        else:
            self.login()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="llmflex.Frontend.streamlit_interface.create_streamlit_script"><code class="name flex">
<span>def <span class="ident">create_streamlit_script</span></span>(<span>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Create the main script to run the app.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Script directory.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_streamlit_script() -&gt; str:
    &#34;&#34;&#34;Create the main script to run the app.

    Returns:
        str: Script directory.
    &#34;&#34;&#34;
    script = [&#39;from llmflex.Frontend.streamlit_interface import AppInterface&#39;]
    script.append(&#39;if __name__ == &#34;__main__&#34;:&#39;)
    script.append(&#39;\tapp = AppInterface()\n\tapp.run()&#39;)
    script = &#39;\n&#39;.join(script)
    import os
    from ..utils import get_config
    script_dir = os.path.join(get_config()[&#39;package_home&#39;], &#39;.streamlit_scripts&#39;, &#39;webapp.py&#39;)
    os.makedirs(os.path.dirname(script_dir), exist_ok=True)
    with open(script_dir, &#39;w&#39;) as f:
        f.write(script)
    return script_dir</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.get_backend"><code class="name flex">
<span>def <span class="ident">get_backend</span></span>(<span>) ‑> <a title="llmflex.Frontend.app_resource.AppBackend" href="app_resource.html#llmflex.Frontend.app_resource.AppBackend">AppBackend</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get the backend object for the webapp.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>AppBackend</code></dt>
<dd>Backend object for the webapp.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@st.cache_resource
def get_backend() -&gt; AppBackend:
    &#34;&#34;&#34;Get the backend object for the webapp.

    Returns:
        AppBackend: Backend object for the webapp.
    &#34;&#34;&#34;
    from ..utils import get_config
    import os
    with open(os.path.join(get_config()[&#39;package_home&#39;], &#39;.streamlit_scripts&#39;, &#39;chatbot_config.yaml&#39;), &#39;r&#39;) as f:
        config = yaml.safe_load(f)
    return AppBackend(config=config)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface"><code class="flex name class">
<span>class <span class="ident">AppInterface</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AppInterface:

    def __init__(self) -&gt; None:
        from ..utils import get_config
        import os
        st.set_page_config(layout=&#39;wide&#39;)
        self.log_dir = os.path.join(get_config()[&#39;package_home&#39;], &#39;.streamlit_scripts&#39;, &#39;logs&#39;)
        os.makedirs(self.log_dir, exist_ok=True)

    @property
    def credentials(self) -&gt; Optional[Tuple[str, str]]:
        &#34;&#34;&#34;Login credentials if provided.

        Returns:
            Optional[Tuple[str, str]]: Login credentials if provided.
        &#34;&#34;&#34;
        return self.backend.config.get(&#39;credentials&#39;)

    @property
    def is_login(self) -&gt; bool:
        &#34;&#34;&#34;Whether it is logged in or not.

        Returns:
            bool: Whether it is logged in or not.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;is_login&#39;):
            st.session_state.is_login = False if self.credentials is not None else True
        return st.session_state.is_login

    @property
    def backend(self) -&gt; AppBackend:
        &#34;&#34;&#34;Backend resources.

        Returns:
            AppBackend: Backend resources.
        &#34;&#34;&#34;
        return get_backend()
    
    @property
    def generating(self) -&gt; bool:
        &#34;&#34;&#34;Whether text generation in progress.

        Returns:
            bool: Whether text generation in progress.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;generating&#39;):
            st.session_state.generating = False
        return st.session_state.generating
    
    @property
    def chat_delete_button(self) -&gt; bool:
        &#34;&#34;&#34;Whether to show chat deletion buttons.

        Returns:
            bool: Whether to show chat deletion buttons.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;chat_delete_button&#39;):
            st.session_state.chat_delete_button = False
        return st.session_state.chat_delete_button
    
    @property
    def mobile(self) -&gt; bool:
        &#34;&#34;&#34;Whether on mobile device.

        Returns:
            bool: Whether on mobile device.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;mobile&#39;):
            st.session_state.mobile = False
        return st.session_state.mobile
    
    @property
    def enable_begin_text(self) -&gt; bool:
        &#34;&#34;&#34;Whether on mobile device.

        Returns:
            bool: Whether on mobile device.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;enable_begin_text&#39;):
            st.session_state.enable_begin_text = False
        return st.session_state.enable_begin_text
    
    @property
    def begin_text_cache(self) -&gt; str:
        &#34;&#34;&#34;Begin text cache.

        Returns:
            str: Begin text cache.
        &#34;&#34;&#34;
        if not hasattr(st.session_state, &#39;begin_text_cache&#39;):
            st.session_state.begin_text_cache = &#39;&#39;
        return st.session_state.begin_text_cache

    @property
    def input_config(self) -&gt; Optional[Dict[str, Any]]:
        &#34;&#34;&#34;Configuration for text generation if available.

        Returns:
            Optional[Dict[str, Any]]: Configuration for text generation if available.
        &#34;&#34;&#34;
        if hasattr(st.session_state, &#39;input_config&#39;):
            return st.session_state.input_config

    # Login page
    def login(self) -&gt; None:
        &#34;&#34;&#34;Creating login page.
        &#34;&#34;&#34;
        login_form = st.form(key=&#39;login&#39;)
        with login_form:
            user = st.text_input(label=&#39;Username:&#39;, placeholder=&#39;Your username...&#39;)
            password = st.text_input(label=&#39;Password&#39;, placeholder=&#39;Your password...&#39;, type=&#39;password&#39;)
            if st.form_submit_button(label=&#39;Login&#39;):
                if ((user == self.credentials[0]) &amp; (password == self.credentials[1])):
                    st.session_state.is_login = True
                    st.rerun()
                else:
                    st.warning(&#39;Incorrect credentials. Please try again.&#39;)

    # Sidebar frontend
    def chats(self) -&gt; None:
        &#34;&#34;&#34;Listing all conversations.
        &#34;&#34;&#34;
        st.button(label=&#39;:heavy_plus_sign: Start a new conversation&#39;, key=f&#39;new_chat&#39;, use_container_width=True, on_click=self.backend.create_memory, disabled=self.generating)

        active_chat_id = self.backend.memory.chat_id
        ids = list_chat_ids()

        def toggle_delete_chats():
            st.session_state.chat_delete_button = not st.session_state.chat_delete_button

        if self.chat_delete_button:
            convs = dict()
            for id in ids:
                btn_type = &#39;primary&#39; if id == active_chat_id else &#39;secondary&#39;
                real_title = get_title_from_id(id)
                title = real_title.replace(&#39;_&#39;, &#39; &#39;).title()
                if len(title) &gt; 20:
                    title = title[:20] + &#39;...&#39;
                convs[id] = row(spec=[0.8, 0.2])
                convs[id].button(label=title, key=id, type=btn_type, use_container_width=True, 
                                 on_click=self.backend.switch_memory, kwargs=dict(chat_id=id), disabled=self.generating, help=real_title)
                convs[id].button(label=&#39;:heavy_minus_sign:&#39;, key=f&#39;del_{id}&#39;, use_container_width=True, 
                                 on_click=self.backend.drop_memory, kwargs=dict(chat_id=id), disabled=self.generating)
        else:
            for id in ids:
                btn_type = &#39;primary&#39; if id == active_chat_id else &#39;secondary&#39;
                real_title = get_title_from_id(id)
                title = real_title.replace(&#39;_&#39;, &#39; &#39;).title()
                if len(title) &gt; 25:
                    title = title[:25] + &#39;...&#39;
                st.button(label=title, key=id, type=btn_type, use_container_width=True, 
                          on_click=self.backend.switch_memory, kwargs=dict(chat_id=id), disabled=self.generating, help=real_title)
        st.toggle(label=&#39;:wastebasket:&#39;, key=f&#39;conv_delete&#39;, disabled=self.generating, 
                value=self.chat_delete_button, on_change=toggle_delete_chats, help=&#39;Select conversations to remove.&#39;)

    def settings(self) -&gt; None:
        &#34;&#34;&#34;Creating the settings.
        &#34;&#34;&#34;
        page_dict = {
            &#39;Prompt Format Settings&#39;: self.prompt_format_settings, 
            &#39;System Message Settings&#39;: self.system_message_setttings, 
            &#39;Memory Settings&#39;: self.memory_settings, 
            &#39;Model Settings&#39;: self.model_settings
            }
        if self.backend.has_tools:
            page_dict[&#39;Tool Settings&#39;] = self.tool_settings
        self.mobile_settings()
        self.begin_text_settings()
        setting_dropdown = st.selectbox(
            label = &#39;Setting dropdown&#39;,
            label_visibility=&#39;collapsed&#39;,
            options= list(page_dict.keys())
        )
        st.markdown(setting_dropdown + &#39;:&#39;)
        page_dict[setting_dropdown]()

    def mobile_settings(self) -&gt; None:
        &#34;&#34;&#34;Create toggle button for mobile mode.
        &#34;&#34;&#34;
        def toggle_mobile() -&gt; None:
            st.session_state.mobile = not st.session_state.mobile
        st.toggle(label=&#39;Mobile&#39;, value=self.mobile, help=&#39;Toggle mobile mode.&#39;, on_change=toggle_mobile, disabled=self.generating) 

    def begin_text_settings(self) -&gt; None:
        &#34;&#34;&#34;Create toggle button for response starting text.
        &#34;&#34;&#34;
        def toggle_begin_text() -&gt; None:
            st.session_state.enable_begin_text = not st.session_state.enable_begin_text
        st.toggle(label=&#39;Response Edit&#39;, value=self.enable_begin_text, help=&#39;Toggle mobile mode.&#39;, on_change=toggle_begin_text, disabled=self.generating) 

    def prompt_format_settings(self) -&gt; None:
        &#34;&#34;&#34;Prompt format settings.
        &#34;&#34;&#34;
        def set_prompt_template() -&gt; None:
            if st.session_state.prompt_format in presets.keys():
                self.backend.set_prompt_template(st.session_state.prompt_format)
            else:
                self.backend._prompt_template = self.backend.factory.prompt_template
        options = list(presets.keys())
        if self.backend.prompt_template.template_name not in options:
            options.append(self.backend.prompt_template.template_name)
        option_index_dict = dict(zip(options, range(len(options))))
        current_index = option_index_dict.get(self.backend.prompt_template.template_name)
        prompt_format = st.selectbox(
            label=&#39;prompt_formats&#39;, 
            label_visibility=&#39;collapsed&#39;,
            key=&#39;prompt_format&#39;,
            options=options, 
            disabled=self.generating, 
            index=current_index,
            on_change=set_prompt_template
        )
        if not self.backend.prompt_template.allow_custom_role:
            st.warning(&#39;Current prompt format does not support function calling.&#39;)
        
    def system_message_setttings(self) -&gt; None:
        &#34;&#34;&#34;Create settings for system message.
        &#34;&#34;&#34;
        self.system_text = st.text_area(label=&#39;System message&#39;, height=250, key=&#39;system_msg&#39;,label_visibility=&#39;collapsed&#39;, value=self.backend.memory.system, disabled=self.generating)
        st.markdown(f&#39;System message token count: {self.backend.llm.get_num_tokens(self.backend.memory.system)}&#39;)
        st.button(label=&#39;:floppy_disk:&#39;, key=&#39;system_save&#39;, disabled=self.generating, use_container_width=True, on_click=self.backend.set_system_message, kwargs=dict(system=self.system_text))

    def memory_settings(self) -&gt; None:
        &#34;&#34;&#34;Create settings for memory.
        &#34;&#34;&#34;
        self.short_limit_slidder = st.slider(&#39;Short term memory token limit&#39;, min_value=0, max_value=10000, step=1, 
                value=self.backend.memory_config[&#39;recent_token_limit&#39;], disabled=self.generating)
        self.long_limit_slidder = st.slider(&#39;Long term memory token limit&#39;, min_value=0, max_value=6000, step=1, 
                value=self.backend.memory_config[&#39;relevant_token_limit&#39;], disabled=self.generating)
        self.rel_score_threshold_slidder = st.slider(&#39;Relevance score threshold for long term memory&#39;, min_value=0.0, max_value=1.0, step=0.01,
                value=self.backend.memory_config[&#39;relevance_score_threshold&#39;], disabled=self.generating)
        self.sim_score_threshold_slidder = st.slider(&#39;Similarity score threshold for long term memory&#39;, min_value=0.0, max_value=1.0, step=0.01,
                value=self.backend.memory_config[&#39;similarity_score_threshold&#39;], disabled=self.generating)
        summary = [
            &#39;Current settings:&#39;,
            f&#34;Short term memory token limit: {self.backend.memory_config[&#39;recent_token_limit&#39;]}&#34;,
            f&#34;Long term memory token limit: {self.backend.memory_config[&#39;relevant_token_limit&#39;]}&#34;,
            f&#34;Relevance score threshold: {self.backend.memory_config[&#39;relevance_score_threshold&#39;]}&#34;,
            f&#34;Similarity score threshold: {self.backend.memory_config[&#39;similarity_score_threshold&#39;]}&#34;

        ]
        st.markdown(&#39;  \n&#39;.join(summary))
        st.button(label=&#39;:floppy_disk:&#39;, key=&#39;memory_token_save&#39;, disabled=self.generating, 
                  use_container_width=True,
                  on_click=self.backend.set_memory_config,
                  kwargs=dict(recent_token_limit=self.short_limit_slidder,
                              relevant_token_limit=self.long_limit_slidder,
                              relevance_score_threshold=self.rel_score_threshold_slidder,
                              similarity_score_threshold=self.sim_score_threshold_slidder))

    def model_settings(self) -&gt; None:
        &#34;&#34;&#34;Create settings for text generation.
        &#34;&#34;&#34;
        self.temperature_slidder = st.slider(&#39;Temparature&#39;, min_value=0.0, max_value=2.0, step=0.01, value=self.backend.generation_config[&#39;temperature&#39;], disabled=self.generating)
        self.max_new_token_slidder = st.slider(&#39;Maximum number of new tokens&#39;, min_value=0, max_value=4096, step=1, value=self.backend.generation_config[&#39;max_new_tokens&#39;], disabled=self.generating)
        self.repetition_slidder = st.slider(&#39;Repetition penalty&#39;, min_value=1.0, max_value=2.0, step=0.01, value=self.backend.generation_config[&#39;repetition_penalty&#39;], disabled=self.generating)
        self.topp_slidder = st.slider(&#39;Top P&#39;, min_value=0.0, max_value=1.0, step=0.01, value=self.backend.generation_config[&#39;top_p&#39;], disabled=self.generating)
        self.topk_slidder = st.slider(&#39;Top K&#39;, min_value=0, max_value=30000, step=1, value=self.backend.generation_config[&#39;top_k&#39;], disabled=self.generating)
        summary = [
            &#39;Current settings:&#39;,
            f&#34;Temperature: {self.backend.generation_config[&#39;temperature&#39;]}&#34;,
            f&#34;Max new tokens: {self.backend.generation_config[&#39;max_new_tokens&#39;]}&#34;,
            f&#34;Repetition penalty: {self.backend.generation_config[&#39;repetition_penalty&#39;]}&#34;,
            f&#34;Top P: {self.backend.generation_config[&#39;top_p&#39;]}&#34;,
            f&#34;Top K: {self.backend.generation_config[&#39;top_k&#39;]}&#34;,
        ]
        st.markdown(&#39;  \n&#39;.join(summary))
        st.button(label=&#39;:floppy_disk:&#39;, 
                  key=&#39;llm_config_save&#39;, 
                  disabled=self.generating, 
                  use_container_width=True,
                  on_click=self.backend.set_generation_config,
                  kwargs=dict(temperature=self.temperature_slidder,
                              max_new_tokens=self.max_new_token_slidder,
                              repetition_penalty=self.repetition_slidder,
                              top_p=self.topp_slidder,
                              top_k=self.topk_slidder))

    def tool_settings(self) -&gt; None:
        &#34;&#34;&#34;Create settings for tools.
        &#34;&#34;&#34;
        for k, v in self.backend.tool_status.items():
            pretty_name = k.replace(&#39;_&#39;, &#39; &#39;).strip().title()
            st.toggle(label=f&#39;{pretty_name}&#39;, value=v, on_change=self.backend.toggle_tool, kwargs=dict(tool_name=k),
                        disabled=self.generating)

    def sidebar(self) -&gt; None:
        &#34;&#34;&#34;Creating the sidebar.
        &#34;&#34;&#34;
        with st.sidebar:
            app_summary = [&#39;Powered by:&#39;, 
                        f&#39;* LLM: {self.backend.factory.model_id}&#39;, 
                        f&#39;* Embedding model: {self.backend.embeddings.name}&#39;, 
                        &#39;&#39;, 
                        &#39;Current conversation:&#39;, 
                        f&#39;* {self.backend.memory.title}&#39;,
                        &#39;&#39;,
                        &#39;Current prompt format:&#39;,
                        f&#39;* {self.backend.prompt_template.template_name}&#39;]
            st.header(PACKAGE_DISPLAY_NAME.upper(), help=&#39;  \n&#39;.join(app_summary), divider=&#34;grey&#34;)
            with st.expander(label=&#39;:left_speech_bubble: Conversations&#39;, expanded=True):
                self.chats()

            with st.expander(label=&#39;:gear: Settings&#39;, expanded=False):
                self.settings()

    # Chatbot frontend
    def create_input_config(self, user_input: str, begin_text: str, generation_mode: Literal[&#39;new&#39;, &#39;retry&#39;, &#39;continue&#39;]) -&gt; None:
        &#34;&#34;&#34;Create everything needed for the next generation.

        Args:
            user_input (str): User request.
            begin_text (str): Starting text of the response.
            generation_mode (Literal[&amp;#39;new&amp;#39;, &amp;#39;retry&amp;#39;, &amp;#39;continue&amp;#39;]): Mode of generation.
        &#34;&#34;&#34;
        new_input = user_input.strip()
        ai_start = begin_text.lstrip()
        if generation_mode != &#39;new&#39;:
            last_record = self.backend.memory.history[-1]
            new_input = last_record[0]
            if generation_mode == &#39;continue&#39;:
                ai_start = last_record[1]
            self.backend.memory.remove_last_interaction()
        prompt_args = dict(
            llm=self.backend.llm,
            memory=self.backend.memory,
            user_input=new_input,
            prompt_template=self.backend.prompt_template,
            system=self.backend.memory.system,
            recent_token_limit=self.backend.memory_config[&#39;recent_token_limit&#39;],
            relevant_token_limit=self.backend.memory_config[&#39;relevant_token_limit&#39;],
            relevance_score_threshold=self.backend.memory_config[&#39;relevance_score_threshold&#39;],
            similarity_score_threshold=self.backend.memory_config[&#39;similarity_score_threshold&#39;]
        )
        if ai_start.strip() != &#39;&#39;:
            prompt = create_prompt_with_history(**prompt_args) + ai_start
            st.session_state.begin_text_cache = ai_start
        elif ((not self.backend.tool_selector.is_empty) &amp; (self.backend.prompt_template.allow_custom_role)):
            prompt_args[&#39;tool_selector&#39;] = self.backend.tool_selector
            prompt = create_prompt_with_history(**prompt_args)
        else:
            prompt = create_prompt_with_history(**prompt_args)
        
        st.session_state.input_config = dict(
            prompt=prompt,
            user_input=new_input,
            begin_text=ai_start,
            mode=generation_mode
        )

    def generation_message(self) -&gt; None:
        &#34;&#34;&#34;Create streaming message.
        &#34;&#34;&#34;
        import json
        if self.input_config is not None:
            import os
            from ..utils import current_time, save_json
            logfilename = os.path.join(self.log_dir, f&#39;{self.backend.memory.chat_id}_{current_time()}.json&#39;)
            save_json(content=self.input_config, file_dir=logfilename)
            with st.chat_message(name=&#39;user&#39;):
                st.markdown(self.input_config[&#39;user_input&#39;])
            with st.chat_message(name=&#39;assistant&#39;):
                with st.spinner(&#39;Thinking....&#39;):
                    prompt = self.input_config[&#39;prompt&#39;]
                    begin_text = self.input_config[&#39;begin_text&#39;]
                    save_args = dict()
                    if not isinstance(prompt, str):
                        tool_input = self.backend.tool_selector.tool_call_input(llm=self.backend.llm, messages=prompt, prompt_template=self.backend.prompt_template, **self.backend.generation_config)
                        if tool_input[&#39;name&#39;] == &#39;direct_response&#39;:
                            prompt = self.backend.prompt_template.create_custom_prompt(messages=prompt) + begin_text
                        else:
                            toolholder = st.empty()
                            tool_name = tool_input[&#39;name&#39;].replace(&#39;_&#39;, &#39; &#39;).title().strip()
                            with toolholder.status(label=f&#34;:hammer_and_pick: Running __{tool_name}__...&#34;, state=&#39;running&#39;):
                                st.text(json.dumps(tool_input, indent=4))
                                tool_output = self.backend.tool_selector.tool_call_output(tool_input=tool_input, return_error=True)
                                save_args[&#39;function_call&#39;] = tool_output
                            with toolholder.status(label=f&#34;:hammer_and_pick: __{tool_name}__&#34;, state=&#39;complete&#39;):
                                st.text(json.dumps(tool_output, indent=4))
                            prompt.append(dict(role=&#39;function_call&#39;, content=str(tool_output)))
                            prompt = self.backend.prompt_template.create_custom_prompt(messages=prompt) + begin_text
                    placeholder = st.empty()
                    streamer = self.backend.llm.stream(prompt, stop=self.backend.prompt_template.stop, **self.backend.generation_config)
                    output = begin_text
                    placeholder.markdown(output.strip(&#39; \r\n\t&#39;))
                    for i in streamer:
                        output += i
                        placeholder.markdown(output.strip(&#39; \r\n\t&#39;))
                    self.backend.memory.save_interaction(user_input=self.input_config[&#39;user_input&#39;], assistant_output=output, **save_args)

                    # Change title if the title is New Chat
                    if self.backend.memory.title == &#39;New Chat&#39;:
                        pref = &#39;\n\nNote: This is the short title of this conversation: {&#34;title&#34;: &#39;
                        title = gen_string(self.backend.llm, prompt=prompt + output + pref, max_new_tokens=30)
                        if title != &#39;New Chat&#39;:
                            self.backend.memory.update_title(title)
                    st.session_state.input_config = None
                    st.session_state.generating = False
                    st.rerun()

    def historical_conversation(self) -&gt; None:
        &#34;&#34;&#34;Creating the historical conversation.
        &#34;&#34;&#34;
        import json
        history = self.backend.memory.history_dict
        for message in history:
            with st.chat_message(name=message[&#39;role&#39;]):
                fn_call = message.get(&#39;function_call&#39;)
                content = message[&#39;content&#39;]
                if fn_call is not None:
                    fn_name = fn_call[&#39;name&#39;].replace(&#39;_&#39;, &#39; &#39;).strip().title()
                    with st.status(label=f&#34;:hammer_and_pick: __{fn_name}__&#34;, state=&#39;complete&#39;):
                        st.code(json.dumps(fn_call, indent=4), language=&#39;plaintext&#39;)
                    if fn_call.get(&#39;output&#39;, dict()).get(&#39;footnote&#39;) is not None:
                        footnote = fn_call.get(&#39;output&#39;, dict()).get(&#39;footnote&#39;)
                        if isinstance(footnote, list):
                            footnote = &#39;  \n&#39;.join(footnote)
                        else:
                            footnote = str(footnote)
                        content += &#39;\n\n---\n&#39; + footnote
                st.markdown(content, help=f&#39;Number of tokens: {self.backend.llm.get_num_tokens(message[&#34;content&#34;])}&#39;)
        self.generation_message()

    def util_buttons(self) -&gt; None:
        &#34;&#34;&#34;Create utility buttons for text generation.
        &#34;&#34;&#34;
        def retry_response(mode):
            if self.backend.memory.interaction_count != 0:
                self.create_input_config(user_input=&#39;sample&#39;, begin_text=self.begin_text, generation_mode=mode)
                st.session_state.generating = True

        btns = row([1, 1, 1])
        btns.button(&#39;:arrows_counterclockwise:&#39;, use_container_width=True, help=&#39;Re-generate response&#39;, disabled=self.generating, 
                      on_click=retry_response, kwargs=dict(mode=&#39;retry&#39;))

        btns.button(&#39;:fast_forward:&#39;, use_container_width=True, help=&#39;Continue generating response&#39;, disabled=self.generating,
                      on_click=retry_response, kwargs=dict(mode=&#39;retry&#39;))

        btns.button(&#39;:wastebasket:&#39;, use_container_width=True, help=&#39;Remove the latest question and response&#39;, disabled=self.generating, 
                       on_click=self.backend.memory.remove_last_interaction)

    def input_box(self) -&gt; None:
        &#34;&#34;&#34;Creating the input box.
        &#34;&#34;&#34;
        with bottom():
            self.user_input = st.chat_input(placeholder=&#39;Your message...&#39;, disabled=self.generating)
            if self.enable_begin_text:
                self.begin_text = st.text_area(label=&#39;response_start&#39;, placeholder=&#39;Starting text of the response here...&#39;, value=self.begin_text_cache, label_visibility=&#39;collapsed&#39;)
            else:
                self.begin_text = &#39;&#39;

            if self.user_input:
                if self.user_input.strip() != &#39;&#39;:
                    self.create_input_config(user_input=self.user_input, begin_text=self.begin_text, generation_mode=&#39;new&#39;)
                    st.session_state.generating = True
                    st.rerun()

            if self.mobile:
                with st.expander(&#39;:gear: Extra options&#39;):
                    self.util_buttons()
            else:
                self.util_buttons()
            
    def chatbot(self) -&gt; None:
        &#34;&#34;&#34;Creating the chatbot interface.
        &#34;&#34;&#34;
        self.historical_conversation()
        self.input_box()

    def run(self) -&gt; None:
        &#34;&#34;&#34;Run the app.
        &#34;&#34;&#34;
        if self.is_login:
            self.sidebar()
            self.chatbot()
        else:
            self.login()</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.backend"><code class="name">var <span class="ident">backend</span> : <a title="llmflex.Frontend.app_resource.AppBackend" href="app_resource.html#llmflex.Frontend.app_resource.AppBackend">AppBackend</a></code></dt>
<dd>
<div class="desc"><p>Backend resources.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>AppBackend</code></dt>
<dd>Backend resources.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def backend(self) -&gt; AppBackend:
    &#34;&#34;&#34;Backend resources.

    Returns:
        AppBackend: Backend resources.
    &#34;&#34;&#34;
    return get_backend()</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.begin_text_cache"><code class="name">var <span class="ident">begin_text_cache</span> : str</code></dt>
<dd>
<div class="desc"><p>Begin text cache.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Begin text cache.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def begin_text_cache(self) -&gt; str:
    &#34;&#34;&#34;Begin text cache.

    Returns:
        str: Begin text cache.
    &#34;&#34;&#34;
    if not hasattr(st.session_state, &#39;begin_text_cache&#39;):
        st.session_state.begin_text_cache = &#39;&#39;
    return st.session_state.begin_text_cache</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.chat_delete_button"><code class="name">var <span class="ident">chat_delete_button</span> : bool</code></dt>
<dd>
<div class="desc"><p>Whether to show chat deletion buttons.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether to show chat deletion buttons.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def chat_delete_button(self) -&gt; bool:
    &#34;&#34;&#34;Whether to show chat deletion buttons.

    Returns:
        bool: Whether to show chat deletion buttons.
    &#34;&#34;&#34;
    if not hasattr(st.session_state, &#39;chat_delete_button&#39;):
        st.session_state.chat_delete_button = False
    return st.session_state.chat_delete_button</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.credentials"><code class="name">var <span class="ident">credentials</span> : Optional[Tuple[str, str]]</code></dt>
<dd>
<div class="desc"><p>Login credentials if provided.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Optional[Tuple[str, str]]</code></dt>
<dd>Login credentials if provided.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def credentials(self) -&gt; Optional[Tuple[str, str]]:
    &#34;&#34;&#34;Login credentials if provided.

    Returns:
        Optional[Tuple[str, str]]: Login credentials if provided.
    &#34;&#34;&#34;
    return self.backend.config.get(&#39;credentials&#39;)</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.enable_begin_text"><code class="name">var <span class="ident">enable_begin_text</span> : bool</code></dt>
<dd>
<div class="desc"><p>Whether on mobile device.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether on mobile device.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def enable_begin_text(self) -&gt; bool:
    &#34;&#34;&#34;Whether on mobile device.

    Returns:
        bool: Whether on mobile device.
    &#34;&#34;&#34;
    if not hasattr(st.session_state, &#39;enable_begin_text&#39;):
        st.session_state.enable_begin_text = False
    return st.session_state.enable_begin_text</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.generating"><code class="name">var <span class="ident">generating</span> : bool</code></dt>
<dd>
<div class="desc"><p>Whether text generation in progress.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether text generation in progress.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def generating(self) -&gt; bool:
    &#34;&#34;&#34;Whether text generation in progress.

    Returns:
        bool: Whether text generation in progress.
    &#34;&#34;&#34;
    if not hasattr(st.session_state, &#39;generating&#39;):
        st.session_state.generating = False
    return st.session_state.generating</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.input_config"><code class="name">var <span class="ident">input_config</span> : Optional[Dict[str, Any]]</code></dt>
<dd>
<div class="desc"><p>Configuration for text generation if available.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Optional[Dict[str, Any]]</code></dt>
<dd>Configuration for text generation if available.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def input_config(self) -&gt; Optional[Dict[str, Any]]:
    &#34;&#34;&#34;Configuration for text generation if available.

    Returns:
        Optional[Dict[str, Any]]: Configuration for text generation if available.
    &#34;&#34;&#34;
    if hasattr(st.session_state, &#39;input_config&#39;):
        return st.session_state.input_config</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.is_login"><code class="name">var <span class="ident">is_login</span> : bool</code></dt>
<dd>
<div class="desc"><p>Whether it is logged in or not.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether it is logged in or not.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def is_login(self) -&gt; bool:
    &#34;&#34;&#34;Whether it is logged in or not.

    Returns:
        bool: Whether it is logged in or not.
    &#34;&#34;&#34;
    if not hasattr(st.session_state, &#39;is_login&#39;):
        st.session_state.is_login = False if self.credentials is not None else True
    return st.session_state.is_login</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.mobile"><code class="name">var <span class="ident">mobile</span> : bool</code></dt>
<dd>
<div class="desc"><p>Whether on mobile device.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether on mobile device.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def mobile(self) -&gt; bool:
    &#34;&#34;&#34;Whether on mobile device.

    Returns:
        bool: Whether on mobile device.
    &#34;&#34;&#34;
    if not hasattr(st.session_state, &#39;mobile&#39;):
        st.session_state.mobile = False
    return st.session_state.mobile</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.begin_text_settings"><code class="name flex">
<span>def <span class="ident">begin_text_settings</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create toggle button for response starting text.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def begin_text_settings(self) -&gt; None:
    &#34;&#34;&#34;Create toggle button for response starting text.
    &#34;&#34;&#34;
    def toggle_begin_text() -&gt; None:
        st.session_state.enable_begin_text = not st.session_state.enable_begin_text
    st.toggle(label=&#39;Response Edit&#39;, value=self.enable_begin_text, help=&#39;Toggle mobile mode.&#39;, on_change=toggle_begin_text, disabled=self.generating) </code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.chatbot"><code class="name flex">
<span>def <span class="ident">chatbot</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Creating the chatbot interface.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chatbot(self) -&gt; None:
    &#34;&#34;&#34;Creating the chatbot interface.
    &#34;&#34;&#34;
    self.historical_conversation()
    self.input_box()</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.chats"><code class="name flex">
<span>def <span class="ident">chats</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Listing all conversations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chats(self) -&gt; None:
    &#34;&#34;&#34;Listing all conversations.
    &#34;&#34;&#34;
    st.button(label=&#39;:heavy_plus_sign: Start a new conversation&#39;, key=f&#39;new_chat&#39;, use_container_width=True, on_click=self.backend.create_memory, disabled=self.generating)

    active_chat_id = self.backend.memory.chat_id
    ids = list_chat_ids()

    def toggle_delete_chats():
        st.session_state.chat_delete_button = not st.session_state.chat_delete_button

    if self.chat_delete_button:
        convs = dict()
        for id in ids:
            btn_type = &#39;primary&#39; if id == active_chat_id else &#39;secondary&#39;
            real_title = get_title_from_id(id)
            title = real_title.replace(&#39;_&#39;, &#39; &#39;).title()
            if len(title) &gt; 20:
                title = title[:20] + &#39;...&#39;
            convs[id] = row(spec=[0.8, 0.2])
            convs[id].button(label=title, key=id, type=btn_type, use_container_width=True, 
                             on_click=self.backend.switch_memory, kwargs=dict(chat_id=id), disabled=self.generating, help=real_title)
            convs[id].button(label=&#39;:heavy_minus_sign:&#39;, key=f&#39;del_{id}&#39;, use_container_width=True, 
                             on_click=self.backend.drop_memory, kwargs=dict(chat_id=id), disabled=self.generating)
    else:
        for id in ids:
            btn_type = &#39;primary&#39; if id == active_chat_id else &#39;secondary&#39;
            real_title = get_title_from_id(id)
            title = real_title.replace(&#39;_&#39;, &#39; &#39;).title()
            if len(title) &gt; 25:
                title = title[:25] + &#39;...&#39;
            st.button(label=title, key=id, type=btn_type, use_container_width=True, 
                      on_click=self.backend.switch_memory, kwargs=dict(chat_id=id), disabled=self.generating, help=real_title)
    st.toggle(label=&#39;:wastebasket:&#39;, key=f&#39;conv_delete&#39;, disabled=self.generating, 
            value=self.chat_delete_button, on_change=toggle_delete_chats, help=&#39;Select conversations to remove.&#39;)</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.create_input_config"><code class="name flex">
<span>def <span class="ident">create_input_config</span></span>(<span>self, user_input: str, begin_text: str, generation_mode: Literal['new', 'retry', 'continue']) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create everything needed for the next generation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>user_input</code></strong> :&ensp;<code>str</code></dt>
<dd>User request.</dd>
<dt><strong><code>begin_text</code></strong> :&ensp;<code>str</code></dt>
<dd>Starting text of the response.</dd>
</dl>
<p>generation_mode (Literal[&#39;new&#39;, &#39;retry&#39;, &#39;continue&#39;]): Mode of generation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_input_config(self, user_input: str, begin_text: str, generation_mode: Literal[&#39;new&#39;, &#39;retry&#39;, &#39;continue&#39;]) -&gt; None:
    &#34;&#34;&#34;Create everything needed for the next generation.

    Args:
        user_input (str): User request.
        begin_text (str): Starting text of the response.
        generation_mode (Literal[&amp;#39;new&amp;#39;, &amp;#39;retry&amp;#39;, &amp;#39;continue&amp;#39;]): Mode of generation.
    &#34;&#34;&#34;
    new_input = user_input.strip()
    ai_start = begin_text.lstrip()
    if generation_mode != &#39;new&#39;:
        last_record = self.backend.memory.history[-1]
        new_input = last_record[0]
        if generation_mode == &#39;continue&#39;:
            ai_start = last_record[1]
        self.backend.memory.remove_last_interaction()
    prompt_args = dict(
        llm=self.backend.llm,
        memory=self.backend.memory,
        user_input=new_input,
        prompt_template=self.backend.prompt_template,
        system=self.backend.memory.system,
        recent_token_limit=self.backend.memory_config[&#39;recent_token_limit&#39;],
        relevant_token_limit=self.backend.memory_config[&#39;relevant_token_limit&#39;],
        relevance_score_threshold=self.backend.memory_config[&#39;relevance_score_threshold&#39;],
        similarity_score_threshold=self.backend.memory_config[&#39;similarity_score_threshold&#39;]
    )
    if ai_start.strip() != &#39;&#39;:
        prompt = create_prompt_with_history(**prompt_args) + ai_start
        st.session_state.begin_text_cache = ai_start
    elif ((not self.backend.tool_selector.is_empty) &amp; (self.backend.prompt_template.allow_custom_role)):
        prompt_args[&#39;tool_selector&#39;] = self.backend.tool_selector
        prompt = create_prompt_with_history(**prompt_args)
    else:
        prompt = create_prompt_with_history(**prompt_args)
    
    st.session_state.input_config = dict(
        prompt=prompt,
        user_input=new_input,
        begin_text=ai_start,
        mode=generation_mode
    )</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.generation_message"><code class="name flex">
<span>def <span class="ident">generation_message</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create streaming message.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generation_message(self) -&gt; None:
    &#34;&#34;&#34;Create streaming message.
    &#34;&#34;&#34;
    import json
    if self.input_config is not None:
        import os
        from ..utils import current_time, save_json
        logfilename = os.path.join(self.log_dir, f&#39;{self.backend.memory.chat_id}_{current_time()}.json&#39;)
        save_json(content=self.input_config, file_dir=logfilename)
        with st.chat_message(name=&#39;user&#39;):
            st.markdown(self.input_config[&#39;user_input&#39;])
        with st.chat_message(name=&#39;assistant&#39;):
            with st.spinner(&#39;Thinking....&#39;):
                prompt = self.input_config[&#39;prompt&#39;]
                begin_text = self.input_config[&#39;begin_text&#39;]
                save_args = dict()
                if not isinstance(prompt, str):
                    tool_input = self.backend.tool_selector.tool_call_input(llm=self.backend.llm, messages=prompt, prompt_template=self.backend.prompt_template, **self.backend.generation_config)
                    if tool_input[&#39;name&#39;] == &#39;direct_response&#39;:
                        prompt = self.backend.prompt_template.create_custom_prompt(messages=prompt) + begin_text
                    else:
                        toolholder = st.empty()
                        tool_name = tool_input[&#39;name&#39;].replace(&#39;_&#39;, &#39; &#39;).title().strip()
                        with toolholder.status(label=f&#34;:hammer_and_pick: Running __{tool_name}__...&#34;, state=&#39;running&#39;):
                            st.text(json.dumps(tool_input, indent=4))
                            tool_output = self.backend.tool_selector.tool_call_output(tool_input=tool_input, return_error=True)
                            save_args[&#39;function_call&#39;] = tool_output
                        with toolholder.status(label=f&#34;:hammer_and_pick: __{tool_name}__&#34;, state=&#39;complete&#39;):
                            st.text(json.dumps(tool_output, indent=4))
                        prompt.append(dict(role=&#39;function_call&#39;, content=str(tool_output)))
                        prompt = self.backend.prompt_template.create_custom_prompt(messages=prompt) + begin_text
                placeholder = st.empty()
                streamer = self.backend.llm.stream(prompt, stop=self.backend.prompt_template.stop, **self.backend.generation_config)
                output = begin_text
                placeholder.markdown(output.strip(&#39; \r\n\t&#39;))
                for i in streamer:
                    output += i
                    placeholder.markdown(output.strip(&#39; \r\n\t&#39;))
                self.backend.memory.save_interaction(user_input=self.input_config[&#39;user_input&#39;], assistant_output=output, **save_args)

                # Change title if the title is New Chat
                if self.backend.memory.title == &#39;New Chat&#39;:
                    pref = &#39;\n\nNote: This is the short title of this conversation: {&#34;title&#34;: &#39;
                    title = gen_string(self.backend.llm, prompt=prompt + output + pref, max_new_tokens=30)
                    if title != &#39;New Chat&#39;:
                        self.backend.memory.update_title(title)
                st.session_state.input_config = None
                st.session_state.generating = False
                st.rerun()</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.historical_conversation"><code class="name flex">
<span>def <span class="ident">historical_conversation</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Creating the historical conversation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def historical_conversation(self) -&gt; None:
    &#34;&#34;&#34;Creating the historical conversation.
    &#34;&#34;&#34;
    import json
    history = self.backend.memory.history_dict
    for message in history:
        with st.chat_message(name=message[&#39;role&#39;]):
            fn_call = message.get(&#39;function_call&#39;)
            content = message[&#39;content&#39;]
            if fn_call is not None:
                fn_name = fn_call[&#39;name&#39;].replace(&#39;_&#39;, &#39; &#39;).strip().title()
                with st.status(label=f&#34;:hammer_and_pick: __{fn_name}__&#34;, state=&#39;complete&#39;):
                    st.code(json.dumps(fn_call, indent=4), language=&#39;plaintext&#39;)
                if fn_call.get(&#39;output&#39;, dict()).get(&#39;footnote&#39;) is not None:
                    footnote = fn_call.get(&#39;output&#39;, dict()).get(&#39;footnote&#39;)
                    if isinstance(footnote, list):
                        footnote = &#39;  \n&#39;.join(footnote)
                    else:
                        footnote = str(footnote)
                    content += &#39;\n\n---\n&#39; + footnote
            st.markdown(content, help=f&#39;Number of tokens: {self.backend.llm.get_num_tokens(message[&#34;content&#34;])}&#39;)
    self.generation_message()</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.input_box"><code class="name flex">
<span>def <span class="ident">input_box</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Creating the input box.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def input_box(self) -&gt; None:
    &#34;&#34;&#34;Creating the input box.
    &#34;&#34;&#34;
    with bottom():
        self.user_input = st.chat_input(placeholder=&#39;Your message...&#39;, disabled=self.generating)
        if self.enable_begin_text:
            self.begin_text = st.text_area(label=&#39;response_start&#39;, placeholder=&#39;Starting text of the response here...&#39;, value=self.begin_text_cache, label_visibility=&#39;collapsed&#39;)
        else:
            self.begin_text = &#39;&#39;

        if self.user_input:
            if self.user_input.strip() != &#39;&#39;:
                self.create_input_config(user_input=self.user_input, begin_text=self.begin_text, generation_mode=&#39;new&#39;)
                st.session_state.generating = True
                st.rerun()

        if self.mobile:
            with st.expander(&#39;:gear: Extra options&#39;):
                self.util_buttons()
        else:
            self.util_buttons()</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.login"><code class="name flex">
<span>def <span class="ident">login</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Creating login page.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def login(self) -&gt; None:
    &#34;&#34;&#34;Creating login page.
    &#34;&#34;&#34;
    login_form = st.form(key=&#39;login&#39;)
    with login_form:
        user = st.text_input(label=&#39;Username:&#39;, placeholder=&#39;Your username...&#39;)
        password = st.text_input(label=&#39;Password&#39;, placeholder=&#39;Your password...&#39;, type=&#39;password&#39;)
        if st.form_submit_button(label=&#39;Login&#39;):
            if ((user == self.credentials[0]) &amp; (password == self.credentials[1])):
                st.session_state.is_login = True
                st.rerun()
            else:
                st.warning(&#39;Incorrect credentials. Please try again.&#39;)</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.memory_settings"><code class="name flex">
<span>def <span class="ident">memory_settings</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create settings for memory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memory_settings(self) -&gt; None:
    &#34;&#34;&#34;Create settings for memory.
    &#34;&#34;&#34;
    self.short_limit_slidder = st.slider(&#39;Short term memory token limit&#39;, min_value=0, max_value=10000, step=1, 
            value=self.backend.memory_config[&#39;recent_token_limit&#39;], disabled=self.generating)
    self.long_limit_slidder = st.slider(&#39;Long term memory token limit&#39;, min_value=0, max_value=6000, step=1, 
            value=self.backend.memory_config[&#39;relevant_token_limit&#39;], disabled=self.generating)
    self.rel_score_threshold_slidder = st.slider(&#39;Relevance score threshold for long term memory&#39;, min_value=0.0, max_value=1.0, step=0.01,
            value=self.backend.memory_config[&#39;relevance_score_threshold&#39;], disabled=self.generating)
    self.sim_score_threshold_slidder = st.slider(&#39;Similarity score threshold for long term memory&#39;, min_value=0.0, max_value=1.0, step=0.01,
            value=self.backend.memory_config[&#39;similarity_score_threshold&#39;], disabled=self.generating)
    summary = [
        &#39;Current settings:&#39;,
        f&#34;Short term memory token limit: {self.backend.memory_config[&#39;recent_token_limit&#39;]}&#34;,
        f&#34;Long term memory token limit: {self.backend.memory_config[&#39;relevant_token_limit&#39;]}&#34;,
        f&#34;Relevance score threshold: {self.backend.memory_config[&#39;relevance_score_threshold&#39;]}&#34;,
        f&#34;Similarity score threshold: {self.backend.memory_config[&#39;similarity_score_threshold&#39;]}&#34;

    ]
    st.markdown(&#39;  \n&#39;.join(summary))
    st.button(label=&#39;:floppy_disk:&#39;, key=&#39;memory_token_save&#39;, disabled=self.generating, 
              use_container_width=True,
              on_click=self.backend.set_memory_config,
              kwargs=dict(recent_token_limit=self.short_limit_slidder,
                          relevant_token_limit=self.long_limit_slidder,
                          relevance_score_threshold=self.rel_score_threshold_slidder,
                          similarity_score_threshold=self.sim_score_threshold_slidder))</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.mobile_settings"><code class="name flex">
<span>def <span class="ident">mobile_settings</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create toggle button for mobile mode.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mobile_settings(self) -&gt; None:
    &#34;&#34;&#34;Create toggle button for mobile mode.
    &#34;&#34;&#34;
    def toggle_mobile() -&gt; None:
        st.session_state.mobile = not st.session_state.mobile
    st.toggle(label=&#39;Mobile&#39;, value=self.mobile, help=&#39;Toggle mobile mode.&#39;, on_change=toggle_mobile, disabled=self.generating) </code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.model_settings"><code class="name flex">
<span>def <span class="ident">model_settings</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create settings for text generation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def model_settings(self) -&gt; None:
    &#34;&#34;&#34;Create settings for text generation.
    &#34;&#34;&#34;
    self.temperature_slidder = st.slider(&#39;Temparature&#39;, min_value=0.0, max_value=2.0, step=0.01, value=self.backend.generation_config[&#39;temperature&#39;], disabled=self.generating)
    self.max_new_token_slidder = st.slider(&#39;Maximum number of new tokens&#39;, min_value=0, max_value=4096, step=1, value=self.backend.generation_config[&#39;max_new_tokens&#39;], disabled=self.generating)
    self.repetition_slidder = st.slider(&#39;Repetition penalty&#39;, min_value=1.0, max_value=2.0, step=0.01, value=self.backend.generation_config[&#39;repetition_penalty&#39;], disabled=self.generating)
    self.topp_slidder = st.slider(&#39;Top P&#39;, min_value=0.0, max_value=1.0, step=0.01, value=self.backend.generation_config[&#39;top_p&#39;], disabled=self.generating)
    self.topk_slidder = st.slider(&#39;Top K&#39;, min_value=0, max_value=30000, step=1, value=self.backend.generation_config[&#39;top_k&#39;], disabled=self.generating)
    summary = [
        &#39;Current settings:&#39;,
        f&#34;Temperature: {self.backend.generation_config[&#39;temperature&#39;]}&#34;,
        f&#34;Max new tokens: {self.backend.generation_config[&#39;max_new_tokens&#39;]}&#34;,
        f&#34;Repetition penalty: {self.backend.generation_config[&#39;repetition_penalty&#39;]}&#34;,
        f&#34;Top P: {self.backend.generation_config[&#39;top_p&#39;]}&#34;,
        f&#34;Top K: {self.backend.generation_config[&#39;top_k&#39;]}&#34;,
    ]
    st.markdown(&#39;  \n&#39;.join(summary))
    st.button(label=&#39;:floppy_disk:&#39;, 
              key=&#39;llm_config_save&#39;, 
              disabled=self.generating, 
              use_container_width=True,
              on_click=self.backend.set_generation_config,
              kwargs=dict(temperature=self.temperature_slidder,
                          max_new_tokens=self.max_new_token_slidder,
                          repetition_penalty=self.repetition_slidder,
                          top_p=self.topp_slidder,
                          top_k=self.topk_slidder))</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.prompt_format_settings"><code class="name flex">
<span>def <span class="ident">prompt_format_settings</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Prompt format settings.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prompt_format_settings(self) -&gt; None:
    &#34;&#34;&#34;Prompt format settings.
    &#34;&#34;&#34;
    def set_prompt_template() -&gt; None:
        if st.session_state.prompt_format in presets.keys():
            self.backend.set_prompt_template(st.session_state.prompt_format)
        else:
            self.backend._prompt_template = self.backend.factory.prompt_template
    options = list(presets.keys())
    if self.backend.prompt_template.template_name not in options:
        options.append(self.backend.prompt_template.template_name)
    option_index_dict = dict(zip(options, range(len(options))))
    current_index = option_index_dict.get(self.backend.prompt_template.template_name)
    prompt_format = st.selectbox(
        label=&#39;prompt_formats&#39;, 
        label_visibility=&#39;collapsed&#39;,
        key=&#39;prompt_format&#39;,
        options=options, 
        disabled=self.generating, 
        index=current_index,
        on_change=set_prompt_template
    )
    if not self.backend.prompt_template.allow_custom_role:
        st.warning(&#39;Current prompt format does not support function calling.&#39;)</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Run the app.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self) -&gt; None:
    &#34;&#34;&#34;Run the app.
    &#34;&#34;&#34;
    if self.is_login:
        self.sidebar()
        self.chatbot()
    else:
        self.login()</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.settings"><code class="name flex">
<span>def <span class="ident">settings</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Creating the settings.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def settings(self) -&gt; None:
    &#34;&#34;&#34;Creating the settings.
    &#34;&#34;&#34;
    page_dict = {
        &#39;Prompt Format Settings&#39;: self.prompt_format_settings, 
        &#39;System Message Settings&#39;: self.system_message_setttings, 
        &#39;Memory Settings&#39;: self.memory_settings, 
        &#39;Model Settings&#39;: self.model_settings
        }
    if self.backend.has_tools:
        page_dict[&#39;Tool Settings&#39;] = self.tool_settings
    self.mobile_settings()
    self.begin_text_settings()
    setting_dropdown = st.selectbox(
        label = &#39;Setting dropdown&#39;,
        label_visibility=&#39;collapsed&#39;,
        options= list(page_dict.keys())
    )
    st.markdown(setting_dropdown + &#39;:&#39;)
    page_dict[setting_dropdown]()</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.sidebar"><code class="name flex">
<span>def <span class="ident">sidebar</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Creating the sidebar.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sidebar(self) -&gt; None:
    &#34;&#34;&#34;Creating the sidebar.
    &#34;&#34;&#34;
    with st.sidebar:
        app_summary = [&#39;Powered by:&#39;, 
                    f&#39;* LLM: {self.backend.factory.model_id}&#39;, 
                    f&#39;* Embedding model: {self.backend.embeddings.name}&#39;, 
                    &#39;&#39;, 
                    &#39;Current conversation:&#39;, 
                    f&#39;* {self.backend.memory.title}&#39;,
                    &#39;&#39;,
                    &#39;Current prompt format:&#39;,
                    f&#39;* {self.backend.prompt_template.template_name}&#39;]
        st.header(PACKAGE_DISPLAY_NAME.upper(), help=&#39;  \n&#39;.join(app_summary), divider=&#34;grey&#34;)
        with st.expander(label=&#39;:left_speech_bubble: Conversations&#39;, expanded=True):
            self.chats()

        with st.expander(label=&#39;:gear: Settings&#39;, expanded=False):
            self.settings()</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.system_message_setttings"><code class="name flex">
<span>def <span class="ident">system_message_setttings</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create settings for system message.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_message_setttings(self) -&gt; None:
    &#34;&#34;&#34;Create settings for system message.
    &#34;&#34;&#34;
    self.system_text = st.text_area(label=&#39;System message&#39;, height=250, key=&#39;system_msg&#39;,label_visibility=&#39;collapsed&#39;, value=self.backend.memory.system, disabled=self.generating)
    st.markdown(f&#39;System message token count: {self.backend.llm.get_num_tokens(self.backend.memory.system)}&#39;)
    st.button(label=&#39;:floppy_disk:&#39;, key=&#39;system_save&#39;, disabled=self.generating, use_container_width=True, on_click=self.backend.set_system_message, kwargs=dict(system=self.system_text))</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.tool_settings"><code class="name flex">
<span>def <span class="ident">tool_settings</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create settings for tools.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tool_settings(self) -&gt; None:
    &#34;&#34;&#34;Create settings for tools.
    &#34;&#34;&#34;
    for k, v in self.backend.tool_status.items():
        pretty_name = k.replace(&#39;_&#39;, &#39; &#39;).strip().title()
        st.toggle(label=f&#39;{pretty_name}&#39;, value=v, on_change=self.backend.toggle_tool, kwargs=dict(tool_name=k),
                    disabled=self.generating)</code></pre>
</details>
</dd>
<dt id="llmflex.Frontend.streamlit_interface.AppInterface.util_buttons"><code class="name flex">
<span>def <span class="ident">util_buttons</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Create utility buttons for text generation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def util_buttons(self) -&gt; None:
    &#34;&#34;&#34;Create utility buttons for text generation.
    &#34;&#34;&#34;
    def retry_response(mode):
        if self.backend.memory.interaction_count != 0:
            self.create_input_config(user_input=&#39;sample&#39;, begin_text=self.begin_text, generation_mode=mode)
            st.session_state.generating = True

    btns = row([1, 1, 1])
    btns.button(&#39;:arrows_counterclockwise:&#39;, use_container_width=True, help=&#39;Re-generate response&#39;, disabled=self.generating, 
                  on_click=retry_response, kwargs=dict(mode=&#39;retry&#39;))

    btns.button(&#39;:fast_forward:&#39;, use_container_width=True, help=&#39;Continue generating response&#39;, disabled=self.generating,
                  on_click=retry_response, kwargs=dict(mode=&#39;retry&#39;))

    btns.button(&#39;:wastebasket:&#39;, use_container_width=True, help=&#39;Remove the latest question and response&#39;, disabled=self.generating, 
                   on_click=self.backend.memory.remove_last_interaction)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="llmflex.Frontend" href="index.html">llmflex.Frontend</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="llmflex.Frontend.streamlit_interface.create_streamlit_script" href="#llmflex.Frontend.streamlit_interface.create_streamlit_script">create_streamlit_script</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.get_backend" href="#llmflex.Frontend.streamlit_interface.get_backend">get_backend</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="llmflex.Frontend.streamlit_interface.AppInterface" href="#llmflex.Frontend.streamlit_interface.AppInterface">AppInterface</a></code></h4>
<ul class="">
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.backend" href="#llmflex.Frontend.streamlit_interface.AppInterface.backend">backend</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.begin_text_cache" href="#llmflex.Frontend.streamlit_interface.AppInterface.begin_text_cache">begin_text_cache</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.begin_text_settings" href="#llmflex.Frontend.streamlit_interface.AppInterface.begin_text_settings">begin_text_settings</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.chat_delete_button" href="#llmflex.Frontend.streamlit_interface.AppInterface.chat_delete_button">chat_delete_button</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.chatbot" href="#llmflex.Frontend.streamlit_interface.AppInterface.chatbot">chatbot</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.chats" href="#llmflex.Frontend.streamlit_interface.AppInterface.chats">chats</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.create_input_config" href="#llmflex.Frontend.streamlit_interface.AppInterface.create_input_config">create_input_config</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.credentials" href="#llmflex.Frontend.streamlit_interface.AppInterface.credentials">credentials</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.enable_begin_text" href="#llmflex.Frontend.streamlit_interface.AppInterface.enable_begin_text">enable_begin_text</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.generating" href="#llmflex.Frontend.streamlit_interface.AppInterface.generating">generating</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.generation_message" href="#llmflex.Frontend.streamlit_interface.AppInterface.generation_message">generation_message</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.historical_conversation" href="#llmflex.Frontend.streamlit_interface.AppInterface.historical_conversation">historical_conversation</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.input_box" href="#llmflex.Frontend.streamlit_interface.AppInterface.input_box">input_box</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.input_config" href="#llmflex.Frontend.streamlit_interface.AppInterface.input_config">input_config</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.is_login" href="#llmflex.Frontend.streamlit_interface.AppInterface.is_login">is_login</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.login" href="#llmflex.Frontend.streamlit_interface.AppInterface.login">login</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.memory_settings" href="#llmflex.Frontend.streamlit_interface.AppInterface.memory_settings">memory_settings</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.mobile" href="#llmflex.Frontend.streamlit_interface.AppInterface.mobile">mobile</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.mobile_settings" href="#llmflex.Frontend.streamlit_interface.AppInterface.mobile_settings">mobile_settings</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.model_settings" href="#llmflex.Frontend.streamlit_interface.AppInterface.model_settings">model_settings</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.prompt_format_settings" href="#llmflex.Frontend.streamlit_interface.AppInterface.prompt_format_settings">prompt_format_settings</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.run" href="#llmflex.Frontend.streamlit_interface.AppInterface.run">run</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.settings" href="#llmflex.Frontend.streamlit_interface.AppInterface.settings">settings</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.sidebar" href="#llmflex.Frontend.streamlit_interface.AppInterface.sidebar">sidebar</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.system_message_setttings" href="#llmflex.Frontend.streamlit_interface.AppInterface.system_message_setttings">system_message_setttings</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.tool_settings" href="#llmflex.Frontend.streamlit_interface.AppInterface.tool_settings">tool_settings</a></code></li>
<li><code><a title="llmflex.Frontend.streamlit_interface.AppInterface.util_buttons" href="#llmflex.Frontend.streamlit_interface.AppInterface.util_buttons">util_buttons</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>