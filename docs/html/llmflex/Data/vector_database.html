<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>llmflex.Data.vector_database API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>llmflex.Data.vector_database</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from __future__ import annotations
import os
from ..Embeddings.base_embeddings import BaseEmbeddingsToolkit
from langchain.schema.document import Document
from langchain.text_splitter import TextSplitter
import pandas as pd
from typing import List, Optional, Type, Dict, Any, Union

def default_vectordb_dir() -&gt; str:
    &#34;&#34;&#34;Default home directory of vector databases.

    Returns:
        str: Default home directory of vector databases.
    &#34;&#34;&#34;
    from ..utils import get_config
    home = os.path.join(get_config()[&#39;package_home&#39;], &#39;vector_databases&#39;)
    if not os.path.exists(home):
        os.makedirs(home)
    return home

def list_vectordbs(vectordb_dir: Optional[str] = None) -&gt; List[str]:
    &#34;&#34;&#34;List all the vector databases in the given directory.

    Args:
        vectordb_dir (Optional[str], optional): Directory where the vector databases live. If None is given, the default_vectordb_dir will be used. Defaults to None.

    Returns:
        List[str]: List all the vector databases in the given directory.
    &#34;&#34;&#34;
    vectordb_dir = vectordb_dir if ((isinstance(vectordb_dir, str)) &amp; (os.path.exists(vectordb_dir))) else default_vectordb_dir()
    dbs = list(filter(lambda x: os.path.isdir(os.path.join(vectordb_dir, x)), os.listdir(vectordb_dir)))
    dbs = list(filter(lambda x: os.path.exists(os.path.join(vectordb_dir, x, &#39;info.json&#39;)), dbs))
    return dbs

def name_checker(name: str) -&gt; str:
    &#34;&#34;&#34;Raise error if the given string has space, newline characters, or tab characters.

    Args:
        name (str): String to check.

    Returns:
        str: Return the given text if it passes all the checkes.
    &#34;&#34;&#34;
    if &#39; &#39; in name:
        raise ValueError(f&#39;Spaces cannot be in the name&#39;)
    if &#39;\n&#39; in name:
        raise ValueError(f&#39;Newline characters cannot be in the name.&#39;)
    if &#39;\r&#39; in name:
        raise ValueError(f&#39;Newline characters cannot be in the name.&#39;)
    if &#39;\t&#39; in name:
        raise ValueError(f&#39;Tab characters cannot be in the name.&#39;)
    return name
        
def texts_to_documents(texts: List[str], 
        embeddings: Optional[Type[BaseEmbeddingsToolkit]] = None,
        text_splitter: Optional[Type[TextSplitter]] = None,
        data: Optional[Union[pd.DataFrame, List[Dict[str, Any]], Dict[str, Any]]] = None,
        split_text: bool = True) -&gt; List[Document]:
    &#34;&#34;&#34;Create splitted documents from the list of text strings.

    Args:
        texts (List[str]): List of strings to split into documents.
        embeddings (Optional[Type[BaseEmbeddingsToolkit]], optional): Embedding toolkit used to split the documents. Defaults to None
        text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
        data (Optional[Union[pd.DataFrame, List[Dict[str, Any]], Dict[str, Any]]], optional): Metadata for each text strings. Defaults to None.
        split_text (bool, optional): Whether to split text if the given text is too long. Defaults to True.

    Returns:
        List[Document]: List of splitted documents.
    &#34;&#34;&#34;
    if type(data) == pd.DataFrame:
        data = data.to_dict(&#39;records&#39;)
    elif type(data) == dict:
        data = [data] * len(texts)
    elif data is None:
        data = [dict()] * len(texts)
    
    docs = list(map(lambda x: Document(page_content=x[0], metadata=x[1]), list(zip(texts, data))))
    if split_text:
        if text_splitter is not None:
            docs = text_splitter.split_documents(docs)
        elif embeddings is not None:
            docs = embeddings.text_splitter.split_documents(docs)
        else:
            raise RuntimeError(&#39;Either embeddings or text_splitter has to be provided if split_text=True.&#39;)
    return docs

class VectorDatabase:
    &#34;&#34;&#34;Vector database class, suitable for storing text data as embeddings for similarity searches and other classes that requires numerical respresentations of texts.
    &#34;&#34;&#34;

    def __init__(self, embeddings: Type[BaseEmbeddingsToolkit], 
                 vectordb_dir: Optional[str] = None, name: Optional[str] = None,
                 save_raw: bool = False) -&gt; None:
        &#34;&#34;&#34;Initialising basic information of the vector database.

        Args:
            embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkits used in the vector database.
            vectordb_dir (Optional[str], optional): Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.
            name (Optional[str], optional): Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.
            save_raw (bool, optional): Whether to save raw text data and metadata as a separate json file. Defaults to False.
        &#34;&#34;&#34;
        self._name = &#39;_InMemoryVectorDB_&#39; if name is None else name_checker(name)
        self._embeddings = embeddings
        self._vectordb_dir = default_vectordb_dir() if vectordb_dir is None else os.path.abspath(vectordb_dir)
        self._save_raw = save_raw

    @property
    def name(self) -&gt; str:
        &#34;&#34;&#34;Name of the vector database.

        Returns:
            str: Name of the vector database.
        &#34;&#34;&#34;
        return self._name
    
    @property
    def embeddings(self) -&gt; Type[BaseEmbeddingsToolkit]:
        &#34;&#34;&#34;Embeddings toolkit used in the vector database.

        Returns:
            Type[BaseEmbeddingsToolkit]: Embeddings toolkit used in the vector database.
        &#34;&#34;&#34;
        return self._embeddings
    
    @property
    def vdb_dir(self) -&gt; Union[str, None]:
        &#34;&#34;&#34;Directory of the vector database if it is not in-memory only.

        Returns:
            Union[str, None]: Directory of the vector database if it is not in-memory only.
        &#34;&#34;&#34;
        if self.name != &#39;_InMemoryVectorDB_&#39;:
            vdb_dir = os.path.join(self._vectordb_dir, self.name)
            os.makedirs(vdb_dir, exist_ok=True)
            return vdb_dir
        else:
            return None

    @property
    def save_raw(self) -&gt; bool:
        &#34;&#34;&#34;Whether to save the raw data as json or not.

        Returns:
            bool: Whether to save the raw data as json or not.
        &#34;&#34;&#34;
        return self._save_raw
    
    @property
    def info(self) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Information of the vector database.

        Returns:
            Dict[str, Any]: Information of the vector database.
        &#34;&#34;&#34;
        if hasattr(self, &#39;_info&#39;):
            return self._info
        elif ((self.vdb_dir is not None) &amp; (&#39;info.json&#39; in os.listdir(self.vdb_dir))):
            from ..utils import read_json
            self._info = read_json(os.path.join(self.vdb_dir, &#39;info.json&#39;))
            return self._info
        else:
            from ..utils import save_json, current_time
            self._info = dict(embeddings=self.embeddings.name, last_update=current_time())
            if self.save_raw:
                save_json(self._info, os.path.join(self.vdb_dir, &#39;info.json&#39;))
            return self._info
        
    @property
    def vectorstore(self) -&gt; &#34;FAISS&#34;:
        &#34;&#34;&#34;Return the faiss vectorstore

        Returns:
            FAISS: The vector store.
        &#34;&#34;&#34;
        return self._vectorstore
    
    @property
    def data(self) -&gt; List[Dict[str, Any]]:
        &#34;&#34;&#34;Raw data of the vector database.

        Returns:
            List[Dict[str, Any]]: Raw data of the vector database.
        &#34;&#34;&#34;
        data = list(self._vectorstore.docstore._dict.values())
        data = list(map(lambda x: dict(index=x.page_content, metadata=x.metadata), data))
        return data
    
    @property
    def size(self) -&gt; int:
        &#34;&#34;&#34;Number of embeddings in the vector database. May be more than the number of texts you have added into the database due to text splitting for longer texts.

        Returns:
            int: Number of embeddings.
        &#34;&#34;&#34;
        return len(self.data)
        
    def _init_vectordb(self, embeddings: Type[BaseEmbeddingsToolkit], from_exist: bool = True) -&gt; None:
        &#34;&#34;&#34;Initialise the langchain vectorstore

        Args:
            from_exist (bool, optional): Whether to initialise from an existing vectorstore. Defaults to True.
        &#34;&#34;&#34;
        from langchain.vectorstores.faiss import FAISS
        import faiss
        import warnings
        warnings.filterwarnings(&#39;ignore&#39;)
        if ((from_exist) &amp; (self.name in list_vectordbs(self._vectordb_dir))):
            if (self.info.get(&#39;embeddings&#39;, &#39;NOT_AVAIALBLE&#39;) == embeddings.name):
                self._vectorstore = FAISS.load_local(folder_path=self.vdb_dir, embeddings=embeddings.embedding_model)
            elif &#39;data.json&#39; in os.listdir(self.vdb_dir):
                from ..utils import read_json
                data = read_json(os.path.join(self.vdb_dir, &#39;data.json&#39;))
                docs = texts_to_documents(texts=list(map(lambda x: x[&#39;index&#39;], data)), 
                                          embeddings=embeddings, data=list(map(lambda x: x[&#39;metadata&#39;], data)), split_text=False)
                self._vectorstore = FAISS.from_documents(docs, embedding=embeddings.embedding_model)
                self.info
                self._info[&#39;embeddings&#39;] = embeddings.name
                self.save()
        else:
            from langchain.docstore import InMemoryDocstore
            if ((self.name in list_vectordbs(self._vectordb_dir)) &amp; (self.vdb_dir is not None)):
                import shutil
                shutil.rmtree(self.vdb_dir)
            self._vectorstore = FAISS(embedding_function=embeddings.embedding_model, index=faiss.IndexFlatL2(embeddings.embedding_size),
                                          docstore=InMemoryDocstore({}), index_to_docstore_id={})
            self.save()
                
    def save(self) -&gt; None:
        &#34;&#34;&#34;Save the latest vector database.
        &#34;&#34;&#34;
        if self.vdb_dir is not None:
            from ..utils import save_json, current_time
            self._vectorstore.save_local(self.vdb_dir)
            self.info
            self._info[&#39;last_update&#39;] = current_time()
            save_json(self.info, os.path.join(self.vdb_dir, &#39;info.json&#39;))
            if self.save_raw:
                save_json(self.data, os.path.join(self.vdb_dir, &#39;data.json&#39;))
        
    @classmethod
    def from_exist(cls, name: str, embeddings: Type[BaseEmbeddingsToolkit], vectordb_dir: Optional[str] = None) -&gt; VectorDatabase:
        &#34;&#34;&#34;Initialise the vector database from existing files.

        Args:
            name (str): Name of the existing vector database.
            embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkit used in this vector database.
            vectordb_dir (Optional[str], optional): Parent directory of the vector database. If None is given, the default_vectordb_dir will be used. Defaults to None.

        Returns:
            VectorDatabase: The intialised vector database.
        &#34;&#34;&#34;
        if name not in list_vectordbs(vectordb_dir=vectordb_dir):
            raise FileNotFoundError(f&#39;Vector database &#34;{name}&#34; does not exist.&#39;)
        vdb = cls(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir)
        if vdb.info.get(&#39;embeddings&#39;, &#39;NOT_AVAIALBLE&#39;) != embeddings.name:
            if &#39;data.json&#39; not in os.listdir(vdb.vdb_dir):
                raise FileNotFoundError(f&#39;The vector database did not use the embeddings &#34;{embeddings.name}&#34; and no raw data was saved. Vector database cannot be loaded with this embeddings.&#39;)
            else:
                vdb._save_raw = True
                vdb._init_vectordb(embeddings=embeddings, from_exist=True)
        else:
            vdb._save_raw = &#39;data.json&#39; in os.listdir(vdb.vdb_dir)
            vdb._init_vectordb(embeddings=embeddings, from_exist=True)
        return vdb
    
    @classmethod
    def from_empty(cls, embeddings: Type[BaseEmbeddingsToolkit], name: Optional[str] = None, vectordb_dir: Optional[str] = None, save_raw: bool = False) -&gt; VectorDatabase:
        &#34;&#34;&#34;Initialise an empty vector database.

        Args:
            embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkits used in the vector database.
            name (Optional[str], optional): Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.
            vectordb_dir (Optional[str], optional): Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.
            save_raw (bool, optional): Whether to save raw text data and metadata as a separate json file. Defaults to False.

        Returns:
            VectorDatabase: The intialised vector database.
        &#34;&#34;&#34;
        vdb = cls(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir, save_raw=save_raw)
        vdb._init_vectordb(embeddings=embeddings, from_exist=False)
        return vdb
    
    @classmethod
    def from_data(cls, index: List[str], embeddings: Type[BaseEmbeddingsToolkit],
                  data: Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]] = dict(), text_splitter: Type[TextSplitter] = None, name: Optional[str] = None, 
                  vectordb_dir: Optional[str] = None, save_raw: bool = False, split_text: bool = True) -&gt; VectorDatabase:
        &#34;&#34;&#34;Initialise the vector database with list of texts.

        Args:
            index (List[str]): List of texts to initialise the database.
            embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkits used in the vector database.
            data (Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]], optional): Metadata for the list of texts. Defaults to dict().
            text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
            name (Optional[str], optional): Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.
            vectordb_dir (Optional[str], optional): Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.
            save_raw (bool, optional): Whether to save raw text data and metadata as a separate json file. Defaults to False.
            split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.

        Returns:
            VectorDatabase: The intialised vector database.
        &#34;&#34;&#34;
        vdb = cls.from_empty(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir, save_raw=save_raw)
        vdb.add_texts(texts=index, metadata=data, text_splitter=text_splitter, split_text=split_text)
        return vdb
    
    def add_texts(self, texts: List[str], metadata: Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]] = dict(), 
                  text_splitter: Optional[Type[TextSplitter]] = None, split_text: bool = True) -&gt; None:
        &#34;&#34;&#34;Adding texts to the vector database.

        Args:
            texts (List[str]): List of texts to add.
            metadata (Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]], optional): Metadata for the texts. Defaults to dict().
            text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
            split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.
        &#34;&#34;&#34;
        docs = texts_to_documents(texts=texts, embeddings=self.embeddings, text_splitter=text_splitter, data=metadata, split_text=split_text)
        self.vectorstore.add_documents(docs)
        self.save()

    def add_documents(self, docs: List[Document], text_splitter: Optional[Type[TextSplitter]] = None, split_text: bool = True) -&gt; None:
        &#34;&#34;&#34;Adding documents to the vector database.

        Args:
            docs (List[Document]): List of documents to add.
            text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
            split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.
        &#34;&#34;&#34;
        texts = list(map(lambda x: x.page_content, docs))
        metadata = list(map(lambda x: x.metadata, docs))
        self.add_texts(texts=texts, metadata=metadata, text_splitter=text_splitter, split_text=split_text)

    def _result_dict(self, index: str, score: float, metadata: Dict[str, Any]) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Helper method to construct search results into a dictionary.

        Args:
            index (str): Index as a text string.
            score (float): Relevance score.
            metadata (Dict[str, Any]): Metadata dictionary.

        Returns:
            Dict[str, Any]:Dictionary with all information of the search result.
        &#34;&#34;&#34;
        return dict(index=index, score=score, metadata=metadata)

    def _dictionary_filter(self, item: List[Union[str, Document]], **kwargs: Dict[str, Any]) -&gt; bool:
        &#34;&#34;&#34;Helper method for dictionary filtering.

        Args:
            item (List[Union[str, Document]]): Document item to check.

        Returns:
            bool: Return True if all metadata of the item satisfy the kwargs values.
        &#34;&#34;&#34;
        for k, v in kwargs.items():
            if item[1].metadata.get(k, None) != v:
                return False
        return True

    def search(self, query: str, top_k: int = 5, index_only: bool = True, **kwargs) -&gt; List[Union[str, Dict[str, Any]]]:
        &#34;&#34;&#34;Similarity search of text on the vector database. Pass keyword arguments as filters on metadata.

        Args:
            query (str): Text search string query.
            top_k (int, optional): Maximum number of results to return. Defaults to 5.
            index_only (bool, optional): If set as True, only the index string will be returned. Otherwise, metadata and scores will be returned as well. Defaults to True.

        Returns:
            List[Union[str, Dict[str, Any]]]: List of search results.
        &#34;&#34;&#34;
        results = self.vectorstore.similarity_search_with_relevance_scores(query=query, k=top_k, fetch_k=max(top_k*2, 20), filter=kwargs)

        if index_only:
            results = list(map(lambda x: x[0].page_content, results))
        else:
            index = list(map(lambda x: x[0].page_content, results))
            metadata = list(map(lambda x: x[0].metadata, results))
            scores = list(map(lambda x: x[1], results))
            results = list(zip(index, scores, metadata))
            results = list(map(lambda x: self._result_dict(x[0], x[1], x[2]), results))
        return results
    
    def search_by_metadata(self, **kwargs: Dict[str, Any]) -&gt; Dict[str, Document]:
        &#34;&#34;&#34;Exact match search on metadata. Filters should be provided as key value pair arguments.

        Returns:
            Dict[str, Document]: Dictionary of saerch results, with docstore ids as the keys.
        &#34;&#34;&#34;
        results = dict(filter(lambda x: self._dictionary_filter(x, **kwargs), self.vectorstore.docstore._dict.items()))
        return results

    def delete_by_metadata(self, **kwargs: Dict[str, Any]) -&gt; None:
        &#34;&#34;&#34;Remove records base on the given key value pairs criteria.

        Raises:
            ValueError: If not key value pairs given, this error will be raised. To clear the whole vector database, please use the &#34;clear()&#34; method.
        &#34;&#34;&#34;
        if len(kwargs) == 0:
            raise ValueError(f&#39;Keyword arguments must be provided to remove data from the vector database.&#39;)
        ids = list(self.search_by_metadata(**kwargs).keys())
        self.vectorstore.delete(ids)
        self.save()

    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="llmflex.Data.vector_database.default_vectordb_dir"><code class="name flex">
<span>def <span class="ident">default_vectordb_dir</span></span>(<span>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Default home directory of vector databases.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Default home directory of vector databases.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def default_vectordb_dir() -&gt; str:
    &#34;&#34;&#34;Default home directory of vector databases.

    Returns:
        str: Default home directory of vector databases.
    &#34;&#34;&#34;
    from ..utils import get_config
    home = os.path.join(get_config()[&#39;package_home&#39;], &#39;vector_databases&#39;)
    if not os.path.exists(home):
        os.makedirs(home)
    return home</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.list_vectordbs"><code class="name flex">
<span>def <span class="ident">list_vectordbs</span></span>(<span>vectordb_dir: Optional[str] = None) ‑> List[str]</span>
</code></dt>
<dd>
<div class="desc"><p>List all the vector databases in the given directory.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>vectordb_dir</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Directory where the vector databases live. If None is given, the default_vectordb_dir will be used. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[str]</code></dt>
<dd>List all the vector databases in the given directory.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def list_vectordbs(vectordb_dir: Optional[str] = None) -&gt; List[str]:
    &#34;&#34;&#34;List all the vector databases in the given directory.

    Args:
        vectordb_dir (Optional[str], optional): Directory where the vector databases live. If None is given, the default_vectordb_dir will be used. Defaults to None.

    Returns:
        List[str]: List all the vector databases in the given directory.
    &#34;&#34;&#34;
    vectordb_dir = vectordb_dir if ((isinstance(vectordb_dir, str)) &amp; (os.path.exists(vectordb_dir))) else default_vectordb_dir()
    dbs = list(filter(lambda x: os.path.isdir(os.path.join(vectordb_dir, x)), os.listdir(vectordb_dir)))
    dbs = list(filter(lambda x: os.path.exists(os.path.join(vectordb_dir, x, &#39;info.json&#39;)), dbs))
    return dbs</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.name_checker"><code class="name flex">
<span>def <span class="ident">name_checker</span></span>(<span>name: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Raise error if the given string has space, newline characters, or tab characters.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>String to check.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Return the given text if it passes all the checkes.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def name_checker(name: str) -&gt; str:
    &#34;&#34;&#34;Raise error if the given string has space, newline characters, or tab characters.

    Args:
        name (str): String to check.

    Returns:
        str: Return the given text if it passes all the checkes.
    &#34;&#34;&#34;
    if &#39; &#39; in name:
        raise ValueError(f&#39;Spaces cannot be in the name&#39;)
    if &#39;\n&#39; in name:
        raise ValueError(f&#39;Newline characters cannot be in the name.&#39;)
    if &#39;\r&#39; in name:
        raise ValueError(f&#39;Newline characters cannot be in the name.&#39;)
    if &#39;\t&#39; in name:
        raise ValueError(f&#39;Tab characters cannot be in the name.&#39;)
    return name</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.texts_to_documents"><code class="name flex">
<span>def <span class="ident">texts_to_documents</span></span>(<span>texts: List[str], embeddings: Optional[Type[BaseEmbeddingsToolkit]] = None, text_splitter: Optional[Type[TextSplitter]] = None, data: Optional[Union[pd.DataFrame, List[Dict[str, Any]], Dict[str, Any]]] = None, split_text: bool = True) ‑> List[langchain_core.documents.base.Document]</span>
</code></dt>
<dd>
<div class="desc"><p>Create splitted documents from the list of text strings.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>List of strings to split into documents.</dd>
<dt><strong><code>embeddings</code></strong> :&ensp;<code>Optional[Type[BaseEmbeddingsToolkit]]</code>, optional</dt>
<dd>Embedding toolkit used to split the documents. Defaults to None</dd>
<dt><strong><code>text_splitter</code></strong> :&ensp;<code>Optional[Type[TextSplitter]]</code>, optional</dt>
<dd>Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.</dd>
<dt><strong><code>data</code></strong> :&ensp;<code>Optional[Union[pd.DataFrame, List[Dict[str, Any]], Dict[str, Any]]]</code>, optional</dt>
<dd>Metadata for each text strings. Defaults to None.</dd>
<dt><strong><code>split_text</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to split text if the given text is too long. Defaults to True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Document]</code></dt>
<dd>List of splitted documents.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def texts_to_documents(texts: List[str], 
        embeddings: Optional[Type[BaseEmbeddingsToolkit]] = None,
        text_splitter: Optional[Type[TextSplitter]] = None,
        data: Optional[Union[pd.DataFrame, List[Dict[str, Any]], Dict[str, Any]]] = None,
        split_text: bool = True) -&gt; List[Document]:
    &#34;&#34;&#34;Create splitted documents from the list of text strings.

    Args:
        texts (List[str]): List of strings to split into documents.
        embeddings (Optional[Type[BaseEmbeddingsToolkit]], optional): Embedding toolkit used to split the documents. Defaults to None
        text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
        data (Optional[Union[pd.DataFrame, List[Dict[str, Any]], Dict[str, Any]]], optional): Metadata for each text strings. Defaults to None.
        split_text (bool, optional): Whether to split text if the given text is too long. Defaults to True.

    Returns:
        List[Document]: List of splitted documents.
    &#34;&#34;&#34;
    if type(data) == pd.DataFrame:
        data = data.to_dict(&#39;records&#39;)
    elif type(data) == dict:
        data = [data] * len(texts)
    elif data is None:
        data = [dict()] * len(texts)
    
    docs = list(map(lambda x: Document(page_content=x[0], metadata=x[1]), list(zip(texts, data))))
    if split_text:
        if text_splitter is not None:
            docs = text_splitter.split_documents(docs)
        elif embeddings is not None:
            docs = embeddings.text_splitter.split_documents(docs)
        else:
            raise RuntimeError(&#39;Either embeddings or text_splitter has to be provided if split_text=True.&#39;)
    return docs</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="llmflex.Data.vector_database.VectorDatabase"><code class="flex name class">
<span>class <span class="ident">VectorDatabase</span></span>
<span>(</span><span>embeddings: Type[BaseEmbeddingsToolkit], vectordb_dir: Optional[str] = None, name: Optional[str] = None, save_raw: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Vector database class, suitable for storing text data as embeddings for similarity searches and other classes that requires numerical respresentations of texts.</p>
<p>Initialising basic information of the vector database.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>embeddings</code></strong> :&ensp;<code>Type[BaseEmbeddingsToolkit]</code></dt>
<dd>Embeddings toolkits used in the vector database.</dd>
<dt><strong><code>vectordb_dir</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.</dd>
<dt><strong><code>save_raw</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to save raw text data and metadata as a separate json file. Defaults to False.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VectorDatabase:
    &#34;&#34;&#34;Vector database class, suitable for storing text data as embeddings for similarity searches and other classes that requires numerical respresentations of texts.
    &#34;&#34;&#34;

    def __init__(self, embeddings: Type[BaseEmbeddingsToolkit], 
                 vectordb_dir: Optional[str] = None, name: Optional[str] = None,
                 save_raw: bool = False) -&gt; None:
        &#34;&#34;&#34;Initialising basic information of the vector database.

        Args:
            embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkits used in the vector database.
            vectordb_dir (Optional[str], optional): Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.
            name (Optional[str], optional): Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.
            save_raw (bool, optional): Whether to save raw text data and metadata as a separate json file. Defaults to False.
        &#34;&#34;&#34;
        self._name = &#39;_InMemoryVectorDB_&#39; if name is None else name_checker(name)
        self._embeddings = embeddings
        self._vectordb_dir = default_vectordb_dir() if vectordb_dir is None else os.path.abspath(vectordb_dir)
        self._save_raw = save_raw

    @property
    def name(self) -&gt; str:
        &#34;&#34;&#34;Name of the vector database.

        Returns:
            str: Name of the vector database.
        &#34;&#34;&#34;
        return self._name
    
    @property
    def embeddings(self) -&gt; Type[BaseEmbeddingsToolkit]:
        &#34;&#34;&#34;Embeddings toolkit used in the vector database.

        Returns:
            Type[BaseEmbeddingsToolkit]: Embeddings toolkit used in the vector database.
        &#34;&#34;&#34;
        return self._embeddings
    
    @property
    def vdb_dir(self) -&gt; Union[str, None]:
        &#34;&#34;&#34;Directory of the vector database if it is not in-memory only.

        Returns:
            Union[str, None]: Directory of the vector database if it is not in-memory only.
        &#34;&#34;&#34;
        if self.name != &#39;_InMemoryVectorDB_&#39;:
            vdb_dir = os.path.join(self._vectordb_dir, self.name)
            os.makedirs(vdb_dir, exist_ok=True)
            return vdb_dir
        else:
            return None

    @property
    def save_raw(self) -&gt; bool:
        &#34;&#34;&#34;Whether to save the raw data as json or not.

        Returns:
            bool: Whether to save the raw data as json or not.
        &#34;&#34;&#34;
        return self._save_raw
    
    @property
    def info(self) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Information of the vector database.

        Returns:
            Dict[str, Any]: Information of the vector database.
        &#34;&#34;&#34;
        if hasattr(self, &#39;_info&#39;):
            return self._info
        elif ((self.vdb_dir is not None) &amp; (&#39;info.json&#39; in os.listdir(self.vdb_dir))):
            from ..utils import read_json
            self._info = read_json(os.path.join(self.vdb_dir, &#39;info.json&#39;))
            return self._info
        else:
            from ..utils import save_json, current_time
            self._info = dict(embeddings=self.embeddings.name, last_update=current_time())
            if self.save_raw:
                save_json(self._info, os.path.join(self.vdb_dir, &#39;info.json&#39;))
            return self._info
        
    @property
    def vectorstore(self) -&gt; &#34;FAISS&#34;:
        &#34;&#34;&#34;Return the faiss vectorstore

        Returns:
            FAISS: The vector store.
        &#34;&#34;&#34;
        return self._vectorstore
    
    @property
    def data(self) -&gt; List[Dict[str, Any]]:
        &#34;&#34;&#34;Raw data of the vector database.

        Returns:
            List[Dict[str, Any]]: Raw data of the vector database.
        &#34;&#34;&#34;
        data = list(self._vectorstore.docstore._dict.values())
        data = list(map(lambda x: dict(index=x.page_content, metadata=x.metadata), data))
        return data
    
    @property
    def size(self) -&gt; int:
        &#34;&#34;&#34;Number of embeddings in the vector database. May be more than the number of texts you have added into the database due to text splitting for longer texts.

        Returns:
            int: Number of embeddings.
        &#34;&#34;&#34;
        return len(self.data)
        
    def _init_vectordb(self, embeddings: Type[BaseEmbeddingsToolkit], from_exist: bool = True) -&gt; None:
        &#34;&#34;&#34;Initialise the langchain vectorstore

        Args:
            from_exist (bool, optional): Whether to initialise from an existing vectorstore. Defaults to True.
        &#34;&#34;&#34;
        from langchain.vectorstores.faiss import FAISS
        import faiss
        import warnings
        warnings.filterwarnings(&#39;ignore&#39;)
        if ((from_exist) &amp; (self.name in list_vectordbs(self._vectordb_dir))):
            if (self.info.get(&#39;embeddings&#39;, &#39;NOT_AVAIALBLE&#39;) == embeddings.name):
                self._vectorstore = FAISS.load_local(folder_path=self.vdb_dir, embeddings=embeddings.embedding_model)
            elif &#39;data.json&#39; in os.listdir(self.vdb_dir):
                from ..utils import read_json
                data = read_json(os.path.join(self.vdb_dir, &#39;data.json&#39;))
                docs = texts_to_documents(texts=list(map(lambda x: x[&#39;index&#39;], data)), 
                                          embeddings=embeddings, data=list(map(lambda x: x[&#39;metadata&#39;], data)), split_text=False)
                self._vectorstore = FAISS.from_documents(docs, embedding=embeddings.embedding_model)
                self.info
                self._info[&#39;embeddings&#39;] = embeddings.name
                self.save()
        else:
            from langchain.docstore import InMemoryDocstore
            if ((self.name in list_vectordbs(self._vectordb_dir)) &amp; (self.vdb_dir is not None)):
                import shutil
                shutil.rmtree(self.vdb_dir)
            self._vectorstore = FAISS(embedding_function=embeddings.embedding_model, index=faiss.IndexFlatL2(embeddings.embedding_size),
                                          docstore=InMemoryDocstore({}), index_to_docstore_id={})
            self.save()
                
    def save(self) -&gt; None:
        &#34;&#34;&#34;Save the latest vector database.
        &#34;&#34;&#34;
        if self.vdb_dir is not None:
            from ..utils import save_json, current_time
            self._vectorstore.save_local(self.vdb_dir)
            self.info
            self._info[&#39;last_update&#39;] = current_time()
            save_json(self.info, os.path.join(self.vdb_dir, &#39;info.json&#39;))
            if self.save_raw:
                save_json(self.data, os.path.join(self.vdb_dir, &#39;data.json&#39;))
        
    @classmethod
    def from_exist(cls, name: str, embeddings: Type[BaseEmbeddingsToolkit], vectordb_dir: Optional[str] = None) -&gt; VectorDatabase:
        &#34;&#34;&#34;Initialise the vector database from existing files.

        Args:
            name (str): Name of the existing vector database.
            embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkit used in this vector database.
            vectordb_dir (Optional[str], optional): Parent directory of the vector database. If None is given, the default_vectordb_dir will be used. Defaults to None.

        Returns:
            VectorDatabase: The intialised vector database.
        &#34;&#34;&#34;
        if name not in list_vectordbs(vectordb_dir=vectordb_dir):
            raise FileNotFoundError(f&#39;Vector database &#34;{name}&#34; does not exist.&#39;)
        vdb = cls(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir)
        if vdb.info.get(&#39;embeddings&#39;, &#39;NOT_AVAIALBLE&#39;) != embeddings.name:
            if &#39;data.json&#39; not in os.listdir(vdb.vdb_dir):
                raise FileNotFoundError(f&#39;The vector database did not use the embeddings &#34;{embeddings.name}&#34; and no raw data was saved. Vector database cannot be loaded with this embeddings.&#39;)
            else:
                vdb._save_raw = True
                vdb._init_vectordb(embeddings=embeddings, from_exist=True)
        else:
            vdb._save_raw = &#39;data.json&#39; in os.listdir(vdb.vdb_dir)
            vdb._init_vectordb(embeddings=embeddings, from_exist=True)
        return vdb
    
    @classmethod
    def from_empty(cls, embeddings: Type[BaseEmbeddingsToolkit], name: Optional[str] = None, vectordb_dir: Optional[str] = None, save_raw: bool = False) -&gt; VectorDatabase:
        &#34;&#34;&#34;Initialise an empty vector database.

        Args:
            embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkits used in the vector database.
            name (Optional[str], optional): Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.
            vectordb_dir (Optional[str], optional): Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.
            save_raw (bool, optional): Whether to save raw text data and metadata as a separate json file. Defaults to False.

        Returns:
            VectorDatabase: The intialised vector database.
        &#34;&#34;&#34;
        vdb = cls(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir, save_raw=save_raw)
        vdb._init_vectordb(embeddings=embeddings, from_exist=False)
        return vdb
    
    @classmethod
    def from_data(cls, index: List[str], embeddings: Type[BaseEmbeddingsToolkit],
                  data: Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]] = dict(), text_splitter: Type[TextSplitter] = None, name: Optional[str] = None, 
                  vectordb_dir: Optional[str] = None, save_raw: bool = False, split_text: bool = True) -&gt; VectorDatabase:
        &#34;&#34;&#34;Initialise the vector database with list of texts.

        Args:
            index (List[str]): List of texts to initialise the database.
            embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkits used in the vector database.
            data (Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]], optional): Metadata for the list of texts. Defaults to dict().
            text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
            name (Optional[str], optional): Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.
            vectordb_dir (Optional[str], optional): Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.
            save_raw (bool, optional): Whether to save raw text data and metadata as a separate json file. Defaults to False.
            split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.

        Returns:
            VectorDatabase: The intialised vector database.
        &#34;&#34;&#34;
        vdb = cls.from_empty(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir, save_raw=save_raw)
        vdb.add_texts(texts=index, metadata=data, text_splitter=text_splitter, split_text=split_text)
        return vdb
    
    def add_texts(self, texts: List[str], metadata: Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]] = dict(), 
                  text_splitter: Optional[Type[TextSplitter]] = None, split_text: bool = True) -&gt; None:
        &#34;&#34;&#34;Adding texts to the vector database.

        Args:
            texts (List[str]): List of texts to add.
            metadata (Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]], optional): Metadata for the texts. Defaults to dict().
            text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
            split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.
        &#34;&#34;&#34;
        docs = texts_to_documents(texts=texts, embeddings=self.embeddings, text_splitter=text_splitter, data=metadata, split_text=split_text)
        self.vectorstore.add_documents(docs)
        self.save()

    def add_documents(self, docs: List[Document], text_splitter: Optional[Type[TextSplitter]] = None, split_text: bool = True) -&gt; None:
        &#34;&#34;&#34;Adding documents to the vector database.

        Args:
            docs (List[Document]): List of documents to add.
            text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
            split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.
        &#34;&#34;&#34;
        texts = list(map(lambda x: x.page_content, docs))
        metadata = list(map(lambda x: x.metadata, docs))
        self.add_texts(texts=texts, metadata=metadata, text_splitter=text_splitter, split_text=split_text)

    def _result_dict(self, index: str, score: float, metadata: Dict[str, Any]) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Helper method to construct search results into a dictionary.

        Args:
            index (str): Index as a text string.
            score (float): Relevance score.
            metadata (Dict[str, Any]): Metadata dictionary.

        Returns:
            Dict[str, Any]:Dictionary with all information of the search result.
        &#34;&#34;&#34;
        return dict(index=index, score=score, metadata=metadata)

    def _dictionary_filter(self, item: List[Union[str, Document]], **kwargs: Dict[str, Any]) -&gt; bool:
        &#34;&#34;&#34;Helper method for dictionary filtering.

        Args:
            item (List[Union[str, Document]]): Document item to check.

        Returns:
            bool: Return True if all metadata of the item satisfy the kwargs values.
        &#34;&#34;&#34;
        for k, v in kwargs.items():
            if item[1].metadata.get(k, None) != v:
                return False
        return True

    def search(self, query: str, top_k: int = 5, index_only: bool = True, **kwargs) -&gt; List[Union[str, Dict[str, Any]]]:
        &#34;&#34;&#34;Similarity search of text on the vector database. Pass keyword arguments as filters on metadata.

        Args:
            query (str): Text search string query.
            top_k (int, optional): Maximum number of results to return. Defaults to 5.
            index_only (bool, optional): If set as True, only the index string will be returned. Otherwise, metadata and scores will be returned as well. Defaults to True.

        Returns:
            List[Union[str, Dict[str, Any]]]: List of search results.
        &#34;&#34;&#34;
        results = self.vectorstore.similarity_search_with_relevance_scores(query=query, k=top_k, fetch_k=max(top_k*2, 20), filter=kwargs)

        if index_only:
            results = list(map(lambda x: x[0].page_content, results))
        else:
            index = list(map(lambda x: x[0].page_content, results))
            metadata = list(map(lambda x: x[0].metadata, results))
            scores = list(map(lambda x: x[1], results))
            results = list(zip(index, scores, metadata))
            results = list(map(lambda x: self._result_dict(x[0], x[1], x[2]), results))
        return results
    
    def search_by_metadata(self, **kwargs: Dict[str, Any]) -&gt; Dict[str, Document]:
        &#34;&#34;&#34;Exact match search on metadata. Filters should be provided as key value pair arguments.

        Returns:
            Dict[str, Document]: Dictionary of saerch results, with docstore ids as the keys.
        &#34;&#34;&#34;
        results = dict(filter(lambda x: self._dictionary_filter(x, **kwargs), self.vectorstore.docstore._dict.items()))
        return results

    def delete_by_metadata(self, **kwargs: Dict[str, Any]) -&gt; None:
        &#34;&#34;&#34;Remove records base on the given key value pairs criteria.

        Raises:
            ValueError: If not key value pairs given, this error will be raised. To clear the whole vector database, please use the &#34;clear()&#34; method.
        &#34;&#34;&#34;
        if len(kwargs) == 0:
            raise ValueError(f&#39;Keyword arguments must be provided to remove data from the vector database.&#39;)
        ids = list(self.search_by_metadata(**kwargs).keys())
        self.vectorstore.delete(ids)
        self.save()</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="llmflex.Data.vector_database.VectorDatabase.from_data"><code class="name flex">
<span>def <span class="ident">from_data</span></span>(<span>index: List[str], embeddings: Type[BaseEmbeddingsToolkit], data: Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]] = {}, text_splitter: Type[TextSplitter] = None, name: Optional[str] = None, vectordb_dir: Optional[str] = None, save_raw: bool = False, split_text: bool = True) ‑> <a title="llmflex.Data.vector_database.VectorDatabase" href="#llmflex.Data.vector_database.VectorDatabase">VectorDatabase</a></span>
</code></dt>
<dd>
<div class="desc"><p>Initialise the vector database with list of texts.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>List of texts to initialise the database.</dd>
<dt><strong><code>embeddings</code></strong> :&ensp;<code>Type[BaseEmbeddingsToolkit]</code></dt>
<dd>Embeddings toolkits used in the vector database.</dd>
<dt><strong><code>data</code></strong> :&ensp;<code>Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]]</code>, optional</dt>
<dd>Metadata for the list of texts. Defaults to dict().</dd>
<dt><strong><code>text_splitter</code></strong> :&ensp;<code>Optional[Type[TextSplitter]]</code>, optional</dt>
<dd>Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.</dd>
<dt><strong><code>vectordb_dir</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.</dd>
<dt><strong><code>save_raw</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to save raw text data and metadata as a separate json file. Defaults to False.</dd>
<dt><strong><code>split_text</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to split the texts if they are too long. Defaults to True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="llmflex.Data.vector_database.VectorDatabase" href="#llmflex.Data.vector_database.VectorDatabase">VectorDatabase</a></code></dt>
<dd>The intialised vector database.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_data(cls, index: List[str], embeddings: Type[BaseEmbeddingsToolkit],
              data: Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]] = dict(), text_splitter: Type[TextSplitter] = None, name: Optional[str] = None, 
              vectordb_dir: Optional[str] = None, save_raw: bool = False, split_text: bool = True) -&gt; VectorDatabase:
    &#34;&#34;&#34;Initialise the vector database with list of texts.

    Args:
        index (List[str]): List of texts to initialise the database.
        embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkits used in the vector database.
        data (Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]], optional): Metadata for the list of texts. Defaults to dict().
        text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
        name (Optional[str], optional): Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.
        vectordb_dir (Optional[str], optional): Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.
        save_raw (bool, optional): Whether to save raw text data and metadata as a separate json file. Defaults to False.
        split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.

    Returns:
        VectorDatabase: The intialised vector database.
    &#34;&#34;&#34;
    vdb = cls.from_empty(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir, save_raw=save_raw)
    vdb.add_texts(texts=index, metadata=data, text_splitter=text_splitter, split_text=split_text)
    return vdb</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.from_empty"><code class="name flex">
<span>def <span class="ident">from_empty</span></span>(<span>embeddings: Type[BaseEmbeddingsToolkit], name: Optional[str] = None, vectordb_dir: Optional[str] = None, save_raw: bool = False) ‑> <a title="llmflex.Data.vector_database.VectorDatabase" href="#llmflex.Data.vector_database.VectorDatabase">VectorDatabase</a></span>
</code></dt>
<dd>
<div class="desc"><p>Initialise an empty vector database.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>embeddings</code></strong> :&ensp;<code>Type[BaseEmbeddingsToolkit]</code></dt>
<dd>Embeddings toolkits used in the vector database.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.</dd>
<dt><strong><code>vectordb_dir</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.</dd>
<dt><strong><code>save_raw</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to save raw text data and metadata as a separate json file. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="llmflex.Data.vector_database.VectorDatabase" href="#llmflex.Data.vector_database.VectorDatabase">VectorDatabase</a></code></dt>
<dd>The intialised vector database.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_empty(cls, embeddings: Type[BaseEmbeddingsToolkit], name: Optional[str] = None, vectordb_dir: Optional[str] = None, save_raw: bool = False) -&gt; VectorDatabase:
    &#34;&#34;&#34;Initialise an empty vector database.

    Args:
        embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkits used in the vector database.
        name (Optional[str], optional): Name of the vector database. If given, the vector database will be stored in storage. Defaults to None.
        vectordb_dir (Optional[str], optional): Parent directory of the vector database if it is not In-memory only. If None is given, the default_vectordb_dir will be used. Defaults to None.
        save_raw (bool, optional): Whether to save raw text data and metadata as a separate json file. Defaults to False.

    Returns:
        VectorDatabase: The intialised vector database.
    &#34;&#34;&#34;
    vdb = cls(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir, save_raw=save_raw)
    vdb._init_vectordb(embeddings=embeddings, from_exist=False)
    return vdb</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.from_exist"><code class="name flex">
<span>def <span class="ident">from_exist</span></span>(<span>name: str, embeddings: Type[BaseEmbeddingsToolkit], vectordb_dir: Optional[str] = None) ‑> <a title="llmflex.Data.vector_database.VectorDatabase" href="#llmflex.Data.vector_database.VectorDatabase">VectorDatabase</a></span>
</code></dt>
<dd>
<div class="desc"><p>Initialise the vector database from existing files.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the existing vector database.</dd>
<dt><strong><code>embeddings</code></strong> :&ensp;<code>Type[BaseEmbeddingsToolkit]</code></dt>
<dd>Embeddings toolkit used in this vector database.</dd>
<dt><strong><code>vectordb_dir</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>Parent directory of the vector database. If None is given, the default_vectordb_dir will be used. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="llmflex.Data.vector_database.VectorDatabase" href="#llmflex.Data.vector_database.VectorDatabase">VectorDatabase</a></code></dt>
<dd>The intialised vector database.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_exist(cls, name: str, embeddings: Type[BaseEmbeddingsToolkit], vectordb_dir: Optional[str] = None) -&gt; VectorDatabase:
    &#34;&#34;&#34;Initialise the vector database from existing files.

    Args:
        name (str): Name of the existing vector database.
        embeddings (Type[BaseEmbeddingsToolkit]): Embeddings toolkit used in this vector database.
        vectordb_dir (Optional[str], optional): Parent directory of the vector database. If None is given, the default_vectordb_dir will be used. Defaults to None.

    Returns:
        VectorDatabase: The intialised vector database.
    &#34;&#34;&#34;
    if name not in list_vectordbs(vectordb_dir=vectordb_dir):
        raise FileNotFoundError(f&#39;Vector database &#34;{name}&#34; does not exist.&#39;)
    vdb = cls(embeddings=embeddings, name=name, vectordb_dir=vectordb_dir)
    if vdb.info.get(&#39;embeddings&#39;, &#39;NOT_AVAIALBLE&#39;) != embeddings.name:
        if &#39;data.json&#39; not in os.listdir(vdb.vdb_dir):
            raise FileNotFoundError(f&#39;The vector database did not use the embeddings &#34;{embeddings.name}&#34; and no raw data was saved. Vector database cannot be loaded with this embeddings.&#39;)
        else:
            vdb._save_raw = True
            vdb._init_vectordb(embeddings=embeddings, from_exist=True)
    else:
        vdb._save_raw = &#39;data.json&#39; in os.listdir(vdb.vdb_dir)
        vdb._init_vectordb(embeddings=embeddings, from_exist=True)
    return vdb</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="llmflex.Data.vector_database.VectorDatabase.data"><code class="name">var <span class="ident">data</span> : List[Dict[str, Any]]</code></dt>
<dd>
<div class="desc"><p>Raw data of the vector database.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Dict[str, Any]]</code></dt>
<dd>Raw data of the vector database.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def data(self) -&gt; List[Dict[str, Any]]:
    &#34;&#34;&#34;Raw data of the vector database.

    Returns:
        List[Dict[str, Any]]: Raw data of the vector database.
    &#34;&#34;&#34;
    data = list(self._vectorstore.docstore._dict.values())
    data = list(map(lambda x: dict(index=x.page_content, metadata=x.metadata), data))
    return data</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.embeddings"><code class="name">var <span class="ident">embeddings</span> : Type[<a title="llmflex.Embeddings.base_embeddings.BaseEmbeddingsToolkit" href="../Embeddings/base_embeddings.html#llmflex.Embeddings.base_embeddings.BaseEmbeddingsToolkit">BaseEmbeddingsToolkit</a>]</code></dt>
<dd>
<div class="desc"><p>Embeddings toolkit used in the vector database.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Type[BaseEmbeddingsToolkit]</code></dt>
<dd>Embeddings toolkit used in the vector database.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def embeddings(self) -&gt; Type[BaseEmbeddingsToolkit]:
    &#34;&#34;&#34;Embeddings toolkit used in the vector database.

    Returns:
        Type[BaseEmbeddingsToolkit]: Embeddings toolkit used in the vector database.
    &#34;&#34;&#34;
    return self._embeddings</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.info"><code class="name">var <span class="ident">info</span> : Dict[str, Any]</code></dt>
<dd>
<div class="desc"><p>Information of the vector database.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Any]</code></dt>
<dd>Information of the vector database.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def info(self) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Information of the vector database.

    Returns:
        Dict[str, Any]: Information of the vector database.
    &#34;&#34;&#34;
    if hasattr(self, &#39;_info&#39;):
        return self._info
    elif ((self.vdb_dir is not None) &amp; (&#39;info.json&#39; in os.listdir(self.vdb_dir))):
        from ..utils import read_json
        self._info = read_json(os.path.join(self.vdb_dir, &#39;info.json&#39;))
        return self._info
    else:
        from ..utils import save_json, current_time
        self._info = dict(embeddings=self.embeddings.name, last_update=current_time())
        if self.save_raw:
            save_json(self._info, os.path.join(self.vdb_dir, &#39;info.json&#39;))
        return self._info</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.name"><code class="name">var <span class="ident">name</span> : str</code></dt>
<dd>
<div class="desc"><p>Name of the vector database.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Name of the vector database.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def name(self) -&gt; str:
    &#34;&#34;&#34;Name of the vector database.

    Returns:
        str: Name of the vector database.
    &#34;&#34;&#34;
    return self._name</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.save_raw"><code class="name">var <span class="ident">save_raw</span> : bool</code></dt>
<dd>
<div class="desc"><p>Whether to save the raw data as json or not.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether to save the raw data as json or not.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def save_raw(self) -&gt; bool:
    &#34;&#34;&#34;Whether to save the raw data as json or not.

    Returns:
        bool: Whether to save the raw data as json or not.
    &#34;&#34;&#34;
    return self._save_raw</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.size"><code class="name">var <span class="ident">size</span> : int</code></dt>
<dd>
<div class="desc"><p>Number of embeddings in the vector database. May be more than the number of texts you have added into the database due to text splitting for longer texts.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Number of embeddings.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def size(self) -&gt; int:
    &#34;&#34;&#34;Number of embeddings in the vector database. May be more than the number of texts you have added into the database due to text splitting for longer texts.

    Returns:
        int: Number of embeddings.
    &#34;&#34;&#34;
    return len(self.data)</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.vdb_dir"><code class="name">var <span class="ident">vdb_dir</span> : Optional[str]</code></dt>
<dd>
<div class="desc"><p>Directory of the vector database if it is not in-memory only.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[str, None]</code></dt>
<dd>Directory of the vector database if it is not in-memory only.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def vdb_dir(self) -&gt; Union[str, None]:
    &#34;&#34;&#34;Directory of the vector database if it is not in-memory only.

    Returns:
        Union[str, None]: Directory of the vector database if it is not in-memory only.
    &#34;&#34;&#34;
    if self.name != &#39;_InMemoryVectorDB_&#39;:
        vdb_dir = os.path.join(self._vectordb_dir, self.name)
        os.makedirs(vdb_dir, exist_ok=True)
        return vdb_dir
    else:
        return None</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.vectorstore"><code class="name">var <span class="ident">vectorstore</span> : 'FAISS'</code></dt>
<dd>
<div class="desc"><p>Return the faiss vectorstore</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>FAISS</code></dt>
<dd>The vector store.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def vectorstore(self) -&gt; &#34;FAISS&#34;:
    &#34;&#34;&#34;Return the faiss vectorstore

    Returns:
        FAISS: The vector store.
    &#34;&#34;&#34;
    return self._vectorstore</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="llmflex.Data.vector_database.VectorDatabase.add_documents"><code class="name flex">
<span>def <span class="ident">add_documents</span></span>(<span>self, docs: List[Document], text_splitter: Optional[Type[TextSplitter]] = None, split_text: bool = True) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Adding documents to the vector database.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>docs</code></strong> :&ensp;<code>List[Document]</code></dt>
<dd>List of documents to add.</dd>
<dt><strong><code>text_splitter</code></strong> :&ensp;<code>Optional[Type[TextSplitter]]</code>, optional</dt>
<dd>Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.</dd>
<dt><strong><code>split_text</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to split the texts if they are too long. Defaults to True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_documents(self, docs: List[Document], text_splitter: Optional[Type[TextSplitter]] = None, split_text: bool = True) -&gt; None:
    &#34;&#34;&#34;Adding documents to the vector database.

    Args:
        docs (List[Document]): List of documents to add.
        text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
        split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.
    &#34;&#34;&#34;
    texts = list(map(lambda x: x.page_content, docs))
    metadata = list(map(lambda x: x.metadata, docs))
    self.add_texts(texts=texts, metadata=metadata, text_splitter=text_splitter, split_text=split_text)</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.add_texts"><code class="name flex">
<span>def <span class="ident">add_texts</span></span>(<span>self, texts: List[str], metadata: Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]] = {}, text_splitter: Optional[Type[TextSplitter]] = None, split_text: bool = True) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Adding texts to the vector database.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>List of texts to add.</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]]</code>, optional</dt>
<dd>Metadata for the texts. Defaults to dict().</dd>
<dt><strong><code>text_splitter</code></strong> :&ensp;<code>Optional[Type[TextSplitter]]</code>, optional</dt>
<dd>Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.</dd>
<dt><strong><code>split_text</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to split the texts if they are too long. Defaults to True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_texts(self, texts: List[str], metadata: Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]] = dict(), 
              text_splitter: Optional[Type[TextSplitter]] = None, split_text: bool = True) -&gt; None:
    &#34;&#34;&#34;Adding texts to the vector database.

    Args:
        texts (List[str]): List of texts to add.
        metadata (Union[pd.DataFrame, Dict[str, Any], List[Dict[str, Any]]], optional): Metadata for the texts. Defaults to dict().
        text_splitter (Optional[Type[TextSplitter]], optional): Text splitter used to split the documents. If provided, it will be used instead of the embedding toolkit. Defaults to None.
        split_text (bool, optional): Whether to split the texts if they are too long. Defaults to True.
    &#34;&#34;&#34;
    docs = texts_to_documents(texts=texts, embeddings=self.embeddings, text_splitter=text_splitter, data=metadata, split_text=split_text)
    self.vectorstore.add_documents(docs)
    self.save()</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.delete_by_metadata"><code class="name flex">
<span>def <span class="ident">delete_by_metadata</span></span>(<span>self, **kwargs: Dict[str, Any]) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Remove records base on the given key value pairs criteria.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If not key value pairs given, this error will be raised. To clear the whole vector database, please use the "clear()" method.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_by_metadata(self, **kwargs: Dict[str, Any]) -&gt; None:
    &#34;&#34;&#34;Remove records base on the given key value pairs criteria.

    Raises:
        ValueError: If not key value pairs given, this error will be raised. To clear the whole vector database, please use the &#34;clear()&#34; method.
    &#34;&#34;&#34;
    if len(kwargs) == 0:
        raise ValueError(f&#39;Keyword arguments must be provided to remove data from the vector database.&#39;)
    ids = list(self.search_by_metadata(**kwargs).keys())
    self.vectorstore.delete(ids)
    self.save()</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Save the latest vector database.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self) -&gt; None:
    &#34;&#34;&#34;Save the latest vector database.
    &#34;&#34;&#34;
    if self.vdb_dir is not None:
        from ..utils import save_json, current_time
        self._vectorstore.save_local(self.vdb_dir)
        self.info
        self._info[&#39;last_update&#39;] = current_time()
        save_json(self.info, os.path.join(self.vdb_dir, &#39;info.json&#39;))
        if self.save_raw:
            save_json(self.data, os.path.join(self.vdb_dir, &#39;data.json&#39;))</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.search"><code class="name flex">
<span>def <span class="ident">search</span></span>(<span>self, query: str, top_k: int = 5, index_only: bool = True, **kwargs) ‑> List[Union[str, Dict[str, Any]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Similarity search of text on the vector database. Pass keyword arguments as filters on metadata.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>query</code></strong> :&ensp;<code>str</code></dt>
<dd>Text search string query.</dd>
<dt><strong><code>top_k</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum number of results to return. Defaults to 5.</dd>
<dt><strong><code>index_only</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If set as True, only the index string will be returned. Otherwise, metadata and scores will be returned as well. Defaults to True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Union[str, Dict[str, Any]]]</code></dt>
<dd>List of search results.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search(self, query: str, top_k: int = 5, index_only: bool = True, **kwargs) -&gt; List[Union[str, Dict[str, Any]]]:
    &#34;&#34;&#34;Similarity search of text on the vector database. Pass keyword arguments as filters on metadata.

    Args:
        query (str): Text search string query.
        top_k (int, optional): Maximum number of results to return. Defaults to 5.
        index_only (bool, optional): If set as True, only the index string will be returned. Otherwise, metadata and scores will be returned as well. Defaults to True.

    Returns:
        List[Union[str, Dict[str, Any]]]: List of search results.
    &#34;&#34;&#34;
    results = self.vectorstore.similarity_search_with_relevance_scores(query=query, k=top_k, fetch_k=max(top_k*2, 20), filter=kwargs)

    if index_only:
        results = list(map(lambda x: x[0].page_content, results))
    else:
        index = list(map(lambda x: x[0].page_content, results))
        metadata = list(map(lambda x: x[0].metadata, results))
        scores = list(map(lambda x: x[1], results))
        results = list(zip(index, scores, metadata))
        results = list(map(lambda x: self._result_dict(x[0], x[1], x[2]), results))
    return results</code></pre>
</details>
</dd>
<dt id="llmflex.Data.vector_database.VectorDatabase.search_by_metadata"><code class="name flex">
<span>def <span class="ident">search_by_metadata</span></span>(<span>self, **kwargs: Dict[str, Any]) ‑> Dict[str, langchain_core.documents.base.Document]</span>
</code></dt>
<dd>
<div class="desc"><p>Exact match search on metadata. Filters should be provided as key value pair arguments.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, Document]</code></dt>
<dd>Dictionary of saerch results, with docstore ids as the keys.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search_by_metadata(self, **kwargs: Dict[str, Any]) -&gt; Dict[str, Document]:
    &#34;&#34;&#34;Exact match search on metadata. Filters should be provided as key value pair arguments.

    Returns:
        Dict[str, Document]: Dictionary of saerch results, with docstore ids as the keys.
    &#34;&#34;&#34;
    results = dict(filter(lambda x: self._dictionary_filter(x, **kwargs), self.vectorstore.docstore._dict.items()))
    return results</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="llmflex.Data" href="index.html">llmflex.Data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="llmflex.Data.vector_database.default_vectordb_dir" href="#llmflex.Data.vector_database.default_vectordb_dir">default_vectordb_dir</a></code></li>
<li><code><a title="llmflex.Data.vector_database.list_vectordbs" href="#llmflex.Data.vector_database.list_vectordbs">list_vectordbs</a></code></li>
<li><code><a title="llmflex.Data.vector_database.name_checker" href="#llmflex.Data.vector_database.name_checker">name_checker</a></code></li>
<li><code><a title="llmflex.Data.vector_database.texts_to_documents" href="#llmflex.Data.vector_database.texts_to_documents">texts_to_documents</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="llmflex.Data.vector_database.VectorDatabase" href="#llmflex.Data.vector_database.VectorDatabase">VectorDatabase</a></code></h4>
<ul class="two-column">
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.add_documents" href="#llmflex.Data.vector_database.VectorDatabase.add_documents">add_documents</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.add_texts" href="#llmflex.Data.vector_database.VectorDatabase.add_texts">add_texts</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.data" href="#llmflex.Data.vector_database.VectorDatabase.data">data</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.delete_by_metadata" href="#llmflex.Data.vector_database.VectorDatabase.delete_by_metadata">delete_by_metadata</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.embeddings" href="#llmflex.Data.vector_database.VectorDatabase.embeddings">embeddings</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.from_data" href="#llmflex.Data.vector_database.VectorDatabase.from_data">from_data</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.from_empty" href="#llmflex.Data.vector_database.VectorDatabase.from_empty">from_empty</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.from_exist" href="#llmflex.Data.vector_database.VectorDatabase.from_exist">from_exist</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.info" href="#llmflex.Data.vector_database.VectorDatabase.info">info</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.name" href="#llmflex.Data.vector_database.VectorDatabase.name">name</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.save" href="#llmflex.Data.vector_database.VectorDatabase.save">save</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.save_raw" href="#llmflex.Data.vector_database.VectorDatabase.save_raw">save_raw</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.search" href="#llmflex.Data.vector_database.VectorDatabase.search">search</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.search_by_metadata" href="#llmflex.Data.vector_database.VectorDatabase.search_by_metadata">search_by_metadata</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.size" href="#llmflex.Data.vector_database.VectorDatabase.size">size</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.vdb_dir" href="#llmflex.Data.vector_database.VectorDatabase.vdb_dir">vdb_dir</a></code></li>
<li><code><a title="llmflex.Data.vector_database.VectorDatabase.vectorstore" href="#llmflex.Data.vector_database.VectorDatabase.vectorstore">vectorstore</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>